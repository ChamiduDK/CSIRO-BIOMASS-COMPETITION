{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01600982",
   "metadata": {
    "_cell_guid": "cf836d28-b79c-4d05-bde0-0cb9403881e9",
    "_uuid": "4ed08708-f596-4346-803f-4d642a3df21f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:03:57.275593Z",
     "iopub.status.busy": "2026-01-26T06:03:57.275324Z",
     "iopub.status.idle": "2026-01-26T06:03:58.510302Z",
     "shell.execute_reply": "2026-01-26T06:03:58.509638Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.248931,
     "end_time": "2026-01-26T06:03:58.511899",
     "exception": false,
     "start_time": "2026-01-26T06:03:57.262968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/pm-105524148-at-01-26-2026-06-03-10/__script__.py\n",
      "/kaggle/input/pm-105524148-at-01-26-2026-06-03-10/timm-1.0.22-py3-none-any.whl\n",
      "/kaggle/input/pm-105524148-at-01-26-2026-06-03-10/__results__.html\n",
      "/kaggle/input/pm-105524148-at-01-26-2026-06-03-10/input_requirements.txt\n",
      "/kaggle/input/pm-105524148-at-01-26-2026-06-03-10/__script__.ipynb\n",
      "/kaggle/input/pm-105524148-at-01-26-2026-06-03-10/__output__.json\n",
      "/kaggle/input/pm-105524148-at-01-26-2026-06-03-10/install_requirements.sh\n",
      "/kaggle/input/pm-105524148-at-01-26-2026-06-03-10/custom.css\n",
      "/kaggle/input/csiro-image-embeddings/train_siglip_embeddings.csv\n",
      "/kaggle/input/csiro-image-embeddings/train_dino_embeddings.csv\n",
      "/kaggle/input/csiro-mvp-models/model1.pth\n",
      "/kaggle/input/csiro-mvp-models/model2.pth\n",
      "/kaggle/input/csiro-mvp-models/model10.pth\n",
      "/kaggle/input/csiro-mvp-models/model7.pth\n",
      "/kaggle/input/csiro-mvp-models/model6.pth\n",
      "/kaggle/input/csiro-mvp-models/model4.pth\n",
      "/kaggle/input/csiro-mvp-models/model5.pth\n",
      "/kaggle/input/csiro-mvp-models/model9.pth\n",
      "/kaggle/input/csiro-mvp-models/model3.pth\n",
      "/kaggle/input/csiro-mvp-models/model8.pth\n",
      "/kaggle/input/csiro-biomass-solution-out-put/submission2.csv\n",
      "/kaggle/input/csiro-biomass-solution-out-put/professional_1_distributions.png\n",
      "/kaggle/input/csiro-biomass-solution-out-put/submission4.csv\n",
      "/kaggle/input/csiro-biomass-solution-out-put/submission3.csv\n",
      "/kaggle/input/csiro-biomass-solution-out-put/professional_6_hierarchical.png\n",
      "/kaggle/input/csiro-biomass-solution-out-put/submission1.csv\n",
      "/kaggle/input/csiro-biomass-solution-out-put/submission5.csv\n",
      "/kaggle/input/csiro-biomass-solution-out-put/professional_4_scatter_matrix.png\n",
      "/kaggle/input/csiro-biomass-solution-out-put/submission.csv\n",
      "/kaggle/input/csiro-biomass-solution-out-put/professional_5_sample_images.png\n",
      "/kaggle/input/csiro-biomass-solution-out-put/professional_3_boxplots.png\n",
      "/kaggle/input/csiro-biomass-solution-out-put/professional_2_correlation_matrix.png\n",
      "/kaggle/input/csiro-biomass-solution-out-put/catboost_info/learn_error.tsv\n",
      "/kaggle/input/csiro-biomass-solution-out-put/catboost_info/catboost_training.json\n",
      "/kaggle/input/csiro-biomass-solution-out-put/catboost_info/time_left.tsv\n",
      "/kaggle/input/csiro-biomass-solution-out-put/catboost_info/learn/events.out.tfevents\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_0/metrics.csv\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_0/swanlab_info.json\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_0/checkpoints/best_loss.pt\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_0/checkpoints/best_wr2.pt\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_0/checkpoints/last.pt\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_4/metrics.csv\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_4/swanlab_info.json\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_4/checkpoints/best_loss.pt\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_4/checkpoints/best_wr2.pt\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_4/checkpoints/last.pt\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_1/metrics.csv\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_1/swanlab_info.json\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_1/checkpoints/best_loss.pt\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_1/checkpoints/best_wr2.pt\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_1/checkpoints/last.pt\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_3/metrics.csv\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_3/swanlab_info.json\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_3/checkpoints/best_loss.pt\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_3/checkpoints/best_wr2.pt\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_3/checkpoints/last.pt\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_2/metrics.csv\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_2/swanlab_info.json\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_2/checkpoints/best_loss.pt\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_2/checkpoints/best_wr2.pt\n",
      "/kaggle/input/csiro/pytorch/default/12/fold_2/checkpoints/last.pt\n",
      "/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1/config.json\n",
      "/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1/preprocessor_config.json\n",
      "/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1/spiece.model\n",
      "/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1/README.md\n",
      "/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1/tokenizer.json\n",
      "/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1/tokenizer_config.json\n",
      "/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1/gitattributes\n",
      "/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1/model.safetensors\n",
      "/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1/special_tokens_map.json\n",
      "/kaggle/input/baseline-dinov3/pytorch/default/4/baseline-dinov3_aux/best_model_fold7.pth\n",
      "/kaggle/input/baseline-dinov3/pytorch/default/4/baseline-dinov3_aux/best_model_fold0.pth\n",
      "/kaggle/input/baseline-dinov3/pytorch/default/4/baseline-dinov3_aux/best_model_fold5.pth\n",
      "/kaggle/input/baseline-dinov3/pytorch/default/4/baseline-dinov3_aux/best_model_fold8.pth\n",
      "/kaggle/input/baseline-dinov3/pytorch/default/4/baseline-dinov3_aux/best_model_fold2.pth\n",
      "/kaggle/input/baseline-dinov3/pytorch/default/4/baseline-dinov3_aux/best_model_fold6.pth\n",
      "/kaggle/input/baseline-dinov3/pytorch/default/4/baseline-dinov3_aux/best_model_fold1.pth\n",
      "/kaggle/input/baseline-dinov3/pytorch/default/4/baseline-dinov3_aux/best_model_fold4.pth\n",
      "/kaggle/input/baseline-dinov3/pytorch/default/4/baseline-dinov3_aux/best_model_fold3.pth\n",
      "/kaggle/input/baseline-dinov3/pytorch/default/4/baseline-dinov3_aux/best_model_fold9.pth\n",
      "/kaggle/input/csiro-datasplit/__results__.html\n",
      "/kaggle/input/csiro-datasplit/csiro_data_split.csv\n",
      "/kaggle/input/csiro-datasplit/__notebook__.ipynb\n",
      "/kaggle/input/csiro-datasplit/__output__.json\n",
      "/kaggle/input/csiro-datasplit/custom.css\n",
      "/kaggle/input/dinov2/pytorch/giant/1/config.json\n",
      "/kaggle/input/dinov2/pytorch/giant/1/preprocessor_config.json\n",
      "/kaggle/input/dinov2/pytorch/giant/1/README.md\n",
      "/kaggle/input/dinov2/pytorch/giant/1/pytorch_model.bin\n",
      "/kaggle/input/dinov2/pytorch/giant/1/.gitattributes\n",
      "/kaggle/input/csiro-biomass/sample_submission.csv\n",
      "/kaggle/input/csiro-biomass/train.csv\n",
      "/kaggle/input/csiro-biomass/test.csv\n",
      "/kaggle/input/csiro-biomass/test/ID1001187975.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2099464826.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2037861084.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1211362607.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1853508321.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID193102215.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID698608346.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1859251563.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1880764911.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID853954911.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1403107574.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1781353117.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID384648061.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1563418511.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2125100696.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID482555369.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID638711343.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID779628955.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1876271942.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1692894460.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID746335827.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1136169672.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1471216911.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID846154859.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1294770420.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1183807388.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID423506847.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1889150649.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1140993511.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1413758094.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1545077474.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID95050718.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID528010569.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1645161155.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID786365141.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID896386823.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1025234388.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID663006174.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1509266870.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1496750796.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID471758347.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID740402124.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1624268863.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1098771283.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID710341728.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2086966681.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1573329652.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID54128926.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID50027657.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1559189397.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID290369222.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1590632667.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID552040066.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID488873801.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID363069566.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1839139621.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1131079710.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2010625680.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID152157478.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1357758282.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1498398599.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID679913293.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID697718693.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID4464212.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1275072698.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1579942839.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID799079114.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1415329644.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1510574031.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1078930021.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1456861072.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID930534670.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID13162390.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID567744300.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID344618040.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID566966892.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1437386574.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID667059550.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID72895391.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1193692654.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1386202352.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID871463897.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2096636211.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2003438517.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID21377800.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID230058600.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1753847361.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1512751450.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID12390962.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1746343319.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID978026131.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID383231615.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID146920896.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1036339023.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1168534540.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1859792585.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1251029854.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1113329413.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1874904894.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1671844336.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1831254380.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1103883611.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID797502182.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1784585001.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1058383417.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1488408526.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID429799190.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1291116815.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1516374298.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1618597318.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1345375788.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID686797154.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1139866256.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1149598723.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID212206250.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID112966473.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1540480250.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID544444725.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1513184765.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID668330410.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1444674500.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1962379474.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID605134229.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID914754166.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID354528442.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID950496197.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1395011773.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1357768767.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID210865340.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID936984905.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1976436386.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1215977190.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID803479541.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1244346858.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID158170916.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1208644039.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1314135397.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1012260530.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1053972079.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID656251220.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1084819986.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1337107565.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1268934251.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID617132135.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1472525822.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID668475812.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID681680726.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1476045099.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1570190541.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1403078396.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2030696575.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1782608354.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID194823383.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID196516535.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID212206832.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1638922597.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1457700382.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1989506559.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID789169173.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1634731537.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1428837636.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2006686196.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID885388135.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1789853061.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1655778545.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID697059386.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID121331988.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2099742797.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID342818398.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID317990700.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID706288721.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1159071020.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID755710743.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1254829053.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID475010202.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1693880739.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1894998379.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID48303557.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1385921939.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID147528735.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID407646960.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1035947949.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1119761112.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1988033238.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1857489997.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID742198710.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID588120964.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID431471530.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID353424190.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID380752847.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2069766023.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID600602588.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID560946727.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1011485656.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID808079729.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1217108125.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1623964968.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID980878870.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID793526563.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID397994621.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID975115267.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1237349078.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID684383343.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID866684633.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1665142816.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2048645043.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1953171547.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1451025862.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID71885430.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID307060225.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID969218269.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID980538882.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1028611175.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID670276799.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2002797732.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1374789439.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID473494649.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1993907137.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1962197151.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID828217731.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID972274220.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1954669045.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1354190372.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1458758610.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID40849327.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1952813879.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID572336285.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1473228876.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1963715583.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1463690813.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1899025384.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID386216505.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1789265307.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID315357834.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2089023774.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID520514019.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1970522802.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1139918758.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1051144034.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1370004842.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID761508093.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2052993274.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1277756619.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID6269659.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1574125908.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID135365668.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1182523622.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID554314721.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1049634115.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1127246618.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID900012207.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID574213894.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID415656958.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID61833032.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2053315094.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID550623196.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID657448172.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1675365449.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2014192906.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID162394992.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID968643034.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID684062938.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID802547515.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID294150104.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1618145129.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID956512130.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID142751858.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID325799913.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID443091455.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID661372352.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1062837331.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID498304885.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID187238869.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1450399782.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2056023629.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID576621307.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1199150612.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1411613934.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID105271783.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1703304524.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID875119737.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1176292407.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1729002155.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2091439402.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID576137678.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1946311744.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1982662138.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID983582017.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID661817669.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID753699705.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1789834546.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID529933668.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID490139972.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID743847993.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID7850481.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1088965591.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID629980789.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1119739385.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1477176296.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1113121340.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2131261930.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2145635095.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1414371018.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1148666289.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID839432753.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID157479394.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1761544403.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID846984946.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID751517087.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID577112774.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID353997899.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID748979397.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1070112260.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1108283583.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1868719645.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1980675327.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1163061745.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1148528732.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID534966093.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1717006117.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1953218650.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID633775166.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID808093827.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1997244125.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1920959057.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1948354837.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID364856705.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID249042826.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID332742639.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1680597197.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1421714468.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID905397692.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1782509721.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID141370843.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2056982009.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID94564238.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID8209776.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID908524512.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID610397481.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID750820644.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1515990019.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1547945326.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID587125778.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1620371305.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1474775613.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID545360459.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1783499590.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1249094008.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1525817840.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID227847873.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1052620238.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1888700589.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2052442675.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID963903358.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1121692672.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1343327476.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1667778338.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID257822026.jpg\n",
      "/kaggle/input/csiro-biomass-competition-comprehensive-eda/__results__.html\n",
      "/kaggle/input/csiro-biomass-competition-comprehensive-eda/__notebook__.ipynb\n",
      "/kaggle/input/csiro-biomass-competition-comprehensive-eda/__output__.json\n",
      "/kaggle/input/csiro-biomass-competition-comprehensive-eda/custom.css\n",
      "/kaggle/input/csiro-biomass-competition-comprehensive-eda/__results___files/__results___15_0.png\n",
      "/kaggle/input/csiro-biomass-competition-comprehensive-eda/__results___files/__results___25_0.png\n",
      "/kaggle/input/csiro-biomass-competition-comprehensive-eda/__results___files/__results___19_0.png\n",
      "/kaggle/input/csiro-biomass-competition-comprehensive-eda/__results___files/__results___31_0.png\n",
      "/kaggle/input/csiro-biomass-competition-comprehensive-eda/__results___files/__results___22_0.png\n",
      "/kaggle/input/csiro-biomass-competition-comprehensive-eda/__results___files/__results___28_0.png\n",
      "/kaggle/input/modelv3/pytorch/default/6/fold2_clover.pth\n",
      "/kaggle/input/modelv3/pytorch/default/6/fold0_dead.pth\n",
      "/kaggle/input/modelv3/pytorch/default/6/fold2_green.pth\n",
      "/kaggle/input/modelv3/pytorch/default/6/fold3_clover.pth\n",
      "/kaggle/input/modelv3/pytorch/default/6/fold3_dead.pth\n",
      "/kaggle/input/modelv3/pytorch/default/6/fold1_green.pth\n",
      "/kaggle/input/modelv3/pytorch/default/6/fold1_dead.pth\n",
      "/kaggle/input/modelv3/pytorch/default/6/fold3_green.pth\n",
      "/kaggle/input/modelv3/pytorch/default/6/fold0_green.pth\n",
      "/kaggle/input/modelv3/pytorch/default/6/fold2_dead.pth\n",
      "/kaggle/input/modelv3/pytorch/default/6/fold1_clover.pth\n",
      "/kaggle/input/modelv3/pytorch/default/6/fold0_clover.pth\n",
      "/kaggle/input/modelv3/pytorch/default/1/models_retrained/fold3_retrained.pth\n",
      "/kaggle/input/modelv3/pytorch/default/1/models_retrained/fold0_retrained.pth\n",
      "/kaggle/input/modelv3/pytorch/default/1/models_retrained/fold4_retrained.pth\n",
      "/kaggle/input/modelv3/pytorch/default/1/models_retrained/fold1_retrained.pth\n",
      "/kaggle/input/modelv3/pytorch/default/1/models_retrained/fold2_retrained.pth\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffa6894",
   "metadata": {
    "_cell_guid": "be27dd58-1d14-47d3-ad71-6691688cd501",
    "_uuid": "fc202777-c2ad-485d-b81d-f857d36e49a7",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009807,
     "end_time": "2026-01-26T06:03:58.533391",
     "exception": false,
     "start_time": "2026-01-26T06:03:58.523584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CSIRO Biomass Prediction - Multi-Model Ensemble\n",
    "\n",
    "## Overview\n",
    "This notebook implements a comprehensive ensemble approach for biomass prediction using three different model architectures:\n",
    "\n",
    "1. **SigLIP Feature Extraction + Ensemble Models** (LightGBM, CatBoost)\n",
    "2. **DINO CrossPVT-T2T-Mamba Architecture**\n",
    "3. **DINO MVP TiledFiLM Architecture**\n",
    "\n",
    "The final submission is a weighted ensemble of all three approaches with built-in timeout management to ensure completion within competition time limits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38a6fb1",
   "metadata": {
    "_cell_guid": "e9f113c4-3da4-4c0f-893f-9d91fc3c3b44",
    "_uuid": "ad7db450-b123-45b4-8616-320b59716393",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009698,
     "end_time": "2026-01-26T06:03:58.553821",
     "exception": false,
     "start_time": "2026-01-26T06:03:58.544123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Installation and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e549715",
   "metadata": {
    "_cell_guid": "0c021a93-4b0b-449b-9367-bf9da466a1ef",
    "_uuid": "5520ac93-ecfb-47a8-b884-75d5acbd84c8",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:03:58.574201Z",
     "iopub.status.busy": "2026-01-26T06:03:58.573820Z",
     "iopub.status.idle": "2026-01-26T06:05:07.490666Z",
     "shell.execute_reply": "2026-01-26T06:05:07.489657Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 68.92981,
     "end_time": "2026-01-26T06:05:07.493147",
     "exception": false,
     "start_time": "2026-01-26T06:03:58.563337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "  data = fetch_version_info()\n",
      "/usr/local/lib/python3.12/dist-packages/sqlalchemy/orm/query.py:195: SyntaxWarning: \"is not\" with 'tuple' literal. Did you mean \"!=\"?\n",
      "  if entities is not ():\n",
      "2026-01-26 06:04:54.214707: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1769407494.391783      31 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1769407494.442285      31 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1769407494.865388      31 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769407494.865438      31 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769407494.865441      31 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769407494.865444      31 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "import argparse\n",
    "import shutil\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List, Tuple, Dict\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import timm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, BayesianRidge\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from transformers import AutoProcessor, AutoImageProcessor, AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df94ebda",
   "metadata": {
    "_cell_guid": "2e883de6-6946-4afa-ae69-69efa315c04f",
    "_uuid": "887b2ae2-d0be-4ffd-b308-c2b8ed93746e",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.010113,
     "end_time": "2026-01-26T06:05:07.517708",
     "exception": false,
     "start_time": "2026-01-26T06:05:07.507595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Timeout Management System\n",
    "\n",
    "The TimeoutManager class ensures that the pipeline completes within the competition time limit by tracking elapsed time and making decisions about which models to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2630eb46",
   "metadata": {
    "_cell_guid": "cd4fe50f-6bcf-43d4-a0e0-53c4f1863d5d",
    "_uuid": "5fef4d52-a0b7-45a8-abd7-00a0f5b3f9bb",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:05:07.539812Z",
     "iopub.status.busy": "2026-01-26T06:05:07.538991Z",
     "iopub.status.idle": "2026-01-26T06:05:07.545007Z",
     "shell.execute_reply": "2026-01-26T06:05:07.544289Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01875,
     "end_time": "2026-01-26T06:05:07.546459",
     "exception": false,
     "start_time": "2026-01-26T06:05:07.527709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimeoutManager:\n",
    "    \"\"\"Manages execution time to prevent timeout\"\"\"\n",
    "    def __init__(self, max_time_seconds):\n",
    "        self.start_time = time.time()\n",
    "        self.max_time = max_time_seconds\n",
    "        \n",
    "    def time_elapsed(self):\n",
    "        return time.time() - self.start_time\n",
    "        \n",
    "    def time_remaining(self):\n",
    "        return self.max_time - self.time_elapsed()\n",
    "    \n",
    "    def should_continue(self, buffer_seconds=300):\n",
    "        \"\"\"Check if we have enough time to continue (with 5 min buffer)\"\"\"\n",
    "        return self.time_remaining() > buffer_seconds\n",
    "    \n",
    "    def log_time(self, message=\"\"):\n",
    "        elapsed = self.time_elapsed()\n",
    "        remaining = self.time_remaining()\n",
    "        print(f\"[TIME] {message} | Elapsed: {elapsed/3600:.2f}h | Remaining: {remaining/3600:.2f}h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0f6bf2",
   "metadata": {
    "_cell_guid": "baf4ae14-df73-4f72-b096-78a7214d6fd8",
    "_uuid": "d54dadd7-d3a9-494e-b7f7-ac4da9741252",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009561,
     "end_time": "2026-01-26T06:05:07.565845",
     "exception": false,
     "start_time": "2026-01-26T06:05:07.556284",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utility Functions and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8a8876e",
   "metadata": {
    "_cell_guid": "f3917f89-d891-4072-8883-dc39841b74c5",
    "_uuid": "2f28fe9d-e064-4ad8-bee7-bbf7eb1ef995",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:05:07.586179Z",
     "iopub.status.busy": "2026-01-26T06:05:07.585905Z",
     "iopub.status.idle": "2026-01-26T06:05:07.595960Z",
     "shell.execute_reply": "2026-01-26T06:05:07.595243Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.022054,
     "end_time": "2026-01-26T06:05:07.597449",
     "exception": false,
     "start_time": "2026-01-26T06:05:07.575395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seeding(SEED):\n",
    "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(SEED)\n",
    "        torch.cuda.manual_seed_all(SEED)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def flush():\n",
    "    \"\"\"Clear memory cache\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    DATA_PATH: Path = Path(\"/kaggle/input/csiro-biomass/\")\n",
    "    TRAIN_DATA_PATH: Path = DATA_PATH/'train'\n",
    "    TEST_DATA_PATH: Path = DATA_PATH/'test'\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    seed = 42\n",
    "\n",
    "cfg = Config()\n",
    "seeding(cfg.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b8761e",
   "metadata": {
    "_cell_guid": "1b59b4ee-d9c7-4b35-90ee-20e2cb987b43",
    "_uuid": "24fddf4f-9d9f-4d46-8cf3-b99569030e3c",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009803,
     "end_time": "2026-01-26T06:05:07.617230",
     "exception": false,
     "start_time": "2026-01-26T06:05:07.607427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Target Variables and Metrics\n",
    "\n",
    "The competition uses 5 target variables with specific weights for scoring:\n",
    "\n",
    "| Target | Weight | Description |\n",
    "|--------|--------|-------------|\n",
    "| Dry_Green_g | 0.1 | Green biomass dry weight |\n",
    "| Dry_Dead_g | 0.1 | Dead material dry weight |\n",
    "| Dry_Clover_g | 0.1 | Clover dry weight |\n",
    "| GDM_g | 0.2 | Green dry matter |\n",
    "| Dry_Total_g | 0.5 | Total dry biomass |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cb455a1",
   "metadata": {
    "_cell_guid": "2f6e4196-fe93-4bf7-bede-064a074d0ed1",
    "_uuid": "0f08636d-472c-4840-aa51-1bd442ecb197",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:05:07.638297Z",
     "iopub.status.busy": "2026-01-26T06:05:07.637629Z",
     "iopub.status.idle": "2026-01-26T06:05:07.643347Z",
     "shell.execute_reply": "2026-01-26T06:05:07.642715Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.017706,
     "end_time": "2026-01-26T06:05:07.644755",
     "exception": false,
     "start_time": "2026-01-26T06:05:07.627049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TARGET_NAMES = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\n",
    "weights = {\n",
    "    'Dry_Green_g': 0.1,\n",
    "    'Dry_Dead_g': 0.1,\n",
    "    'Dry_Clover_g': 0.1,\n",
    "    'GDM_g': 0.2,\n",
    "    'Dry_Total_g': 0.5,\n",
    "}\n",
    "TARGET_MAX = {\n",
    "    \"Dry_Clover_g\": 71.7865,\n",
    "    \"Dry_Dead_g\": 83.8407,\n",
    "    \"Dry_Green_g\": 157.9836,\n",
    "    \"Dry_Total_g\": 185.70,\n",
    "    \"GDM_g\": 157.9836,\n",
    "}\n",
    "\n",
    "def competition_metric(y_true, y_pred) -> float:\n",
    "    \"\"\"Calculate weighted R-squared metric as defined by competition\"\"\"\n",
    "    y_weighted = 0\n",
    "    for l, label in enumerate(TARGET_NAMES):\n",
    "        y_weighted = y_weighted + y_true[:, l].mean() * weights[label]\n",
    "    ss_res = 0\n",
    "    ss_tot = 0\n",
    "    for l, label in enumerate(TARGET_NAMES):\n",
    "        ss_res = ss_res + ((y_true[:, l] - y_pred[:, l])**2).mean() * weights[label]\n",
    "        ss_tot = ss_tot + ((y_true[:, l] - y_weighted)**2).mean() * weights[label]\n",
    "    return 1 - ss_res / ss_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de99cab9",
   "metadata": {
    "_cell_guid": "014d3f83-63da-40ba-9d81-b59ba4733ae6",
    "_uuid": "16201f9b-a860-4bd9-8820-857638bca36e",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009782,
     "end_time": "2026-01-26T06:05:07.664259",
     "exception": false,
     "start_time": "2026-01-26T06:05:07.654477",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb393b91",
   "metadata": {
    "_cell_guid": "84101df3-e1bc-4a77-a272-0620bf8ea28e",
    "_uuid": "b2ada914-dc4d-4a9f-bf2c-8865333c69ba",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:05:07.685320Z",
     "iopub.status.busy": "2026-01-26T06:05:07.684691Z",
     "iopub.status.idle": "2026-01-26T06:05:07.691657Z",
     "shell.execute_reply": "2026-01-26T06:05:07.691122Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018839,
     "end_time": "2026-01-26T06:05:07.692959",
     "exception": false,
     "start_time": "2026-01-26T06:05:07.674120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pivot_table(df: pd.DataFrame)->pd.DataFrame:\n",
    "    \"\"\"Convert long format to wide format\"\"\"\n",
    "    if 'target' in df.columns.tolist():\n",
    "        df_pt = pd.pivot_table(\n",
    "            df, \n",
    "            values='target', \n",
    "            index=['image_path', 'Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm'], \n",
    "            columns='target_name', \n",
    "            aggfunc='mean'\n",
    "        ).reset_index()\n",
    "    else:\n",
    "        df['target'] = 0\n",
    "        df_pt = pd.pivot_table(\n",
    "            df, \n",
    "            values='target', \n",
    "            index='image_path', \n",
    "            columns='target_name', \n",
    "            aggfunc='mean'\n",
    "        ).reset_index()\n",
    "    return df_pt\n",
    "\n",
    "def melt_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Convert wide format to long format for submission\"\"\"\n",
    "    melted = df.melt(\n",
    "        id_vars='image_path',\n",
    "        value_vars=TARGET_NAMES,\n",
    "        var_name='target_name',\n",
    "        value_name='target'\n",
    "    )\n",
    "    melted['sample_id'] = (\n",
    "        melted['image_path']\n",
    "        .str.replace(r'^.*/', '', regex=True)\n",
    "        .str.replace('.jpg', '', regex=False)\n",
    "        + '__' + melted['target_name']\n",
    "    )\n",
    "    return melted[['sample_id', 'image_path', 'target_name', 'target']]\n",
    "\n",
    "def post_process_biomass(df_preds):\n",
    "    \"\"\"Apply hierarchical reconciliation to ensure biological constraints\"\"\"\n",
    "    ordered_cols = [\"Dry_Green_g\", \"Dry_Clover_g\", \"Dry_Dead_g\", \"GDM_g\", \"Dry_Total_g\"]\n",
    "    Y = df_preds[ordered_cols].values.T\n",
    "    C = np.array([[1, 1, 0, -1,  0], [0, 0, 1,  1, -1]])\n",
    "    C_T = C.T\n",
    "    inv_CCt = np.linalg.inv(C @ C_T)\n",
    "    P = np.eye(5) - C_T @ inv_CCt @ C\n",
    "    Y_reconciled = P @ Y\n",
    "    Y_reconciled = Y_reconciled.T.clip(min=0)\n",
    "    df_out = df_preds.copy()\n",
    "    df_out[ordered_cols] = Y_reconciled\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f0fd8b",
   "metadata": {
    "_cell_guid": "b4b4cabc-1119-4852-a368-7e8b0048bb93",
    "_uuid": "0f8ad7b0-88d0-4119-a71e-3e72005efdd6",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009789,
     "end_time": "2026-01-26T06:05:07.712428",
     "exception": false,
     "start_time": "2026-01-26T06:05:07.702639",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Image Processing and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50d4889a",
   "metadata": {
    "_cell_guid": "cc3a4eb1-fa2b-4fe2-a85a-d7585d44c06b",
    "_uuid": "7c078fa4-5def-4c2a-8e32-5af825290439",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:05:07.733155Z",
     "iopub.status.busy": "2026-01-26T06:05:07.732913Z",
     "iopub.status.idle": "2026-01-26T06:05:07.742928Z",
     "shell.execute_reply": "2026-01-26T06:05:07.742362Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.022043,
     "end_time": "2026-01-26T06:05:07.744253",
     "exception": false,
     "start_time": "2026-01-26T06:05:07.722210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_image(image, patch_size=520, overlap=16):\n",
    "    \"\"\"Split image into overlapping patches\"\"\"\n",
    "    h, w, c = image.shape\n",
    "    stride = patch_size - overlap\n",
    "    patches, coords = [], []\n",
    "    for y in range(0, h, stride):\n",
    "        for x in range(0, w, stride):\n",
    "            y1, x1, y2, x2 = y, x, y + patch_size, x + patch_size\n",
    "            patch = image[y1:y2, x1:x2, :]\n",
    "            if patch.shape[0] < patch_size or patch.shape[1] < patch_size:\n",
    "                pad_h = patch_size - patch.shape[0]\n",
    "                pad_w = patch_size - patch.shape[1]\n",
    "                patch = np.pad(patch, ((0,pad_h), (0,pad_w), (0,0)), mode='reflect')\n",
    "            patches.append(patch)\n",
    "            coords.append((y1, x1, y2, x2))\n",
    "    return patches, coords\n",
    "\n",
    "def get_model(model_path: str, device: str = 'cpu'):\n",
    "    \"\"\"Load pretrained model and processor\"\"\"\n",
    "    model = AutoModel.from_pretrained(model_path, local_files_only=True)\n",
    "    processor = AutoImageProcessor.from_pretrained(model_path)\n",
    "    return model.eval().to(device), processor\n",
    "\n",
    "def compute_embeddings(model_path, df, patch_size=520):\n",
    "    \"\"\"Extract image embeddings using pretrained model\"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model, processor = get_model(model_path=model_path, device=device)\n",
    "    IMAGE_PATHS, EMBEDDINGS = [], []\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Computing embeddings\"):\n",
    "        img_path = row['image_path']\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        patches, coords = split_image(img, patch_size=patch_size)\n",
    "        images = [Image.fromarray(p).convert(\"RGB\") for p in patches]\n",
    "        inputs = processor(images=images, return_tensors=\"pt\").to(model.device)\n",
    "        with torch.no_grad():\n",
    "            if 'siglip' in model_path:\n",
    "                features = model.get_image_features(**inputs)\n",
    "            elif 'dino' in model_path:\n",
    "                features = model(**inputs).pooler_output\n",
    "            else:\n",
    "                raise Exception(\"Model should be dino or siglip\")\n",
    "        embeds = features.mean(dim=0).detach().cpu().numpy()\n",
    "        EMBEDDINGS.append(embeds)\n",
    "        IMAGE_PATHS.append(img_path)\n",
    "    embeddings = np.stack(EMBEDDINGS, axis=0)\n",
    "    n_features = embeddings.shape[1]\n",
    "    emb_columns = [f\"emb{i+1}\" for i in range(n_features)]\n",
    "    emb_df = pd.DataFrame(embeddings, columns=emb_columns)\n",
    "    emb_df['image_path'] = IMAGE_PATHS\n",
    "    df_final = df.merge(emb_df, on='image_path', how='left')\n",
    "    flush()\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aace48",
   "metadata": {
    "_cell_guid": "38bef913-fd46-4d9e-8875-b295d12127a5",
    "_uuid": "135e7313-654d-4bc6-80c7-8a8003cf2a97",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009673,
     "end_time": "2026-01-26T06:05:07.763849",
     "exception": false,
     "start_time": "2026-01-26T06:05:07.754176",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Semantic Feature Generation\n",
    "\n",
    "This section generates semantic features by computing similarity scores between image embeddings and text-based concept vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d2c1e20",
   "metadata": {
    "_cell_guid": "476d67da-1ecc-4789-a417-21b561f0ba8d",
    "_uuid": "5985a68d-6a02-49dd-8c92-29f91d229f2f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:05:07.784750Z",
     "iopub.status.busy": "2026-01-26T06:05:07.784514Z",
     "iopub.status.idle": "2026-01-26T06:05:07.792549Z",
     "shell.execute_reply": "2026-01-26T06:05:07.791856Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.020266,
     "end_time": "2026-01-26T06:05:07.794036",
     "exception": false,
     "start_time": "2026-01-26T06:05:07.773770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_semantic_features(image_embeddings, model_path):\n",
    "    \"\"\"Generate semantic similarity scores for various pasture concepts\"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    try:\n",
    "        model = AutoModel.from_pretrained(model_path).to(device)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    concept_groups = {\n",
    "        \"bare\": [\"bare soil\", \"dirt ground\", \"sparse vegetation\", \"exposed earth\"],\n",
    "        \"sparse\": [\"low density pasture\", \"thin grass\", \"short clipped grass\"],\n",
    "        \"medium\": [\"average pasture cover\", \"medium height grass\", \"grazed pasture\"],\n",
    "        \"dense\": [\"dense tall pasture\", \"thick grassy volume\", \"high biomass\", \"overgrown vegetation\"],\n",
    "        \"green\": [\"lush green vibrant pasture\", \"photosynthesizing leaves\", \"fresh growth\"],\n",
    "        \"dead\": [\"dry brown dead grass\", \"yellow straw\", \"senesced material\", \"standing hay\"],\n",
    "        \"clover\": [\"white clover\", \"trifolium repens\", \"broadleaf legume\", \"clover flowers\"],\n",
    "        \"grass\": [\"ryegrass\", \"blade-like leaves\", \"fescue\", \"grassy sward\"],\n",
    "        \"weeds\": [\"broadleaf weeds\", \"thistles\", \"non-pasture vegetation\"]\n",
    "    }\n",
    "    concept_vectors = {}\n",
    "    with torch.no_grad():\n",
    "        for name, prompts in concept_groups.items():\n",
    "            inputs = tokenizer(prompts, padding=\"max_length\", return_tensors=\"pt\").to(device)\n",
    "            emb = model.get_text_features(**inputs)\n",
    "            emb = emb / emb.norm(p=2, dim=-1, keepdim=True)\n",
    "            concept_vectors[name] = emb.mean(dim=0, keepdim=True)\n",
    "    if isinstance(image_embeddings, np.ndarray):\n",
    "        img_tensor = torch.tensor(image_embeddings, dtype=torch.float32).to(device)\n",
    "    else:\n",
    "        img_tensor = image_embeddings.to(device)\n",
    "    img_tensor = img_tensor / img_tensor.norm(p=2, dim=-1, keepdim=True)\n",
    "    scores = {}\n",
    "    for name, vec in concept_vectors.items():\n",
    "        scores[name] = torch.matmul(img_tensor, vec.T).cpu().numpy().flatten()\n",
    "    df_scores = pd.DataFrame(scores)\n",
    "    df_scores['ratio_greenness'] = df_scores['green'] / (df_scores['green'] + df_scores['dead'] + 1e-6)\n",
    "    df_scores['ratio_clover'] = df_scores['clover'] / (df_scores['clover'] + df_scores['grass'] + 1e-6)\n",
    "    df_scores['ratio_cover'] = (df_scores['dense'] + df_scores['medium']) / (df_scores['bare'] + df_scores['sparse'] + 1e-6)\n",
    "    df_scores['max_density'] = df_scores[['bare', 'sparse', 'medium', 'dense']].max(axis=1)\n",
    "    return df_scores.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb819b1",
   "metadata": {
    "_cell_guid": "239a6d70-431a-4ed6-86c0-1e2b9630dfbc",
    "_uuid": "10fe8f5b-febc-4b29-ac29-b2c62b0154c3",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.010357,
     "end_time": "2026-01-26T06:05:07.814487",
     "exception": false,
     "start_time": "2026-01-26T06:05:07.804130",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Supervised Embedding Engine\n",
    "\n",
    "Transforms raw embeddings into enriched features using PCA, PLS, and GMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a67c2a25",
   "metadata": {
    "_cell_guid": "e37732c2-3acf-484a-85d4-c525003051b7",
    "_uuid": "e49b801f-43c2-490e-ad48-f1933ef2979d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:05:07.836789Z",
     "iopub.status.busy": "2026-01-26T06:05:07.836551Z",
     "iopub.status.idle": "2026-01-26T06:05:07.843845Z",
     "shell.execute_reply": "2026-01-26T06:05:07.843147Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.019523,
     "end_time": "2026-01-26T06:05:07.845405",
     "exception": false,
     "start_time": "2026-01-26T06:05:07.825882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SupervisedEmbeddingEngine(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Feature engineering pipeline combining PCA, PLS, and GMM\"\"\"\n",
    "    def __init__(self, n_pca=0.98, n_pls=8, n_gmm=5, random_state=42):\n",
    "        self.n_pca = n_pca\n",
    "        self.n_pls = n_pls\n",
    "        self.n_gmm = n_gmm\n",
    "        self.random_state = random_state\n",
    "        self.scaler = StandardScaler()\n",
    "        self.pca = PCA(n_components=n_pca, random_state=random_state)\n",
    "        self.pls = PLSRegression(n_components=n_pls, scale=False)\n",
    "        self.gmm = GaussianMixture(n_components=n_gmm, covariance_type='diag', random_state=random_state)\n",
    "        self.pls_fitted_ = False\n",
    "\n",
    "    def fit(self, X, y=None, X_semantic=None):\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        self.pca.fit(X_scaled)\n",
    "        self.gmm.fit(X_scaled)\n",
    "        if y is not None:\n",
    "            y_clean = y.values if hasattr(y, 'values') else y\n",
    "            self.pls.fit(X_scaled, y_clean)\n",
    "            self.pls_fitted_ = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, X_semantic=None):\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self._generate_features(X_scaled, X_semantic)\n",
    "\n",
    "    def _generate_features(self, X_scaled, X_semantic=None):\n",
    "        features = []\n",
    "        f_pca = self.pca.transform(X_scaled)\n",
    "        features.append(f_pca)\n",
    "        if self.pls_fitted_:\n",
    "            f_pls = self.pls.transform(X_scaled)\n",
    "            features.append(f_pls)\n",
    "        f_gmm = self.gmm.predict_proba(X_scaled)\n",
    "        features.append(f_gmm)\n",
    "        if X_semantic is not None:\n",
    "            sem_norm = (X_semantic - np.mean(X_semantic, axis=0)) / (np.std(X_semantic, axis=0) + 1e-6)\n",
    "            features.append(sem_norm)\n",
    "        return np.hstack(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff12ef6",
   "metadata": {
    "_cell_guid": "5047752d-e0df-4c6c-8529-e2ec2a7d32d8",
    "_uuid": "45920271-1e59-49b0-8f70-3671980ba259",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.010155,
     "end_time": "2026-01-26T06:05:07.865512",
     "exception": false,
     "start_time": "2026-01-26T06:05:07.855357",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cross-Validation and Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4b85eab",
   "metadata": {
    "_cell_guid": "6bd41ed4-684f-4517-9fb4-f879b35440b2",
    "_uuid": "a6b27c40-cdcd-4e44-943a-73f9a34e1a5b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:05:07.886689Z",
     "iopub.status.busy": "2026-01-26T06:05:07.886434Z",
     "iopub.status.idle": "2026-01-26T06:05:07.897487Z",
     "shell.execute_reply": "2026-01-26T06:05:07.896682Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.023718,
     "end_time": "2026-01-26T06:05:07.899181",
     "exception": false,
     "start_time": "2026-01-26T06:05:07.875463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_results(oof, train_data):\n",
    "    \"\"\"Compare raw and post-processed predictions\"\"\"\n",
    "    y_oof_df = pd.DataFrame(oof, columns=TARGET_NAMES)\n",
    "    raw_score = competition_metric(train_data[TARGET_NAMES].values, y_oof_df.values)\n",
    "    print(f\"Raw CV Score: {raw_score:.6f}\")\n",
    "    y_oof_proc = post_process_biomass(y_oof_df)\n",
    "    proc_score = competition_metric(train_data[TARGET_NAMES].values, y_oof_proc.values)\n",
    "    print(f\"Processed CV Score: {proc_score:.6f}\")\n",
    "    print(f\"Improvement: {raw_score - proc_score:.6f}\")\n",
    "\n",
    "def cross_validate(model, train_data, test_data, feature_engine, semantic_train=None, semantic_test=None, target_transform='max', seed=42):\n",
    "    \"\"\"Perform k-fold cross-validation\"\"\"\n",
    "    n_splits = train_data['fold'].nunique()\n",
    "    target_max_arr = np.array([TARGET_MAX[t] for t in TARGET_NAMES], dtype=float)\n",
    "    y_true = train_data[TARGET_NAMES]\n",
    "    y_pred = pd.DataFrame(0.0, index=train_data.index, columns=TARGET_NAMES)\n",
    "    y_pred_test = np.zeros([len(test_data), len(TARGET_NAMES)], dtype=float)\n",
    "    \n",
    "    COLUMNS = [col for col in train_data.columns if col.startswith('emb')]\n",
    "    \n",
    "    for fold in range(n_splits):\n",
    "        seeding(seed*(seed//2 + fold))\n",
    "        train_mask = train_data['fold'] != fold\n",
    "        valid_mask = train_data['fold'] == fold\n",
    "        val_idx = train_data[valid_mask].index\n",
    "        X_train_raw = train_data[train_mask][COLUMNS].values\n",
    "        X_valid_raw = train_data[valid_mask][COLUMNS].values\n",
    "        X_test_raw = test_data[COLUMNS].values\n",
    "        sem_train_fold = semantic_train[train_mask] if semantic_train is not None else None\n",
    "        sem_valid_fold = semantic_train[valid_mask] if semantic_train is not None else None\n",
    "        y_train = train_data[train_mask][TARGET_NAMES].values\n",
    "        y_valid = train_data[valid_mask][TARGET_NAMES].values\n",
    "        if target_transform == 'log':\n",
    "            y_train_proc = np.log1p(y_train)\n",
    "        elif target_transform == 'max':\n",
    "            y_train_proc = y_train / target_max_arr\n",
    "        else:\n",
    "            y_train_proc = y_train\n",
    "        engine = deepcopy(feature_engine)\n",
    "        engine.fit(X_train_raw, y=y_train_proc, X_semantic=sem_train_fold)\n",
    "        x_train_eng = engine.transform(X_train_raw, X_semantic=sem_train_fold)\n",
    "        x_valid_eng = engine.transform(X_valid_raw, X_semantic=sem_valid_fold)\n",
    "        x_test_eng = engine.transform(X_test_raw, X_semantic=semantic_test)\n",
    "        fold_valid_pred = np.zeros_like(y_valid)\n",
    "        fold_test_pred = np.zeros([len(test_data), len(TARGET_NAMES)])\n",
    "        for k in range(len(TARGET_NAMES)):\n",
    "            regr = deepcopy(model)\n",
    "            regr.fit(x_train_eng, y_train_proc[:, k])\n",
    "            pred_valid_raw = regr.predict(x_valid_eng)\n",
    "            pred_test_raw = regr.predict(x_test_eng)\n",
    "            if target_transform == 'log':\n",
    "                pred_valid_inv = np.expm1(pred_valid_raw)\n",
    "                pred_test_inv = np.expm1(pred_test_raw)\n",
    "            elif target_transform == 'max':\n",
    "                pred_valid_inv = (pred_valid_raw * target_max_arr[k])\n",
    "                pred_test_inv = (pred_test_raw * target_max_arr[k])\n",
    "            else:\n",
    "                pred_valid_inv = pred_valid_raw\n",
    "                pred_test_inv = pred_test_raw\n",
    "            fold_valid_pred[:, k] = pred_valid_inv\n",
    "            fold_test_pred[:, k] = pred_test_inv\n",
    "        y_pred.loc[val_idx] = fold_valid_pred\n",
    "        y_pred_test += fold_test_pred / n_splits\n",
    "    full_cv = competition_metric(y_true.values, y_pred.values)\n",
    "    print(f\"Full CV Score: {full_cv:.6f}\")\n",
    "    return y_pred.values, y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4866f395",
   "metadata": {
    "_cell_guid": "0c8b73a7-7f0a-4854-9605-3106f6c5a1b2",
    "_uuid": "811f8068-c6c3-45f8-ba30-69ab3fb175fa",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009928,
     "end_time": "2026-01-26T06:05:07.919231",
     "exception": false,
     "start_time": "2026-01-26T06:05:07.909303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DINO Model Architecture - Part 1: Building Blocks\n",
    "\n",
    "This section implements the complex neural network architecture for the first DINO model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "543860c0",
   "metadata": {
    "_cell_guid": "1a14275b-2cb5-4786-b00b-81deac0537c4",
    "_uuid": "a6661d08-d88f-41cd-84bc-c557795d9ab5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:05:07.940726Z",
     "iopub.status.busy": "2026-01-26T06:05:07.940467Z",
     "iopub.status.idle": "2026-01-26T06:05:07.961287Z",
     "shell.execute_reply": "2026-01-26T06:05:07.960549Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.033454,
     "end_time": "2026-01-26T06:05:07.962667",
     "exception": false,
     "start_time": "2026-01-26T06:05:07.929213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, mlp_ratio=4.0, dropout=0.0):\n",
    "        super().__init__()\n",
    "        hid = int(dim * mlp_ratio)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hid), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(hid, dim), nn.Dropout(dropout))\n",
    "\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, dim, heads=8, dropout=0.0, mlp_ratio=4.0):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = nn.MultiheadAttention(dim, heads, dropout=dropout, batch_first=True)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.ff = FeedForward(dim, mlp_ratio=mlp_ratio, dropout=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.norm1(x)\n",
    "        attn_out, _ = self.attn(h, h, h, need_weights=False)\n",
    "        x = x + attn_out\n",
    "        x = x + self.ff(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "class MobileViTBlock(nn.Module):\n",
    "    \"\"\"Mobile Vision Transformer block for efficient local processing\"\"\"\n",
    "    def __init__(self, dim, heads=4, depth=2, patch=(2, 2), dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.local = nn.Sequential(\n",
    "            nn.Conv2d(dim, dim, 3, padding=1, groups=dim),\n",
    "            nn.Conv2d(dim, dim, 1), nn.GELU())\n",
    "        self.patch = patch\n",
    "        self.transformer = nn.ModuleList([AttentionBlock(dim, heads=heads, dropout=dropout, mlp_ratio=2.0) for _ in range(depth)])\n",
    "        self.fuse = nn.Conv2d(dim * 2, dim, kernel_size=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        local_feat = self.local(x)\n",
    "        B, C, H, W = local_feat.shape\n",
    "        ph, pw = self.patch\n",
    "        new_h = math.ceil(H / ph) * ph\n",
    "        new_w = math.ceil(W / pw) * pw\n",
    "        if new_h != H or new_w != W:\n",
    "            local_feat = F.interpolate(local_feat, size=(new_h, new_w), mode=\"bilinear\", align_corners=False)\n",
    "            H, W = new_h, new_w\n",
    "        tokens = local_feat.unfold(2, ph, ph).unfold(3, pw, pw)\n",
    "        tokens = tokens.contiguous().view(B, C, -1, ph, pw)\n",
    "        tokens = tokens.permute(0, 2, 3, 4, 1).reshape(B, -1, C)\n",
    "        for blk in self.transformer: tokens = blk(tokens)\n",
    "        feat = tokens.view(B, -1, ph * pw, C).permute(0, 3, 1, 2)\n",
    "        nh = H // ph\n",
    "        nw = W // pw\n",
    "        feat = feat.view(B, C, nh, nw, ph, pw).permute(0, 1, 2, 4, 3, 5)\n",
    "        feat = feat.reshape(B, C, H, W)\n",
    "        if feat.shape[-2:] != x.shape[-2:]:\n",
    "            feat = F.interpolate(feat, size=x.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        return self.fuse(torch.cat([x, feat], dim=1))\n",
    "\n",
    "class SpatialReductionAttention(nn.Module):\n",
    "    \"\"\"Pyramid Vision Transformer spatial reduction attention\"\"\"\n",
    "    def __init__(self, dim, heads=8, sr_ratio=2, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        self.scale = (dim // heads) ** -0.5\n",
    "        self.q = nn.Linear(dim, dim)\n",
    "        self.kv = nn.Linear(dim, dim * 2)\n",
    "        self.sr_ratio = sr_ratio\n",
    "        if sr_ratio > 1:\n",
    "            self.sr = nn.Conv2d(dim, dim, kernel_size=sr_ratio, stride=sr_ratio)\n",
    "            self.norm = nn.LayerNorm(dim)\n",
    "        else: self.sr = None\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, hw: Tuple[int, int]):\n",
    "        B, N, C = x.shape\n",
    "        q = self.q(x).reshape(B, N, self.heads, C // self.heads).permute(0, 2, 1, 3)\n",
    "        if self.sr is not None:\n",
    "            H, W = hw\n",
    "            feat = x.transpose(1, 2).reshape(B, C, H, W)\n",
    "            feat = self.sr(feat)\n",
    "            feat = feat.reshape(B, C, -1).transpose(1, 2)\n",
    "            feat = self.norm(feat)\n",
    "        else: feat = x\n",
    "        kv = self.kv(feat)\n",
    "        k, v = kv.chunk(2, dim=-1)\n",
    "        k = k.reshape(B, -1, self.heads, C // self.heads).permute(0, 2, 3, 1)\n",
    "        v = v.reshape(B, -1, self.heads, C // self.heads).permute(0, 2, 1, 3)\n",
    "        attn = torch.matmul(q, k) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.drop(attn)\n",
    "        out = torch.matmul(attn, v).permute(0, 2, 1, 3).reshape(B, N, C)\n",
    "        return self.proj(out)\n",
    "\n",
    "class PVTBlock(nn.Module):\n",
    "    \"\"\"Pyramid Vision Transformer block\"\"\"\n",
    "    def __init__(self, dim, heads=8, sr_ratio=2, dropout=0.0, mlp_ratio=4.0):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.sra = SpatialReductionAttention(dim, heads=heads, sr_ratio=sr_ratio, dropout=dropout)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.ff = FeedForward(dim, mlp_ratio=mlp_ratio, dropout=dropout)\n",
    "\n",
    "    def forward(self, x, hw: Tuple[int, int]):\n",
    "        x = x + self.sra(self.norm1(x), hw)\n",
    "        x = x + self.ff(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "class LocalMambaBlock(nn.Module):\n",
    "    \"\"\"Local processing block inspired by Mamba architecture\"\"\"\n",
    "    def __init__(self, dim, kernel_size=5, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.dwconv = nn.Conv1d(dim, dim, kernel_size=kernel_size, padding=kernel_size//2, groups=dim)\n",
    "        self.gate = nn.Linear(dim, dim)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm(x)\n",
    "        g = torch.sigmoid(self.gate(x))\n",
    "        x = (x * g).transpose(1, 2)\n",
    "        x = self.dwconv(x).transpose(1, 2)\n",
    "        x = self.proj(x)\n",
    "        x = self.drop(x)\n",
    "        return shortcut + x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549e4aee",
   "metadata": {
    "_cell_guid": "0ce39ddf-048a-4a34-9295-9938bb786d98",
    "_uuid": "f0380909-2c1a-4af3-a619-af1c2109b7e7",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009848,
     "end_time": "2026-01-26T06:05:07.982682",
     "exception": false,
     "start_time": "2026-01-26T06:05:07.972834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DINO Model Architecture - Part 2: Advanced Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c75bb95f",
   "metadata": {
    "_cell_guid": "9d42f7e3-e576-4e8b-9d5a-294a3f2f5a91",
    "_uuid": "e4d3bfae-c03f-42ab-a69e-e6a08fb0af80",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:05:08.004114Z",
     "iopub.status.busy": "2026-01-26T06:05:08.003852Z",
     "iopub.status.idle": "2026-01-26T06:05:08.026458Z",
     "shell.execute_reply": "2026-01-26T06:05:08.025854Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.034929,
     "end_time": "2026-01-26T06:05:08.027686",
     "exception": false,
     "start_time": "2026-01-26T06:05:07.992757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class T2TRetokenizer(nn.Module):\n",
    "    \"\"\"Tokens-to-Token retokenization module\"\"\"\n",
    "    def __init__(self, dim, depth=2, heads=4, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([AttentionBlock(dim, heads=heads, dropout=dropout, mlp_ratio=2.0) for _ in range(depth)])\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, grid_hw: Tuple[int, int]):\n",
    "        B, T, C = tokens.shape\n",
    "        H, W = grid_hw\n",
    "        feat_map = tokens.transpose(1, 2).reshape(B, C, H, W)\n",
    "        seq = feat_map.flatten(2).transpose(1, 2)\n",
    "        for blk in self.blocks: seq = blk(seq)\n",
    "        seq_map = seq.transpose(1, 2).reshape(B, C, H, W)\n",
    "        pooled = F.adaptive_avg_pool2d(seq_map, (2, 2))\n",
    "        retokens = pooled.flatten(2).transpose(1, 2)\n",
    "        return retokens, seq_map\n",
    "\n",
    "class CrossScaleFusion(nn.Module):\n",
    "    \"\"\"Cross-scale feature fusion with bidirectional attention\"\"\"\n",
    "    def __init__(self, dim, heads=6, dropout=0.0, layers=2):\n",
    "        super().__init__()\n",
    "        self.layers_s = nn.ModuleList([AttentionBlock(dim, heads=heads, dropout=dropout, mlp_ratio=2.0) for _ in range(layers)])\n",
    "        self.layers_b = nn.ModuleList([AttentionBlock(dim, heads=heads, dropout=dropout, mlp_ratio=2.0) for _ in range(layers)])\n",
    "        self.cross_s = nn.ModuleList([nn.MultiheadAttention(dim, heads, dropout=dropout, batch_first=True, kdim=dim, vdim=dim) for _ in range(layers)])\n",
    "        self.cross_b = nn.ModuleList([nn.MultiheadAttention(dim, heads, dropout=dropout, batch_first=True, kdim=dim, vdim=dim) for _ in range(layers)])\n",
    "        self.norm_s = nn.LayerNorm(dim)\n",
    "        self.norm_b = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, tok_s: torch.Tensor, tok_b: torch.Tensor):\n",
    "        B, Ts, C = tok_s.shape\n",
    "        Tb = tok_b.shape[1]\n",
    "        cls_s = tok_s.new_zeros(B, 1, C)\n",
    "        cls_b = tok_b.new_zeros(B, 1, C)\n",
    "        tok_s = torch.cat([cls_s, tok_s], dim=1)\n",
    "        tok_b = torch.cat([cls_b, tok_b], dim=1)\n",
    "        for ls, lb, cs, cb in zip(self.layers_s, self.layers_b, self.cross_s, self.cross_b):\n",
    "            tok_s = ls(tok_s)\n",
    "            tok_b = lb(tok_b)\n",
    "            q_s = self.norm_s(tok_s[:, :1])\n",
    "            q_b = self.norm_b(tok_b[:, :1])\n",
    "            cls_s_upd, _ = cs(q_s, torch.cat([tok_b, q_b], dim=1), torch.cat([tok_b, q_b], dim=1), need_weights=False)\n",
    "            cls_b_upd, _ = cb(q_b, torch.cat([tok_s, q_s], dim=1), torch.cat([tok_s, q_s], dim=1), need_weights=False)\n",
    "            tok_s = torch.cat([tok_s[:, :1] + cls_s_upd, tok_s[:, 1:]], dim=1)\n",
    "            tok_b = torch.cat([tok_b[:, :1] + cls_b_upd, tok_b[:, 1:]], dim=1)\n",
    "        tokens = torch.cat([tok_s[:, :1], tok_b[:, :1], tok_s[:, 1:], tok_b[:, 1:]], dim=1)\n",
    "        return tokens\n",
    "\n",
    "class TileEncoder(nn.Module):\n",
    "    \"\"\"Encode image tiles using backbone model\"\"\"\n",
    "    def __init__(self, backbone: nn.Module, input_res: int):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.input_res = input_res\n",
    "\n",
    "    def forward(self, x: torch.Tensor, grid: Tuple[int, int]):\n",
    "        B, C, H, W = x.shape\n",
    "        r, c = grid\n",
    "        hs = torch.linspace(0, H, steps=r + 1, device=x.device).round().long()\n",
    "        ws = torch.linspace(0, W, steps=c + 1, device=x.device).round().long()\n",
    "        tiles = []\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                rs, re = hs[i].item(), hs[i + 1].item()\n",
    "                cs, ce = ws[j].item(), ws[j + 1].item()\n",
    "                xt = x[:, :, rs:re, cs:ce]\n",
    "                if xt.shape[-2:] != (self.input_res, self.input_res):\n",
    "                    xt = F.interpolate(xt, size=(self.input_res, self.input_res), mode=\"bilinear\", align_corners=False)\n",
    "                tiles.append(xt)\n",
    "        tiles = torch.stack(tiles, dim=1)\n",
    "        flat = tiles.view(-1, C, self.input_res, self.input_res)\n",
    "        feats = self.backbone(flat)\n",
    "        return feats.view(B, -1, feats.shape[-1])\n",
    "\n",
    "class PyramidMixer(nn.Module):\n",
    "    \"\"\"Multi-scale pyramid feature mixing with MobileViT, PVT, and Mamba blocks\"\"\"\n",
    "    def __init__(self, dim_in: int, dims: Tuple[int, int, int], mobilevit_heads=4, mobilevit_depth=2, sra_heads=6, sra_ratio=2, mamba_depth=3, mamba_kernel=5, dropout=0.0):\n",
    "        super().__init__()\n",
    "        c1, c2, c3 = dims\n",
    "        self.proj1 = nn.Linear(dim_in, c1)\n",
    "        self.mobilevit = MobileViTBlock(c1, heads=mobilevit_heads, depth=mobilevit_depth, dropout=dropout)\n",
    "        self.proj2 = nn.Linear(c1, c2)\n",
    "        self.pvt = PVTBlock(c2, heads=sra_heads, sr_ratio=sra_ratio, dropout=dropout, mlp_ratio=3.0)\n",
    "        self.mamba_local = LocalMambaBlock(c2, kernel_size=mamba_kernel, dropout=dropout)\n",
    "        self.proj3 = nn.Linear(c2, c3)\n",
    "        self.mamba_global = nn.ModuleList([LocalMambaBlock(c3, kernel_size=mamba_kernel, dropout=dropout) for _ in range(mamba_depth)])\n",
    "        self.final_attn = AttentionBlock(c3, heads=min(8, c3//64+1), dropout=dropout, mlp_ratio=2.0)\n",
    "\n",
    "    def _tokens_to_map(self, tokens: torch.Tensor, target_hw: Tuple[int, int]):\n",
    "        B, N, C = tokens.shape\n",
    "        H, W = target_hw\n",
    "        need = H * W\n",
    "        if N < need:\n",
    "            pad = tokens.new_zeros(B, need-N, C)\n",
    "            tokens = torch.cat([tokens, pad], dim=1)\n",
    "        tokens = tokens[:, :need, :]\n",
    "        return tokens.transpose(1, 2).reshape(B, C, H, W)\n",
    "\n",
    "    @staticmethod\n",
    "    def _fit_hw(n_tokens: int) -> Tuple[int, int]:\n",
    "        h = int(math.sqrt(n_tokens))\n",
    "        w = h\n",
    "        while h * w < n_tokens:\n",
    "            w += 1\n",
    "            if h * w < n_tokens: h += 1\n",
    "        return h, w\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor):\n",
    "        B, N, C = tokens.shape\n",
    "        map_hw = (3, 4)\n",
    "        feat_map = self._tokens_to_map(tokens, map_hw)\n",
    "        t1 = self.proj1(tokens)\n",
    "        m1 = self._tokens_to_map(t1, map_hw)\n",
    "        m1 = self.mobilevit(m1)\n",
    "        t1_out = m1.flatten(2).transpose(1, 2)[:, :N]\n",
    "        t2 = self.proj2(t1_out)\n",
    "        new_len = max(4, N//2)\n",
    "        t2 = t2[:, :new_len] + F.adaptive_avg_pool1d(t2.transpose(1, 2), new_len).transpose(1, 2)\n",
    "        hw2 = self._fit_hw(t2.size(1))\n",
    "        if t2.size(1) < hw2[0] * hw2[1]:\n",
    "            pad = t2.new_zeros(B, hw2[0]*hw2[1]-t2.size(1), t2.size(2))\n",
    "            t2 = torch.cat([t2, pad], dim=1)\n",
    "        t2 = self.pvt(t2, hw2)\n",
    "        t2 = self.mamba_local(t2)\n",
    "        t3 = self.proj3(t2)\n",
    "        pooled = torch.stack([t3.mean(dim=1), t3.max(dim=1).values], dim=1)\n",
    "        t3 = pooled\n",
    "        for blk in self.mamba_global: t3 = blk(t3)\n",
    "        t3 = self.final_attn(t3)\n",
    "        return t3.mean(dim=1), {\"stage1_map\": m1.detach(), \"stage2_tokens\": t2.detach(), \"stage3_tokens\": t3.detach()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc261c04",
   "metadata": {
    "_cell_guid": "48d4ab0b-c799-4b61-818b-245be7bdb3b7",
    "_uuid": "c7ba9766-1134-4c99-92bb-4078a089b06d",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.010014,
     "end_time": "2026-01-26T06:05:08.047544",
     "exception": false,
     "start_time": "2026-01-26T06:05:08.037530",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DINO Model Architecture - Part 3: Main Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9a3e6d2",
   "metadata": {
    "_cell_guid": "b1754cc3-3086-455e-a5c8-6c56429549c7",
    "_uuid": "40bbc7dc-5f68-49db-954a-eb9c18fc40ae",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:05:08.069053Z",
     "iopub.status.busy": "2026-01-26T06:05:08.068825Z",
     "iopub.status.idle": "2026-01-26T06:05:08.090921Z",
     "shell.execute_reply": "2026-01-26T06:05:08.090280Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.034788,
     "end_time": "2026-01-26T06:05:08.092380",
     "exception": false,
     "start_time": "2026-01-26T06:05:08.057592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainCFG:\n",
    "    dropout: float = 0.1\n",
    "    hidden_ratio: float = 0.35\n",
    "    dino_candidates: Tuple[str, ...] = (\"vit_base_patch14_dinov2\", \"vit_base_patch14_reg4_dinov2\", \"vit_small_patch14_dinov2\")\n",
    "    small_grid: Tuple[int, int] = (4, 4)\n",
    "    big_grid: Tuple[int, int] = (2, 2)\n",
    "    t2t_depth: int = 2\n",
    "    cross_layers: int = 2\n",
    "    cross_heads: int = 6\n",
    "    pyramid_dims: Tuple[int, int, int] = (384, 512, 640)\n",
    "    mobilevit_heads: int = 4\n",
    "    mobilevit_depth: int = 2\n",
    "    sra_heads: int = 8\n",
    "    sra_ratio: int = 2\n",
    "    mamba_depth: int = 3\n",
    "    mamba_kernel: int = 5\n",
    "    aux_head: bool = True\n",
    "    aux_loss_weight: float = 0.4\n",
    "    ALL_TARGET_COLS: Tuple[str, ...] = (\"Dry_Green_g\", \"Dry_Dead_g\", \"Dry_Clover_g\", \"GDM_g\", \"Dry_Total_g\")\n",
    "\n",
    "CFG = TrainCFG()\n",
    "\n",
    "def update_cfg_from_checkpoint(cfg_dict: dict):\n",
    "    global CFG\n",
    "    if not cfg_dict: return\n",
    "    for k, v in cfg_dict.items():\n",
    "        if hasattr(CFG, k): setattr(CFG, k, v)\n",
    "\n",
    "class CrossPVT_T2T_MambaDINO(nn.Module):\n",
    "    \"\"\"\n",
    "    Advanced DINO architecture combining:\n",
    "    - Cross-scale Vision Transformer (PVT)\n",
    "    - Tokens-to-Token (T2T) processing\n",
    "    - Mamba-inspired local blocks\n",
    "    - Multi-grid tile encoding\n",
    "    \"\"\"\n",
    "    def __init__(self, dropout: float = 0.1, hidden_ratio: float = 0.35):\n",
    "        super().__init__()\n",
    "        self.backbone, self.feat_dim, self.backbone_name, self.input_res = self._build_dino_backbone()\n",
    "        self.tile_encoder = TileEncoder(self.backbone, self.input_res)\n",
    "        self.t2t = T2TRetokenizer(self.feat_dim, depth=CFG.t2t_depth, heads=CFG.cross_heads, dropout=dropout)\n",
    "        self.cross = CrossScaleFusion(self.feat_dim, heads=CFG.cross_heads, dropout=dropout, layers=CFG.cross_layers)\n",
    "        self.pyramid = PyramidMixer(dim_in=self.feat_dim, dims=CFG.pyramid_dims, mobilevit_heads=CFG.mobilevit_heads, mobilevit_depth=CFG.mobilevit_depth, sra_heads=CFG.sra_heads, sra_ratio=CFG.sra_ratio, mamba_depth=CFG.mamba_depth, mamba_kernel=CFG.mamba_kernel, dropout=dropout)\n",
    "        self.combined_dim = CFG.pyramid_dims[-1] * 2\n",
    "        hidden = max(32, int(self.combined_dim * hidden_ratio))\n",
    "        def head(): return nn.Sequential(nn.Linear(self.combined_dim, hidden), nn.GELU(), nn.Dropout(dropout), nn.Linear(hidden, 1))\n",
    "        self.head_green = head()\n",
    "        self.head_clover = head()\n",
    "        self.head_dead = head()\n",
    "        self.score_head = nn.Sequential(nn.LayerNorm(self.combined_dim), nn.Linear(self.combined_dim, 1))\n",
    "        self.aux_head = nn.Sequential(nn.LayerNorm(CFG.pyramid_dims[1]), nn.Linear(CFG.pyramid_dims[1], 5)) if CFG.aux_head else None\n",
    "        self.softplus = nn.Softplus(beta=1.0)\n",
    "        self.cross_gate_left = nn.Linear(CFG.pyramid_dims[-1], CFG.pyramid_dims[-1])\n",
    "        self.cross_gate_right = nn.Linear(CFG.pyramid_dims[-1], CFG.pyramid_dims[-1])\n",
    "\n",
    "    def _build_dino_backbone(self):\n",
    "        last_err = None\n",
    "        for name in CFG.dino_candidates:\n",
    "            for gp in [\"token\", \"avg\", \"__default__\"]:\n",
    "                try:\n",
    "                    if gp == \"__default__\":\n",
    "                        m = timm.create_model(name, pretrained=False, num_classes=0)\n",
    "                        gp_str = \"default\"\n",
    "                    else:\n",
    "                        m = timm.create_model(name, pretrained=False, num_classes=0, global_pool=gp)\n",
    "                        gp_str = gp\n",
    "                    feat = m.num_features\n",
    "                    input_res = self._infer_input_res(m)\n",
    "                    if hasattr(m, \"set_grad_checkpointing\"):\n",
    "                        m.set_grad_checkpointing(True)\n",
    "                    return m, feat, name, int(input_res)\n",
    "                except Exception as e: last_err = e; continue\n",
    "        raise RuntimeError(f\"Cannot create any DINO backbone. Last error: {last_err}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _infer_input_res(m) -> int:\n",
    "        if hasattr(m, \"patch_embed\") and hasattr(m.patch_embed, \"img_size\"):\n",
    "            isz = m.patch_embed.img_size\n",
    "            return int(isz if isinstance(isz, (int, float)) else isz[0])\n",
    "        if hasattr(m, \"img_size\"):\n",
    "            isz = m.img_size\n",
    "            return int(isz if isinstance(isz, (int, float)) else isz[0])\n",
    "        dc = getattr(m, \"default_cfg\", {}) or {}\n",
    "        ins = dc.get(\"input_size\", None)\n",
    "        if ins:\n",
    "            if isinstance(ins, (tuple, list)) and len(ins) >= 2:\n",
    "                return int(ins[1])\n",
    "            return int(ins if isinstance(ins, (int, float)) else 224)\n",
    "        return 518\n",
    "\n",
    "    def _half_forward(self, x_half: torch.Tensor):\n",
    "        tiles_small = self.tile_encoder(x_half, CFG.small_grid)\n",
    "        tiles_big = self.tile_encoder(x_half, CFG.big_grid)\n",
    "        t2, stage1_map = self.t2t(tiles_small, CFG.small_grid)\n",
    "        fused = self.cross(t2, tiles_big)\n",
    "        feat, feat_maps = self.pyramid(fused)\n",
    "        feat_maps[\"stage1_map\"] = stage1_map\n",
    "        return feat, feat_maps\n",
    "\n",
    "    def _merge_heads(self, f_l: torch.Tensor, f_r: torch.Tensor):\n",
    "        g_l = torch.sigmoid(self.cross_gate_left(f_r))\n",
    "        g_r = torch.sigmoid(self.cross_gate_right(f_l))\n",
    "        f_l = f_l * g_l\n",
    "        f_r = f_r * g_r\n",
    "        f = torch.cat([f_l, f_r], dim=1)\n",
    "        green_pos = self.softplus(self.head_green(f))\n",
    "        clover_pos = self.softplus(self.head_clover(f))\n",
    "        dead_pos = self.softplus(self.head_dead(f))\n",
    "        gdm = green_pos + clover_pos\n",
    "        total = gdm + dead_pos\n",
    "        return total, gdm, green_pos, f\n",
    "\n",
    "    def forward(self, *inputs, x_left=None, x_right=None, return_features: bool = False):\n",
    "        if inputs:\n",
    "            if len(inputs) == 1:\n",
    "                first = inputs[0]\n",
    "                if isinstance(first, (tuple, list)):\n",
    "                    if len(first) >= 1: x_left = first[0]\n",
    "                    if len(first) >= 2: x_right = first[1]\n",
    "                else: x_left = first\n",
    "            else: x_left = inputs[0]; x_right = inputs[1]\n",
    "        if x_left is None or (isinstance(x_left, torch.Tensor) and x_left.shape[0] == 0):\n",
    "            device = next(self.parameters()).device\n",
    "            dtype = next(self.parameters()).dtype\n",
    "            zero = torch.zeros(0, 1, device=device, dtype=dtype)\n",
    "            out = {\"total\": zero, \"gdm\": zero, \"green\": zero, \"score_feat\": torch.zeros(0, self.combined_dim, device=device, dtype=dtype)}\n",
    "            if self.aux_head is not None:\n",
    "                out[\"aux\"] = torch.zeros(0, len(CFG.ALL_TARGET_COLS), device=device, dtype=dtype)\n",
    "            if return_features: out[\"feature_maps\"] = {}\n",
    "            return out\n",
    "        if x_right is None:\n",
    "            if isinstance(x_left, torch.Tensor) and x_left.shape[1] % 2 == 0:\n",
    "                x_left, x_right = torch.chunk(x_left, 2, dim=1)\n",
    "            else: raise ValueError(\"Missing x_right input.\")\n",
    "        feat_l, feats_l = self._half_forward(x_left)\n",
    "        feat_r, feats_r = self._half_forward(x_right)\n",
    "        total, gdm, green, f_concat = self._merge_heads(feat_l, feat_r)\n",
    "        out = {\"total\": total, \"gdm\": gdm, \"green\": green, \"score_feat\": f_concat}\n",
    "        if self.aux_head is not None:\n",
    "            aux_tokens = torch.cat([feats_l[\"stage2_tokens\"], feats_r[\"stage2_tokens\"]], dim=1)\n",
    "            aux_pred = self.softplus(self.aux_head(aux_tokens.mean(dim=1)))\n",
    "            out[\"aux\"] = aux_pred\n",
    "        if return_features:\n",
    "            out[\"feature_maps\"] = {\"stage1_left\": feats_l.get(\"stage1_map\"), \"stage1_right\": feats_r.get(\"stage1_map\"), \"stage3_left\": feats_l.get(\"stage3_tokens\"), \"stage3_right\": feats_r.get(\"stage3_tokens\")}\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52156e1a",
   "metadata": {
    "_cell_guid": "d559898b-680c-4ef6-bfbc-5184a331b617",
    "_uuid": "411652ca-d414-49c7-9652-606cfb0cb76e",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009942,
     "end_time": "2026-01-26T06:05:08.112344",
     "exception": false,
     "start_time": "2026-01-26T06:05:08.102402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DINO Model 1 Inference Configuration and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9daedb5",
   "metadata": {
    "_cell_guid": "d3536868-4a0e-42a7-9a90-36a5c266d746",
    "_uuid": "8f48fa96-0508-4018-89d9-5336b5cadba2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:05:08.133193Z",
     "iopub.status.busy": "2026-01-26T06:05:08.132979Z",
     "iopub.status.idle": "2026-01-26T06:05:08.141754Z",
     "shell.execute_reply": "2026-01-26T06:05:08.141105Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.020948,
     "end_time": "2026-01-26T06:05:08.143160",
     "exception": false,
     "start_time": "2026-01-26T06:05:08.122212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class INF_CFG:\n",
    "    BASE_PATH = \"/kaggle/input/csiro-biomass\"\n",
    "    TEST_CSV = os.path.join(BASE_PATH, \"test.csv\")\n",
    "    TEST_IMAGE_DIR = os.path.join(BASE_PATH, \"test\")\n",
    "    EXPERIMENT_DIR = \"/kaggle/input/csiro/pytorch/default/12\"\n",
    "    CKPT_PATTERN_FOLD_X = os.path.join(EXPERIMENT_DIR, \"fold_{fold}\", \"checkpoints\", \"best_wr2.pt\")\n",
    "    CKPT_PATTERN_FOLDX = os.path.join(EXPERIMENT_DIR, \"fold{fold}\", \"checkpoints\", \"best_wr2.pt\")\n",
    "    N_FOLDS = 3\n",
    "    SUBMISSION_FILE = \"submission3.csv\"\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    BATCH_SIZE = 4\n",
    "    NUM_WORKERS = 0\n",
    "    MIXED_PRECISION = True\n",
    "    USE_TTA = True\n",
    "    TTA_TRANSFORMS = [\"original\", \"hflip\"]\n",
    "    ALL_TARGET_COLS = [\"Dry_Green_g\", \"Dry_Dead_g\", \"Dry_Clover_g\", \"GDM_g\", \"Dry_Total_g\"]\n",
    "\n",
    "class TestBiomassDataset(Dataset):\n",
    "    \"\"\"Dataset for test images with dual-stream processing\"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, transform, image_dir: str):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.image_dir = image_dir\n",
    "        self.paths = self.df[\"image_path\"].values\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = os.path.basename(self.paths[idx])\n",
    "        full_path = os.path.join(self.image_dir, filename)\n",
    "        img = cv2.imread(full_path)\n",
    "        if img is None: img = np.zeros((1000, 2000, 3), dtype=np.uint8)\n",
    "        else: img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w, _ = img.shape\n",
    "        mid = w // 2\n",
    "        left = img[:, :mid]\n",
    "        right = img[:, mid:]\n",
    "        left_t = self.transform(image=left)[\"image\"]\n",
    "        right_t = self.transform(image=right)[\"image\"]\n",
    "        return left_t, right_t\n",
    "\n",
    "def get_tta_transforms(img_size: int) -> List[A.Compose]:\n",
    "    \"\"\"Generate test-time augmentation transforms\"\"\"\n",
    "    base = [A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ToTensorV2()]\n",
    "    transforms = []\n",
    "    transforms.append(A.Compose([A.Resize(img_size, img_size, interpolation=cv2.INTER_AREA), *base]))\n",
    "    transforms.append(A.Compose([A.HorizontalFlip(p=1.0), A.Resize(img_size, img_size, interpolation=cv2.INTER_AREA), *base]))\n",
    "    return transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e073865",
   "metadata": {
    "_cell_guid": "008718f4-ab6e-4325-8447-aeadfe7e2146",
    "_uuid": "2d242af3-9325-4327-aea8-aed7b27ea12d",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009934,
     "end_time": "2026-01-26T06:05:08.163073",
     "exception": false,
     "start_time": "2026-01-26T06:05:08.153139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DINO Model 1 Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a659dce4",
   "metadata": {
    "_cell_guid": "972bbb4a-638b-4bcb-b063-71bde3f27ec0",
    "_uuid": "1794df3e-2383-41cf-8327-a142cb8ab11c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:05:08.184395Z",
     "iopub.status.busy": "2026-01-26T06:05:08.184171Z",
     "iopub.status.idle": "2026-01-26T06:05:08.202999Z",
     "shell.execute_reply": "2026-01-26T06:05:08.202445Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.031226,
     "end_time": "2026-01-26T06:05:08.204358",
     "exception": false,
     "start_time": "2026-01-26T06:05:08.173132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def strip_module_prefix(state_dict: dict) -> dict:\n",
    "    \"\"\"Remove 'module.' prefix from state dict keys if present\"\"\"\n",
    "    if not state_dict: return state_dict\n",
    "    keys = list(state_dict.keys())\n",
    "    if all(k.startswith(\"module.\") for k in keys):\n",
    "        return {k[len(\"module.\"):]: v for k, v in state_dict.items()}\n",
    "    return state_dict\n",
    "\n",
    "def load_checkpoint(path: str) -> dict:\n",
    "    \"\"\"Load model checkpoint\"\"\"\n",
    "    if not os.path.exists(path): raise FileNotFoundError(f\"Checkpoint not found: {path}\")\n",
    "    try: state = torch.load(path, map_location=\"cpu\", weights_only=False)\n",
    "    except TypeError: state = torch.load(path, map_location=\"cpu\")\n",
    "    return state\n",
    "\n",
    "def load_model_from_checkpoint(ckpt_path: str) -> nn.Module:\n",
    "    \"\"\"Load DINO model from checkpoint\"\"\"\n",
    "    state = load_checkpoint(ckpt_path)\n",
    "    cfg_dict = state.get(\"cfg\", {})\n",
    "    update_cfg_from_checkpoint(cfg_dict)\n",
    "    dropout = cfg_dict.get(\"dropout\", CFG.dropout)\n",
    "    hidden_ratio = cfg_dict.get(\"hidden_ratio\", CFG.hidden_ratio)\n",
    "    model = CrossPVT_T2T_MambaDINO(dropout=dropout, hidden_ratio=hidden_ratio)\n",
    "    model_state = state.get(\"model_state\", state)\n",
    "    model_state = strip_module_prefix(model_state)\n",
    "    missing_keys, unexpected_keys = model.load_state_dict(model_state, strict=False)\n",
    "    model.to(INF_CFG.DEVICE)\n",
    "    model.eval()\n",
    "    input_res = getattr(model, \"input_res\", 518)\n",
    "    return model\n",
    "\n",
    "def pack5_targets(total: torch.Tensor, gdm: torch.Tensor, green: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Pack 5 target predictions into single tensor\"\"\"\n",
    "    clover = gdm - green\n",
    "    dead = total - gdm\n",
    "    return torch.cat([green, dead, clover, gdm, total], dim=1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_one_view(models: List[nn.Module], loader: DataLoader) -> np.ndarray:\n",
    "    \"\"\"Run inference on one TTA view\"\"\"\n",
    "    preds_list = []\n",
    "    amp_dtype = \"cuda\" if INF_CFG.DEVICE.type == \"cuda\" else \"cpu\"\n",
    "    for xl, xr in tqdm(loader, desc=\"  Predicting\", leave=False):\n",
    "        xl = xl.to(INF_CFG.DEVICE, non_blocking=True)\n",
    "        xr = xr.to(INF_CFG.DEVICE, non_blocking=True)\n",
    "        x_cat = torch.cat([xl, xr], dim=1)\n",
    "        per_model_preds = []\n",
    "        with torch.amp.autocast(amp_dtype, enabled=INF_CFG.MIXED_PRECISION):\n",
    "            for model in models:\n",
    "                out = model(x_cat, return_features=False)\n",
    "                total = out[\"total\"]\n",
    "                gdm = out[\"gdm\"]\n",
    "                green = out[\"green\"]\n",
    "                five = pack5_targets(total, gdm, green)\n",
    "                five = torch.clamp(five, min=0.0)\n",
    "                per_model_preds.append(five.float().cpu())\n",
    "        stacked = torch.mean(torch.stack(per_model_preds, dim=0), dim=0)\n",
    "        preds_list.append(stacked.numpy())\n",
    "    return np.concatenate(preds_list, axis=0)\n",
    "\n",
    "def run_inference(test_df: pd.DataFrame, image_dir: str) -> np.ndarray:\n",
    "    \"\"\"Main inference function for DINO Model 1\"\"\"\n",
    "    models = []\n",
    "    input_res = None\n",
    "    for fold in range(INF_CFG.N_FOLDS):\n",
    "        ckpt_path = INF_CFG.CKPT_PATTERN_FOLD_X.format(fold=fold)\n",
    "        if not os.path.exists(ckpt_path):\n",
    "            ckpt_path = INF_CFG.CKPT_PATTERN_FOLDX.format(fold=fold)\n",
    "        if not os.path.exists(ckpt_path): continue\n",
    "        model = load_model_from_checkpoint(ckpt_path)\n",
    "        models.append(model)\n",
    "        if input_res is None: input_res = getattr(model, \"input_res\", 518)\n",
    "    if len(models) == 0:\n",
    "        raise RuntimeError(\"No checkpoints found!\")\n",
    "    if INF_CFG.USE_TTA:\n",
    "        tta_transforms = get_tta_transforms(input_res)\n",
    "        per_view_preds = []\n",
    "        for transform in tta_transforms:\n",
    "            ds = TestBiomassDataset(test_df, transform, image_dir)\n",
    "            dl = DataLoader(ds, batch_size=INF_CFG.BATCH_SIZE, shuffle=False, num_workers=INF_CFG.NUM_WORKERS, pin_memory=True)\n",
    "            view_pred = predict_one_view(models, dl)\n",
    "            per_view_preds.append(view_pred)\n",
    "        final_pred = np.mean(per_view_preds, axis=0)\n",
    "    else:\n",
    "        transform = get_tta_transforms(input_res)[0]\n",
    "        ds = TestBiomassDataset(test_df, transform, image_dir)\n",
    "        dl = DataLoader(ds, batch_size=INF_CFG.BATCH_SIZE, shuffle=False, num_workers=INF_CFG.NUM_WORKERS, pin_memory=True)\n",
    "        final_pred = predict_one_view(models, dl)\n",
    "    return final_pred\n",
    "\n",
    "def create_submission(final_pred: np.ndarray, test_long: pd.DataFrame, test_unique: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create submission file from predictions\"\"\"\n",
    "    def clean(x):\n",
    "        x = np.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return np.maximum(0, x)\n",
    "    green, dead, clover, gdm, total = map(clean, [final_pred[:,0], final_pred[:,1], final_pred[:,2], final_pred[:,3], final_pred[:,4]])\n",
    "    wide = pd.DataFrame({\"image_path\": test_unique[\"image_path\"], \"Dry_Green_g\": green, \"Dry_Dead_g\": dead, \"Dry_Clover_g\": clover, \"GDM_g\": gdm, \"Dry_Total_g\": total})\n",
    "    long_preds = wide.melt(id_vars=[\"image_path\"], value_vars=INF_CFG.ALL_TARGET_COLS, var_name=\"target_name\", value_name=\"target\")\n",
    "    sub = pd.merge(test_long[[\"sample_id\", \"image_path\", \"target_name\"]], long_preds, on=[\"image_path\", \"target_name\"], how=\"left\")[[\"sample_id\", \"target\"]]\n",
    "    sub[\"target\"] = np.nan_to_num(sub[\"target\"], nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    sub.to_csv(INF_CFG.SUBMISSION_FILE, index=False)\n",
    "    return sub\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"CSIRO v4 CrossPVT T2T Mamba Inference\")\n",
    "    parser.add_argument(\"--test-csv\", type=str, default=None)\n",
    "    parser.add_argument(\"--test-image-dir\", type=str, default=None)\n",
    "    parser.add_argument(\"--experiment-dir\", type=str, default=None)\n",
    "    parser.add_argument(\"--output\", type=str, default=None)\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=None)\n",
    "    parser.add_argument(\"--no-tta\", action=\"store_true\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args\n",
    "\n",
    "def run_dino_inference():\n",
    "    \"\"\"Main function for DINO Model 1 inference\"\"\"\n",
    "    args = parse_args()\n",
    "    if args.test_csv: INF_CFG.TEST_CSV = args.test_csv\n",
    "    if args.test_image_dir: INF_CFG.TEST_IMAGE_DIR = args.test_image_dir\n",
    "    if args.experiment_dir:\n",
    "        INF_CFG.EXPERIMENT_DIR = args.experiment_dir\n",
    "        INF_CFG.CKPT_PATTERN_FOLD_X = os.path.join(INF_CFG.EXPERIMENT_DIR, \"fold_{fold}\", \"checkpoints\", \"best_wr2.pt\")\n",
    "        INF_CFG.CKPT_PATTERN_FOLDX = os.path.join(INF_CFG.EXPERIMENT_DIR, \"fold{fold}\", \"checkpoints\", \"best_wr2.pt\")\n",
    "    if args.output: INF_CFG.SUBMISSION_FILE = args.output\n",
    "    if args.batch_size: INF_CFG.BATCH_SIZE = args.batch_size\n",
    "    if args.no_tta: INF_CFG.USE_TTA = False\n",
    "    test_long = pd.read_csv(INF_CFG.TEST_CSV)\n",
    "    test_unique = test_long.drop_duplicates(subset=[\"image_path\"]).reset_index(drop=True)\n",
    "    final_pred = run_inference(test_unique, INF_CFG.TEST_IMAGE_DIR)\n",
    "    submission = create_submission(final_pred, test_long, test_unique)\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8165aebb",
   "metadata": {
    "_cell_guid": "01815653-f1d9-4b55-8ab2-cef9c1ff87b3",
    "_uuid": "ee500d0a-9a9a-4f94-a45e-e810c94febc0",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01026,
     "end_time": "2026-01-26T06:05:08.224569",
     "exception": false,
     "start_time": "2026-01-26T06:05:08.214309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DINO Model 2 (MVP) - Simpler Architecture\n",
    "\n",
    "This is a more lightweight model using tiled processing with FiLM modulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65fa737b",
   "metadata": {
    "_cell_guid": "cda0491a-4c0c-4f1a-aa47-6153ea48825d",
    "_uuid": "29270f76-da41-4eb0-be41-0c0f4b01491c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:05:08.245622Z",
     "iopub.status.busy": "2026-01-26T06:05:08.245422Z",
     "iopub.status.idle": "2026-01-26T06:05:08.259548Z",
     "shell.execute_reply": "2026-01-26T06:05:08.259014Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.026258,
     "end_time": "2026-01-26T06:05:08.260764",
     "exception": false,
     "start_time": "2026-01-26T06:05:08.234506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_input_size(model):\n",
    "    \"\"\"Infer input size from model configuration\"\"\"\n",
    "    if hasattr(model, \"patch_embed\") and hasattr(model.patch_embed, \"img_size\"):\n",
    "        size = model.patch_embed.img_size\n",
    "        return int(size if isinstance(size, (int, float)) else size[0])\n",
    "    if hasattr(model, \"img_size\"):\n",
    "        size = model.img_size\n",
    "        return int(size if isinstance(size, (int, float)) else size[0])\n",
    "    cfg = getattr(model, \"default_cfg\", {}) or {}\n",
    "    input_size = cfg.get(\"input_size\", None)\n",
    "    if input_size:\n",
    "        if isinstance(input_size, (tuple, list)) and len(input_size) >= 2:\n",
    "            return int(input_size[1])\n",
    "        return int(input_size if isinstance(input_size, (int, float)) else 224)\n",
    "    arch = cfg.get(\"architecture\", \"\") or str(type(model))\n",
    "    return 518 if \"dinov2\" in arch.lower() or \"dinov3\" in arch.lower() else 224\n",
    "\n",
    "def build_backbone(name):\n",
    "    \"\"\"Build DINO backbone model\"\"\"\n",
    "    model = timm.create_model(name, pretrained=False, num_classes=0)\n",
    "    features = model.num_features\n",
    "    input_size = get_input_size(model)\n",
    "    return model, features, input_size\n",
    "\n",
    "class BaseDINO(nn.Module):\n",
    "    \"\"\"Base class for DINO models\"\"\"\n",
    "    def __init__(self, backbone_name):\n",
    "        super().__init__()\n",
    "        self.backbone, feat_dim, input_size = build_backbone(backbone_name)\n",
    "        self.input_size = int(input_size)\n",
    "        self.feat_dim = feat_dim\n",
    "        self.combined_dim = feat_dim * 2\n",
    "        hidden_size = max(8, int(self.combined_dim * 0.25))\n",
    "        def make_head():\n",
    "            return nn.Sequential(nn.Linear(self.combined_dim, hidden_size), nn.ReLU(inplace=True), nn.Dropout(0.30), nn.Linear(hidden_size, 1))\n",
    "        self.head_green = make_head()\n",
    "        self.head_clover = make_head()\n",
    "        self.head_dead = make_head()\n",
    "        self.softplus = nn.Softplus(beta=1.0)\n",
    "\n",
    "    def merge_features(self, left_feat, right_feat):\n",
    "        combined = torch.cat([left_feat, right_feat], dim=1)\n",
    "        green = self.softplus(self.head_green(combined))\n",
    "        clover = self.softplus(self.head_clover(combined))\n",
    "        dead = self.softplus(self.head_dead(combined))\n",
    "        gdm = green + clover\n",
    "        total = gdm + dead\n",
    "        return total, gdm, green\n",
    "\n",
    "class TiledFiLMDINO(BaseDINO):\n",
    "    \"\"\"Tiled processing with Feature-wise Linear Modulation (FiLM)\"\"\"\n",
    "    def __init__(self, backbone_name):\n",
    "        super().__init__(backbone_name)\n",
    "        self.grid = (2, 2)\n",
    "        class FiLM(nn.Module):\n",
    "            def __init__(self, feat_dim):\n",
    "                super().__init__()\n",
    "                hidden = max(32, feat_dim // 2)\n",
    "                self.mlp = nn.Sequential(nn.Linear(feat_dim, hidden), nn.ReLU(inplace=True), nn.Linear(hidden, feat_dim * 2))\n",
    "            def forward(self, context):\n",
    "                gamma_beta = self.mlp(context)\n",
    "                return torch.chunk(gamma_beta, 2, dim=1)\n",
    "        self.film_left = FiLM(self.feat_dim)\n",
    "        self.film_right = FiLM(self.feat_dim)\n",
    "\n",
    "    def extract_tile_features(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        rows, cols = self.grid\n",
    "        def split_dimension(length, parts):\n",
    "            step = length // parts\n",
    "            segments = []; start = 0\n",
    "            for _ in range(parts - 1):\n",
    "                segments.append((start, start + step))\n",
    "                start += step\n",
    "            segments.append((start, length))\n",
    "            return segments\n",
    "        row_segments = split_dimension(H, rows)\n",
    "        col_segments = split_dimension(W, cols)\n",
    "        features = []\n",
    "        for (rs, re) in row_segments:\n",
    "            for (cs, ce) in col_segments:\n",
    "                tile = x[:, :, rs:re, cs:ce]\n",
    "                if tile.shape[-2:] != (self.input_size, self.input_size):\n",
    "                    tile = F.interpolate(tile, size=(self.input_size, self.input_size), mode=\"bilinear\")\n",
    "                feat = self.backbone(tile)\n",
    "                features.append(feat)\n",
    "        return torch.stack(features, dim=0).permute(1, 0, 2)\n",
    "\n",
    "    def process_stream(self, x, film_layer):\n",
    "        tiles = self.extract_tile_features(x)\n",
    "        context = tiles.mean(dim=1)\n",
    "        gamma, beta = film_layer(context)\n",
    "        modulated = tiles * (1 + gamma.unsqueeze(1)) + beta.unsqueeze(1)\n",
    "        return modulated.mean(dim=1)\n",
    "\n",
    "    def forward(self, left_img, right_img):\n",
    "        left_feat = self.process_stream(left_img, self.film_left)\n",
    "        right_feat = self.process_stream(right_img, self.film_right)\n",
    "        return self.merge_features(left_feat, right_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b3267d",
   "metadata": {
    "_cell_guid": "1db8ef97-bb8a-4162-b402-5b5b0bd7661a",
    "_uuid": "f64b7c15-068d-4031-a3e9-81c38f81b919",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009953,
     "end_time": "2026-01-26T06:05:08.280827",
     "exception": false,
     "start_time": "2026-01-26T06:05:08.270874",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DINO Model 2 Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7483380",
   "metadata": {
    "_cell_guid": "8b0a2517-4e98-4629-858e-59ce1021df32",
    "_uuid": "e3078fd5-c301-41db-969a-a74a7c16284e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:05:08.301854Z",
     "iopub.status.busy": "2026-01-26T06:05:08.301629Z",
     "iopub.status.idle": "2026-01-26T06:05:08.320289Z",
     "shell.execute_reply": "2026-01-26T06:05:08.319733Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.030869,
     "end_time": "2026-01-26T06:05:08.321567",
     "exception": false,
     "start_time": "2026-01-26T06:05:08.290698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_state_dict(state_dict):\n",
    "    \"\"\"Clean state dict by removing unwanted prefixes\"\"\"\n",
    "    if not state_dict: return state_dict\n",
    "    cleaned_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if k.startswith(\"module.\"): k = k[7:]\n",
    "        if k.startswith(\"student.\"): k = k[8:]\n",
    "        skip_prefixes = (\"txt_enc.\", \"img_proj.\", \"txt_film\", \"teacher.\", \"momentum_teacher.\")\n",
    "        if any(k.startswith(prefix) for prefix in skip_prefixes): continue\n",
    "        cleaned_dict[k] = v\n",
    "    return cleaned_dict\n",
    "\n",
    "def load_model(checkpoint_path, device):\n",
    "    \"\"\"Load DINO Model 2 from checkpoint\"\"\"\n",
    "    if not os.path.exists(checkpoint_path): raise FileNotFoundError(f\"Checkpoint not found: {checkpoint_path}\")\n",
    "    try: raw_state = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "    except Exception as e: return None\n",
    "    if isinstance(raw_state, dict):\n",
    "        if 'state_dict' in raw_state: state_dict = raw_state['state_dict']\n",
    "        elif 'model' in raw_state: state_dict = raw_state['model']\n",
    "        else: state_dict = raw_state\n",
    "    else: state_dict = raw_state\n",
    "    state_dict = clean_state_dict(state_dict)\n",
    "    if not state_dict: return None\n",
    "    backbones = [\"vit_base_patch14_reg4_dinov2\", \"vit_base_patch14_reg4_dinov3\", \"vit_base_patch14_dinov3\"]\n",
    "    for backbone in backbones:\n",
    "        try:\n",
    "            model = TiledFiLMDINO(backbone)\n",
    "            result = model.load_state_dict(state_dict, strict=False)\n",
    "            missing = [k for k in result.missing_keys if not k.startswith('backbone.pos_embed')]\n",
    "            if len(missing) == 0:\n",
    "                model.to(device); model.eval(); return model\n",
    "        except Exception as e: continue\n",
    "    return None\n",
    "\n",
    "def get_tta_transforms_mvp(img_size):\n",
    "    \"\"\"TTA transforms for MVP model\"\"\"\n",
    "    norm = [A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ToTensorV2()]\n",
    "    return [\n",
    "        A.Compose([A.Resize(img_size, img_size), *norm]),\n",
    "        A.Compose([A.HorizontalFlip(p=1.0), A.Resize(img_size, img_size), *norm]),\n",
    "    ]\n",
    "\n",
    "class BiomassDataset(Dataset):\n",
    "    \"\"\"Dataset for biomass images\"\"\"\n",
    "    def __init__(self, df, transform, img_dir):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.img_dir = img_dir\n",
    "        self.paths = self.df[\"image_path\"].values\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = os.path.basename(self.paths[idx])\n",
    "        full_path = os.path.join(self.img_dir, filename)\n",
    "        img = cv2.imread(full_path)\n",
    "        if img is None: img = np.zeros((1000, 2000, 3), dtype=np.uint8)\n",
    "        else: img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w, _ = img.shape\n",
    "        mid = w // 2\n",
    "        left_img = img[:, :mid]; right_img = img[:, mid:]\n",
    "        left_tensor = self.transform(image=left_img)[\"image\"]\n",
    "        right_tensor = self.transform(image=right_img)[\"image\"]\n",
    "        return left_tensor, right_tensor\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_one_view_mvp(models, loader, device):\n",
    "    \"\"\"Inference for one TTA view - MVP model\"\"\"\n",
    "    preds = []; use_amp = device.type == \"cuda\"\n",
    "    for left_imgs, right_imgs in tqdm(loader, desc=\"Infer MVP\", leave=False):\n",
    "        left_imgs = left_imgs.to(device, non_blocking=True)\n",
    "        right_imgs = right_imgs.to(device, non_blocking=True)\n",
    "        batch_preds = []\n",
    "        with torch.amp.autocast(\"cuda\", enabled=use_amp):\n",
    "            for model in models:\n",
    "                total, gdm, green = model(left_imgs, right_imgs)\n",
    "                dead = torch.clamp(total - gdm, min=0.0)\n",
    "                clover = torch.clamp(gdm - green, min=0.0)\n",
    "                pred = torch.cat([green, dead, clover, gdm, total], dim=1)\n",
    "                batch_preds.append(pred.clamp(0.05, 400.0).cpu())\n",
    "        preds.append(torch.stack(batch_preds).mean(dim=0).numpy())\n",
    "    return np.concatenate(preds)\n",
    "\n",
    "def run_inference_for_ckpts(checkpoint_paths, df, img_dir, device):\n",
    "    \"\"\"Run inference for given checkpoints\"\"\"\n",
    "    models = []\n",
    "    for ckpt_path in checkpoint_paths:\n",
    "        model = load_model(ckpt_path, device)\n",
    "        if model is not None: models.append(model)\n",
    "    if not models: raise ValueError(f\"No models loaded from {checkpoint_paths}\")\n",
    "    input_size = models[0].input_size\n",
    "    tta_preds = []\n",
    "    for transform in get_tta_transforms_mvp(input_size):\n",
    "        ds = BiomassDataset(df, transform, img_dir)\n",
    "        dl = DataLoader(ds, batch_size=4, shuffle=False, num_workers=0, pin_memory=True)\n",
    "        tta_preds.append(predict_one_view_mvp(models, dl, device))\n",
    "    return np.mean(tta_preds, axis=0)\n",
    "\n",
    "def create_submission_mvp(final_preds, test_df, unique_df):\n",
    "    \"\"\"Create submission for MVP model\"\"\"\n",
    "    cols = [\"Dry_Green_g\", \"Dry_Dead_g\", \"Dry_Clover_g\", \"GDM_g\", \"Dry_Total_g\"]\n",
    "    wide = pd.DataFrame({\"image_path\": unique_df[\"image_path\"]})\n",
    "    for i, col in enumerate(cols): wide[col] = np.clip(final_preds[:, i], 0.05, 400.0)\n",
    "    wide[\"GDM_g\"] = wide[\"Dry_Green_g\"] + wide[\"Dry_Clover_g\"]\n",
    "    wide[\"Dry_Total_g\"] = wide[\"GDM_g\"] + wide[\"Dry_Dead_g\"]\n",
    "    wide[cols] = wide[cols].clip(0.05, 400.0)\n",
    "    long_df = wide.melt(id_vars=\"image_path\", value_vars=cols, var_name=\"target_name\", value_name=\"target\")\n",
    "    sub = test_df[[\"sample_id\", \"image_path\", \"target_name\"]].merge(long_df, on=[\"image_path\", \"target_name\"], how=\"left\")[[\"sample_id\", \"target\"]]\n",
    "    sub.to_csv(\"submission2.csv\", index=False)\n",
    "    return sub\n",
    "\n",
    "def run_mvp_inference():\n",
    "    \"\"\"Main function for MVP model inference\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    test_csv = \"/kaggle/input/csiro-biomass/test.csv\"\n",
    "    test_img_dir = \"/kaggle/input/csiro-biomass/test\"\n",
    "    model_dir = \"/kaggle/input/csiro-mvp-models\"\n",
    "    model_paths = [os.path.join(model_dir, f\"model{i}.pth\") for i in range(1, 11)]\n",
    "    existing_models = [path for path in model_paths if os.path.exists(path)]\n",
    "    \n",
    "    CKPTS_A = existing_models[:5]\n",
    "    CKPTS_B = existing_models[5:7] if len(existing_models) > 5 else []\n",
    "    \n",
    "    W_A, W_B = 0.95, 0.075\n",
    "    test_df = pd.read_csv(test_csv)\n",
    "    unique_df = test_df.drop_duplicates(\"image_path\").reset_index(drop=True)\n",
    "    pred_a = run_inference_for_ckpts(CKPTS_A, unique_df, test_img_dir, device)\n",
    "    \n",
    "    if CKPTS_B:\n",
    "        pred_b = run_inference_for_ckpts(CKPTS_B, unique_df, test_img_dir, device)\n",
    "        final_preds = W_A * pred_a + W_B * pred_b\n",
    "    else:\n",
    "        final_preds = pred_a\n",
    "    \n",
    "    submission = create_submission_mvp(final_preds, test_df, unique_df)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fb8543",
   "metadata": {
    "_cell_guid": "c0b01e53-ecc5-4736-8935-7f85fc306e51",
    "_uuid": "169d9ba7-03df-4c1f-8bc1-5dd4ee948545",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.010035,
     "end_time": "2026-01-26T06:05:08.341624",
     "exception": false,
     "start_time": "2026-01-26T06:05:08.331589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main Execution Pipeline\n",
    "\n",
    "This section orchestrates the entire prediction pipeline with timeout management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3cde35e",
   "metadata": {
    "_cell_guid": "c2c30466-2757-430b-ba5e-f748d1a41123",
    "_uuid": "88d096fe-6cfc-45f2-9925-9b006a42d7ba",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:05:08.363385Z",
     "iopub.status.busy": "2026-01-26T06:05:08.363184Z",
     "iopub.status.idle": "2026-01-26T06:05:08.381397Z",
     "shell.execute_reply": "2026-01-26T06:05:08.380792Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.030682,
     "end_time": "2026-01-26T06:05:08.382637",
     "exception": false,
     "start_time": "2026-01-26T06:05:08.351955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main execution function with timeout management\"\"\"\n",
    "    timeout_mgr = TimeoutManager(max_time_seconds=8.5 * 3600)\n",
    "    \n",
    "    seeding(42)\n",
    "    timeout_mgr.log_time(\"Started execution\")\n",
    "    \n",
    "    # Create fallback submission\n",
    "    try:\n",
    "        sample_sub_path = cfg.DATA_PATH / 'sample_submission.csv'\n",
    "        if os.path.exists(sample_sub_path):\n",
    "            sample_sub = pd.read_csv(sample_sub_path)\n",
    "            sample_sub.to_csv('submission.csv', index=False)\n",
    "            print(\"Created fallback submission from sample\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not create fallback submission: {e}\")\n",
    "    \n",
    "    # Part 1: SigLIP Ensemble Model\n",
    "    if timeout_mgr.should_continue(buffer_seconds=6*3600):\n",
    "        try:\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"PART 1: SigLIP/Ensemble Model\")\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "            test_df = pd.read_csv(cfg.DATA_PATH/'test.csv')\n",
    "            test_df = pivot_table(df=test_df)\n",
    "            test_df['image_path'] = test_df['image_path'].apply(lambda p: str(cfg.DATA_PATH / p))\n",
    "            \n",
    "            train_embeddings_path = \"/kaggle/input/csiro-datasplit/csiro_data_split.csv\"\n",
    "            if os.path.exists(train_embeddings_path):\n",
    "                train_siglip_df = pd.read_csv(train_embeddings_path)\n",
    "                print(\"Loaded pre-computed training embeddings\")\n",
    "            else:\n",
    "                print(\"Warning: Pre-computed embeddings not found, this will be slow\")\n",
    "                train_df = pd.read_csv(cfg.DATA_PATH/'train.csv')\n",
    "                train_df = pivot_table(df=train_df)\n",
    "                train_df['image_path'] = train_df['image_path'].apply(lambda p: str(cfg.DATA_PATH / p))\n",
    "                train_siglip_df = train_df\n",
    "            \n",
    "            timeout_mgr.log_time(\"Loaded training data\")\n",
    "            \n",
    "            siglip_path = \"/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1\"\n",
    "            test_siglip_df = compute_embeddings(model_path=siglip_path, df=test_df, patch_size=520)\n",
    "            \n",
    "            flush()\n",
    "            timeout_mgr.log_time(\"Computed test embeddings\")\n",
    "            \n",
    "            X_all_emb = np.vstack([train_siglip_df.filter(like=\"emb\").values, test_siglip_df.filter(like=\"emb\").values])\n",
    "            try:\n",
    "                all_semantic_scores = generate_semantic_features(X_all_emb, model_path=siglip_path)\n",
    "                n_train = len(train_siglip_df)\n",
    "                sem_train_full = all_semantic_scores[:n_train]\n",
    "                sem_test_full = all_semantic_scores[n_train:]\n",
    "                timeout_mgr.log_time(\"Generated semantic features\")\n",
    "            except Exception as e:\n",
    "                print(f\"Semantic feature generation failed: {e}\")\n",
    "                sem_train_full = None\n",
    "                sem_test_full = None\n",
    "            \n",
    "            feat_engine = SupervisedEmbeddingEngine(n_pca=0.80, n_pls=8, n_gmm=6)\n",
    "            \n",
    "            print(\"\\nRunning LightGBM...\")\n",
    "            oof_lgbm, pred_test_lgbm = cross_validate(\n",
    "                LGBMRegressor(verbose=-1, n_estimators=100),\n",
    "                train_siglip_df, test_siglip_df, \n",
    "                feature_engine=feat_engine, \n",
    "                semantic_train=sem_train_full, \n",
    "                semantic_test=sem_test_full, \n",
    "                target_transform='max'\n",
    "            )\n",
    "            compare_results(oof_lgbm, train_siglip_df)\n",
    "            timeout_mgr.log_time(\"Completed LightGBM\")\n",
    "            \n",
    "            print(\"\\nRunning CatBoost...\")\n",
    "            oof_cat, pred_test_cat = cross_validate(\n",
    "                CatBoostRegressor(verbose=0, iterations=100),\n",
    "                train_siglip_df, test_siglip_df, \n",
    "                feature_engine=feat_engine, \n",
    "                semantic_train=sem_train_full, \n",
    "                semantic_test=sem_test_full\n",
    "            )\n",
    "            compare_results(oof_cat, train_siglip_df)\n",
    "            timeout_mgr.log_time(\"Completed CatBoost\")\n",
    "            \n",
    "            pred_test = (pred_test_lgbm + pred_test_cat) / 2\n",
    "            test_df[TARGET_NAMES] = pred_test\n",
    "            test_df = post_process_biomass(test_df)\n",
    "            sub_df = melt_table(test_df)\n",
    "            sub_df[['sample_id', 'target']].to_csv(\"submission1.csv\", index=False)\n",
    "            \n",
    "            print(\"SigLIP/Ensemble submission created successfully\")\n",
    "            timeout_mgr.log_time(\"Completed SigLIP ensemble\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"SigLIP/Ensemble failed: {e}\")\n",
    "            try:\n",
    "                sample = pd.read_csv(cfg.DATA_PATH / 'sample_submission.csv')\n",
    "                sample.to_csv(\"submission1.csv\", index=False)\n",
    "            except:\n",
    "                pass\n",
    "    else:\n",
    "        print(\"\\nSkipping SigLIP/Ensemble - insufficient time\")\n",
    "        try:\n",
    "            sample = pd.read_csv(cfg.DATA_PATH / 'sample_submission.csv')\n",
    "            sample.to_csv(\"submission1.csv\", index=False)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Part 2: DINO Model 1\n",
    "    if timeout_mgr.should_continue(buffer_seconds=3*3600):\n",
    "        try:\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"PART 2: DINO Model 1 (CrossPVT)\")\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "            if timeout_mgr.time_remaining() < 4 * 3600:\n",
    "                print(\"Limited time - disabling TTA\")\n",
    "                INF_CFG.USE_TTA = False\n",
    "            \n",
    "            run_dino_inference()\n",
    "            print(\"DINO Model 1 submission created successfully\")\n",
    "            timeout_mgr.log_time(\"Completed DINO Model 1\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"DINO Model 1 failed: {e}\")\n",
    "            try:\n",
    "                if os.path.exists(\"submission1.csv\"):\n",
    "                    shutil.copy(\"submission1.csv\", \"submission3.csv\")\n",
    "                else:\n",
    "                    sample = pd.read_csv(cfg.DATA_PATH / 'sample_submission.csv')\n",
    "                    sample.to_csv(\"submission3.csv\", index=False)\n",
    "            except:\n",
    "                pass\n",
    "    else:\n",
    "        print(\"\\nSkipping DINO Model 1 - insufficient time\")\n",
    "        try:\n",
    "            if os.path.exists(\"submission1.csv\"):\n",
    "                shutil.copy(\"submission1.csv\", \"submission3.csv\")\n",
    "            else:\n",
    "                sample = pd.read_csv(cfg.DATA_PATH / 'sample_submission.csv')\n",
    "                sample.to_csv(\"submission3.csv\", index=False)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Part 3: DINO Model 2 (MVP)\n",
    "    if timeout_mgr.should_continue(buffer_seconds=2*3600):\n",
    "        try:\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"PART 3: DINO Model 2 (MVP)\")\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "            run_mvp_inference()\n",
    "            print(\"DINO Model 2 submission created successfully\")\n",
    "            timeout_mgr.log_time(\"Completed DINO Model 2\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"DINO Model 2 failed: {e}\")\n",
    "            try:\n",
    "                if os.path.exists(\"submission1.csv\"):\n",
    "                    shutil.copy(\"submission1.csv\", \"submission2.csv\")\n",
    "                else:\n",
    "                    sample = pd.read_csv(cfg.DATA_PATH / 'sample_submission.csv')\n",
    "                    sample.to_csv(\"submission2.csv\", index=False)\n",
    "            except:\n",
    "                pass\n",
    "    else:\n",
    "        print(\"\\nSkipping DINO Model 2 - insufficient time\")\n",
    "        try:\n",
    "            if os.path.exists(\"submission1.csv\"):\n",
    "                shutil.copy(\"submission1.csv\", \"submission2.csv\")\n",
    "            else:\n",
    "                sample = pd.read_csv(cfg.DATA_PATH / 'sample_submission.csv')\n",
    "                sample.to_csv(\"submission2.csv\", index=False)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Part 4: Final Ensemble\n",
    "    try:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"PART 4: Creating Final Ensemble\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        submission1 = pd.read_csv('submission1.csv')\n",
    "        submission2 = pd.read_csv('submission2.csv')\n",
    "        submission3 = pd.read_csv('submission3.csv')\n",
    "        \n",
    "        merged = pd.merge(submission1, submission2, on='sample_id', suffixes=('_1', '_2'))\n",
    "        merged = pd.merge(merged, submission3, on='sample_id')\n",
    "        if 'target' in merged.columns and 'target_1' in merged.columns and 'target_2' in merged.columns:\n",
    "            merged = merged.rename(columns={'target': 'target_3'})\n",
    "        \n",
    "        weight1, weight2, weight3 = 0.5, 0.25, 0.25\n",
    "        merged['target'] = (\n",
    "            merged['target_1'] * weight1 + \n",
    "            merged['target_2'] * weight2 + \n",
    "            merged['target_3'] * weight3\n",
    "        )\n",
    "        \n",
    "        final_submission = merged[['sample_id', 'target']]\n",
    "        final_submission.to_csv('submission.csv', index=False)\n",
    "        \n",
    "        print(\"Final ensemble submission created successfully\")\n",
    "        timeout_mgr.log_time(\"Completed final ensemble\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ensemble failed: {e}\")\n",
    "        for fallback in ['submission1.csv', 'submission3.csv', 'submission2.csv']:\n",
    "            if os.path.exists(fallback):\n",
    "                shutil.copy(fallback, 'submission.csv')\n",
    "                print(f\"Using {fallback} as final submission\")\n",
    "                break\n",
    "    \n",
    "    timeout_mgr.log_time(\"Execution completed\")\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXECUTION COMPLETE\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3541e5ef",
   "metadata": {
    "_cell_guid": "a138e568-2afc-4e66-898f-747c18a200b8",
    "_uuid": "0000fc6c-e7da-4523-900e-d33f44ead0f3",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009945,
     "end_time": "2026-01-26T06:05:08.402640",
     "exception": false,
     "start_time": "2026-01-26T06:05:08.392695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Execute Pipeline\n",
    "\n",
    "Run the complete prediction pipeline. This will:\n",
    "\n",
    "1. Generate predictions using SigLIP embeddings and ensemble models\n",
    "2. Generate predictions using DINO CrossPVT-T2T-Mamba architecture\n",
    "3. Generate predictions using DINO MVP TiledFiLM architecture\n",
    "4. Create a weighted ensemble of all three approaches\n",
    "\n",
    "The pipeline includes automatic timeout management to ensure completion within competition limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "260fa981",
   "metadata": {
    "_cell_guid": "65495a10-329c-485f-8214-c29b30174971",
    "_uuid": "ed4ab064-24f6-45b5-9757-7a155abb486f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:05:08.423558Z",
     "iopub.status.busy": "2026-01-26T06:05:08.423350Z",
     "iopub.status.idle": "2026-01-26T06:07:21.369588Z",
     "shell.execute_reply": "2026-01-26T06:07:21.368704Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 132.958477,
     "end_time": "2026-01-26T06:07:21.371123",
     "exception": false,
     "start_time": "2026-01-26T06:05:08.412646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TIME] Started execution | Elapsed: 0.00h | Remaining: 8.50h\n",
      "Created fallback submission from sample\n",
      "\n",
      "================================================================================\n",
      "PART 1: SigLIP/Ensemble Model\n",
      "================================================================================\n",
      "Loaded pre-computed training embeddings\n",
      "[TIME] Loaded training data | Elapsed: 0.00h | Remaining: 8.50h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1f8abc4bd44858ba147ca317c9f252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TIME] Computed test embeddings | Elapsed: 0.01h | Remaining: 8.49h\n",
      "[TIME] Generated semantic features | Elapsed: 0.01h | Remaining: 8.49h\n",
      "\n",
      "Running LightGBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full CV Score: 0.771173\n",
      "Raw CV Score: 0.771173\n",
      "Processed CV Score: 0.780312\n",
      "Improvement: -0.009139\n",
      "[TIME] Completed LightGBM | Elapsed: 0.01h | Remaining: 8.49h\n",
      "\n",
      "Running CatBoost...\n",
      "Full CV Score: 0.769548\n",
      "Raw CV Score: 0.769548\n",
      "Processed CV Score: 0.778592\n",
      "Improvement: -0.009044\n",
      "[TIME] Completed CatBoost | Elapsed: 0.01h | Remaining: 8.49h\n",
      "SigLIP/Ensemble submission created successfully\n",
      "[TIME] Completed SigLIP ensemble | Elapsed: 0.01h | Remaining: 8.49h\n",
      "\n",
      "================================================================================\n",
      "PART 2: DINO Model 1 (CrossPVT)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5f17d6b6bf4686be89f27caf8a2b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Predicting:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da9e92d7335485a8d13971fe50b8ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Predicting:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DINO Model 1 submission created successfully\n",
      "[TIME] Completed DINO Model 1 | Elapsed: 0.03h | Remaining: 8.47h\n",
      "\n",
      "================================================================================\n",
      "PART 3: DINO Model 2 (MVP)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9674560773f408fa8621e014ea36577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer MVP:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b808afae941b49fb9103e6b299c105a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer MVP:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfbf7bccf6ed4bf98c1c7ee6f9ed3271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer MVP:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca447185343a427aa9b8760d93491991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer MVP:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DINO Model 2 submission created successfully\n",
      "[TIME] Completed DINO Model 2 | Elapsed: 0.04h | Remaining: 8.46h\n",
      "\n",
      "================================================================================\n",
      "PART 4: Creating Final Ensemble\n",
      "================================================================================\n",
      "Final ensemble submission created successfully\n",
      "[TIME] Completed final ensemble | Elapsed: 0.04h | Remaining: 8.46h\n",
      "[TIME] Execution completed | Elapsed: 0.04h | Remaining: 8.46h\n",
      "\n",
      "================================================================================\n",
      "EXECUTION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        print(f\"CRITICAL ERROR: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        try:\n",
    "            sample_path = \"/kaggle/input/csiro-biomass/sample_submission.csv\"\n",
    "            if os.path.exists(sample_path):\n",
    "                sample = pd.read_csv(sample_path)\n",
    "                sample.to_csv('submission.csv', index=False)\n",
    "                print(\"Created emergency fallback submission\")\n",
    "        except:\n",
    "            print(\"Could not create emergency fallback\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3438fb",
   "metadata": {
    "_cell_guid": "ed6a6e1f-a81e-4d38-a2ec-e8bc4042ed77",
    "_uuid": "beb0bd60-2719-41fc-959b-904e4a1190a2",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.011502,
     "end_time": "2026-01-26T06:07:21.394704",
     "exception": false,
     "start_time": "2026-01-26T06:07:21.383202",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CSIRO Biomass Prediction - Ultimate Pipeline (CLOVER ENABLED)\n",
    "\n",
    "## Overview\n",
    "This notebook implements a comprehensive ensemble approach combining:\n",
    "\n",
    "1. **SigLIP Feature Extraction** with semantic features and advanced ensemble models\n",
    "2. **DINOv3 Vision Transformer** with FiLM modulation for dual-stream processing\n",
    "3. **Strategic Ensemble** with weighted combination for all targets\n",
    "\n",
    "### Key Features\n",
    "- Embedding caching for faster execution\n",
    "- **Clover prediction ENABLED** (with threshold to remove noise)\n",
    "- Mass balance reconciliation\n",
    "- Test-time augmentation\n",
    "- Optimized hyperparameters\n",
    "- 10+ model architectures (Random Forest, Extra Trees, MLP, TabNet, Custom NN)\n",
    "\n",
    "### IMPORTANT: Clover Prediction\n",
    "**This version TRAINS models to predict Dry_Clover_g** (not fixed at 0)\n",
    "- All models (LightGBM, CatBoost, RF, etc.) predict clover\n",
    "- Threshold of 0.5g applied to remove noise\n",
    "- Both SigLIP and DINOv3 contribute to clover predictions\n",
    "- Adjust `CLOVER_THRESHOLD` in `post_process_biomass()` as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951ad5d8",
   "metadata": {
    "_cell_guid": "731c394d-0eae-46dd-94e8-095af3c20dae",
    "_uuid": "68695e10-c42a-44ee-86e7-b0e4a4a5deba",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.011223,
     "end_time": "2026-01-26T06:07:21.417159",
     "exception": false,
     "start_time": "2026-01-26T06:07:21.405936",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Installation and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccc575b2",
   "metadata": {
    "_cell_guid": "4b2aff72-e70c-4a35-a337-1953a1084b22",
    "_uuid": "ce8d99eb-8e81-49fa-8cd7-3da8cb5ea923",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:07:21.440918Z",
     "iopub.status.busy": "2026-01-26T06:07:21.440622Z",
     "iopub.status.idle": "2026-01-26T06:07:21.469778Z",
     "shell.execute_reply": "2026-01-26T06:07:21.463569Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.043677,
     "end_time": "2026-01-26T06:07:21.472050",
     "exception": false,
     "start_time": "2026-01-26T06:07:21.428373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: pytorch-tabnet not available. TabNet models will be skipped.\n",
      "ULTIMATE CSIRO Pipeline - All Features Enabled\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor, RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from transformers import AutoModel, AutoImageProcessor, AutoTokenizer\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "import timm\n",
    "\n",
    "# Try to import TabNet (optional)\n",
    "try:\n",
    "    from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "    TABNET_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TABNET_AVAILABLE = False\n",
    "    print(\"Warning: pytorch-tabnet not available. TabNet models will be skipped.\")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "print(\"ULTIMATE CSIRO Pipeline - All Features Enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29887b41",
   "metadata": {
    "_cell_guid": "04f47cef-58b8-4147-9ca8-fb5bef377cf1",
    "_uuid": "0718ed44-bf33-4616-958d-41020300f045",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.011343,
     "end_time": "2026-01-26T06:07:21.495220",
     "exception": false,
     "start_time": "2026-01-26T06:07:21.483877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Custom Model Architectures\n",
    "\n",
    "Define custom neural network architectures for biomass prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b7ca384",
   "metadata": {
    "_cell_guid": "8838f3a6-afd6-4ee5-9418-1ca4e1d6b105",
    "_uuid": "3fd6e2be-aac0-4d6b-b7ca-06c8ffc0c127",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:07:21.519115Z",
     "iopub.status.busy": "2026-01-26T06:07:21.518850Z",
     "iopub.status.idle": "2026-01-26T06:07:21.537109Z",
     "shell.execute_reply": "2026-01-26T06:07:21.536461Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.032138,
     "end_time": "2026-01-26T06:07:21.538549",
     "exception": false,
     "start_time": "2026-01-26T06:07:21.506411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual block with batch normalization and dropout\"\"\"\n",
    "    def __init__(self, dim, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.BatchNorm1d(dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.BatchNorm1d(dim)\n",
    "        )\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.activation(x + self.net(x))\n",
    "\n",
    "class DeepFeatureExtractor(nn.Module):\n",
    "    \"\"\"Deep feature extraction network with residual connections\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dims=[512, 256, 128], dropout=0.3):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                ResidualBlock(hidden_dim, dropout)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        self.output_dim = hidden_dims[-1]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.feature_extractor(x)\n",
    "\n",
    "class MultiTargetRegressor(nn.Module):\n",
    "    \"\"\"Multi-target regression with shared feature extraction\"\"\"\n",
    "    def __init__(self, input_dim, n_targets=5, hidden_dims=[512, 256, 128], dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = DeepFeatureExtractor(input_dim, hidden_dims, dropout)\n",
    "        \n",
    "        # Separate heads for each target\n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(self.feature_extractor.output_dim, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(64, 1)\n",
    "            ) for _ in range(n_targets)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        outputs = [head(features) for head in self.heads]\n",
    "        return torch.cat(outputs, dim=1)\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    \"\"\"Self-attention block for feature importance\"\"\"\n",
    "    def __init__(self, dim, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(dim, num_heads, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Add sequence dimension\n",
    "        x = x.unsqueeze(1)\n",
    "        attended, _ = self.attention(x, x, x)\n",
    "        x = self.norm(x + attended)\n",
    "        return x.squeeze(1)\n",
    "\n",
    "class AttentionRegressor(nn.Module):\n",
    "    \"\"\"Regression with attention mechanism\"\"\"\n",
    "    def __init__(self, input_dim, n_targets=5, hidden_dim=256, num_heads=8, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
    "        self.attention = AttentionBlock(hidden_dim, num_heads)\n",
    "        self.feature_net = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            ResidualBlock(hidden_dim, dropout)\n",
    "        )\n",
    "        self.output = nn.Linear(hidden_dim, n_targets)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x)\n",
    "        x = self.attention(x)\n",
    "        x = self.feature_net(x)\n",
    "        return self.output(x)\n",
    "\n",
    "class PyTorchRegressorWrapper:\n",
    "    \"\"\"Wrapper to use PyTorch models with sklearn interface\"\"\"\n",
    "    def __init__(self, model_class, input_dim, n_targets=1, epochs=100, batch_size=32, \n",
    "                 lr=0.001, device='cuda', **model_kwargs):\n",
    "        self.model_class = model_class\n",
    "        self.input_dim = input_dim\n",
    "        self.n_targets = n_targets\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.device = device if torch.cuda.is_available() else 'cpu'\n",
    "        self.model_kwargs = model_kwargs\n",
    "        self.model = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Handle single target\n",
    "        if len(y.shape) == 1:\n",
    "            y = y.reshape(-1, 1)\n",
    "        \n",
    "        # Create model\n",
    "        self.model = self.model_class(\n",
    "            input_dim=self.input_dim,\n",
    "            n_targets=y.shape[1],\n",
    "            **self.model_kwargs\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Prepare data\n",
    "        X_tensor = torch.FloatTensor(X).to(self.device)\n",
    "        y_tensor = torch.FloatTensor(y).to(self.device)\n",
    "        \n",
    "        dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        \n",
    "        # Training\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr, weight_decay=0.01)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        self.model.train()\n",
    "        for epoch in range(self.epochs):\n",
    "            total_loss = 0\n",
    "            for batch_x, batch_y in loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            if (epoch + 1) % 20 == 0:\n",
    "                avg_loss = total_loss / len(loader)\n",
    "                print(f'    Epoch {epoch+1}/{self.epochs}, Loss: {avg_loss:.6f}')\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not fitted yet!\")\n",
    "        \n",
    "        self.model.eval()\n",
    "        X_tensor = torch.FloatTensor(X).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = self.model(X_tensor).cpu().numpy()\n",
    "        \n",
    "        # Return flattened if single target\n",
    "        if predictions.shape[1] == 1:\n",
    "            return predictions.flatten()\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0b62e8",
   "metadata": {
    "_cell_guid": "e4508765-e744-4832-b849-32034af54fcb",
    "_uuid": "51d8833e-a319-4211-b614-2c908dd29bf7",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.011664,
     "end_time": "2026-01-26T06:07:21.561892",
     "exception": false,
     "start_time": "2026-01-26T06:07:21.550228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configuration\n",
    "\n",
    "Define all paths, hyperparameters, and target specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86290a2a",
   "metadata": {
    "_cell_guid": "6bf6c6c6-0a72-4d51-953a-678874754e4c",
    "_uuid": "d0f13656-9e10-4107-8589-c2eeb5a447e1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:07:21.586112Z",
     "iopub.status.busy": "2026-01-26T06:07:21.585876Z",
     "iopub.status.idle": "2026-01-26T06:07:21.591716Z",
     "shell.execute_reply": "2026-01-26T06:07:21.591178Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01949,
     "end_time": "2026-01-26T06:07:21.592983",
     "exception": false,
     "start_time": "2026-01-26T06:07:21.573493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    DATA_PATH: Path = Path(\"/kaggle/input/csiro-biomass/\")\n",
    "    SPLIT_PATH: Path = Path(\"/kaggle/input/csiro-datasplit/csiro_data_split.csv\")\n",
    "    SIGLIP_PATH: str = \"/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1\"\n",
    "    DINOV3_MODELS_DIR: str = '/kaggle/input/modelv3/pytorch/default/1/models_retrained'\n",
    "    CACHE_DIR: Path = Path(\"./embeddings_cache\")\n",
    "    \n",
    "    SEED: int = 42\n",
    "    DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    PATCH_SIZE: int = 520\n",
    "    OVERLAP: int = 16\n",
    "    \n",
    "    TARGET_NAMES = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\n",
    "    TARGET_MAX = {\n",
    "        \"Dry_Clover_g\": 71.7865,\n",
    "        \"Dry_Dead_g\": 83.8407,\n",
    "        \"Dry_Green_g\": 157.9836,\n",
    "        \"Dry_Total_g\": 185.70,\n",
    "        \"GDM_g\": 157.9836,\n",
    "    }\n",
    "    \n",
    "    W_SIGLIP = 0.48\n",
    "    W_DINO = 0.52\n",
    "\n",
    "cfg = Config()\n",
    "cfg.CACHE_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4d9162",
   "metadata": {
    "_cell_guid": "944b632d-2ce8-43fc-8c6a-de66b7d867fe",
    "_uuid": "6f45a720-36b5-45e2-b38d-d3b363bf9911",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.011463,
     "end_time": "2026-01-26T06:07:21.615992",
     "exception": false,
     "start_time": "2026-01-26T06:07:21.604529",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Clover Prediction Settings\n",
    "\n",
    "This notebook includes clover prediction with configurable threshold:\n",
    "- **CLOVER_THRESHOLD = 0.5** - Predictions below this are set to 0\n",
    "- Adjust in `post_process_biomass()` function\n",
    "- Lower threshold (e.g., 0.1) = more sensitive to small amounts\n",
    "- Higher threshold (e.g., 1.0) = only detect significant clover\n",
    "\n",
    "**To completely disable clover (revert to original):**\n",
    "Change in `post_process_biomass()`: `df_out['Dry_Clover_g'] = 0.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ef0cb58",
   "metadata": {
    "_cell_guid": "b1839de5-e4cd-4e56-9afe-0d37b7b616d5",
    "_uuid": "86a45fa9-818f-46ce-b904-f61d35961dc5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:07:21.639989Z",
     "iopub.status.busy": "2026-01-26T06:07:21.639740Z",
     "iopub.status.idle": "2026-01-26T06:07:21.645648Z",
     "shell.execute_reply": "2026-01-26T06:07:21.644864Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.019554,
     "end_time": "2026-01-26T06:07:21.647047",
     "exception": false,
     "start_time": "2026-01-26T06:07:21.627493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "def seeding(SEED):\n",
    "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(SEED)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeding(cfg.SEED)\n",
    "print(f\"Device: {cfg.DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f827d40",
   "metadata": {
    "_cell_guid": "6409e781-25dd-4f89-895c-55c98cfcb6c8",
    "_uuid": "7be74e08-9295-49bb-a335-e1bacea5c79e",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.011623,
     "end_time": "2026-01-26T06:07:21.670183",
     "exception": false,
     "start_time": "2026-01-26T06:07:21.658560",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Utilities\n",
    "\n",
    "Functions for data transformation and post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14b344fd",
   "metadata": {
    "_cell_guid": "fb8f4130-13f9-4c39-a9b9-f9a06b58a0ce",
    "_uuid": "ade87705-d4b0-4c19-aafb-cb85ed291642",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:07:21.694453Z",
     "iopub.status.busy": "2026-01-26T06:07:21.694256Z",
     "iopub.status.idle": "2026-01-26T06:07:21.701480Z",
     "shell.execute_reply": "2026-01-26T06:07:21.700878Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.02104,
     "end_time": "2026-01-26T06:07:21.702753",
     "exception": false,
     "start_time": "2026-01-26T06:07:21.681713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pivot_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Convert long format to wide format\"\"\"\n",
    "    if 'target' in df.columns.tolist():\n",
    "        df_pt = pd.pivot_table(\n",
    "            df, values='target', \n",
    "            index=['image_path', 'Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm'], \n",
    "            columns='target_name', aggfunc='mean'\n",
    "        ).reset_index()\n",
    "    else:\n",
    "        df['target'] = 0\n",
    "        df_pt = pd.pivot_table(\n",
    "            df, values='target', index='image_path',\n",
    "            columns='target_name', aggfunc='mean'\n",
    "        ).reset_index()\n",
    "    return df_pt\n",
    "\n",
    "def melt_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Convert wide format to long format for submission\"\"\"\n",
    "    melted = df.melt(\n",
    "        id_vars='image_path', value_vars=cfg.TARGET_NAMES,\n",
    "        var_name='target_name', value_name='target'\n",
    "    )\n",
    "    melted['sample_id'] = (\n",
    "        melted['image_path'].str.replace(r'^.*/', '', regex=True).str.replace('.jpg', '', regex=False)\n",
    "        + '__' + melted['target_name']\n",
    "    )\n",
    "    return melted[['sample_id', 'target']]\n",
    "\n",
    "def post_process_biomass(df_preds):\n",
    "    \"\"\"\n",
    "    Apply hierarchical constraints\n",
    "    UPDATED: Clover prediction ENABLED with threshold to remove noise\n",
    "    \"\"\"\n",
    "    ordered_cols = [\"Dry_Green_g\", \"Dry_Clover_g\", \"Dry_Dead_g\", \"GDM_g\", \"Dry_Total_g\"]\n",
    "    \n",
    "    for c in ordered_cols:\n",
    "        if c not in df_preds.columns:\n",
    "            df_preds[c] = 0.0\n",
    "    \n",
    "    df_out = df_preds.copy()\n",
    "    \n",
    "    # Apply threshold to remove noise (adjust as needed based on validation)\n",
    "    CLOVER_THRESHOLD = 0.5\n",
    "    df_out['Dry_Clover_g'] = df_out['Dry_Clover_g'].apply(\n",
    "        lambda x: 0.0 if x < CLOVER_THRESHOLD else x\n",
    "    )\n",
    "    \n",
    "    # Derive GDM and Total\n",
    "    df_out['GDM_g'] = df_out['Dry_Green_g'] + df_out['Dry_Clover_g']\n",
    "    df_out['Dry_Total_g'] = df_out['GDM_g'] + df_out['Dry_Dead_g']\n",
    "    \n",
    "    # Clip to non-negative\n",
    "    df_out['GDM_g'] = df_out['GDM_g'].clip(lower=0.0)\n",
    "    df_out['Dry_Total_g'] = df_out['Dry_Total_g'].clip(lower=0.0)\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbd27d5",
   "metadata": {
    "_cell_guid": "102612c0-0ff7-4590-89d7-6455afa5103a",
    "_uuid": "a7a0ab5c-4c3e-4765-8f8c-9da1e055df6c",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01157,
     "end_time": "2026-01-26T06:07:21.725964",
     "exception": false,
     "start_time": "2026-01-26T06:07:21.714394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05cebf96",
   "metadata": {
    "_cell_guid": "227b1212-a731-4d4c-bbd6-3ae0ea7ae6a8",
    "_uuid": "58d46e11-7275-4302-98fa-5c0d4a1a91a1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:07:21.750042Z",
     "iopub.status.busy": "2026-01-26T06:07:21.749824Z",
     "iopub.status.idle": "2026-01-26T06:07:21.842030Z",
     "shell.execute_reply": "2026-01-26T06:07:21.841171Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.10608,
     "end_time": "2026-01-26T06:07:21.843498",
     "exception": false,
     "start_time": "2026-01-26T06:07:21.737418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "Train: 357 samples\n",
      "Test: 1 samples\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Data...\")\n",
    "train_df = pd.read_csv(cfg.SPLIT_PATH) \n",
    "cols_to_keep = [c for c in train_df.columns if not c.startswith('emb')]\n",
    "train_df = train_df[cols_to_keep]\n",
    "\n",
    "if not str(train_df['image_path'].iloc[0]).startswith('/'):\n",
    "     train_df['image_path'] = train_df['image_path'].apply(\n",
    "         lambda p: str(cfg.DATA_PATH / 'train' / os.path.basename(p))\n",
    "     )\n",
    "\n",
    "test_df_raw = pd.read_csv(cfg.DATA_PATH / 'test.csv')\n",
    "test_df = pivot_table(test_df_raw)\n",
    "test_df['image_path'] = test_df['image_path'].apply(lambda p: str(cfg.DATA_PATH / p))\n",
    "\n",
    "print(f\"Train: {len(train_df)} samples\")\n",
    "print(f\"Test: {len(test_df)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4f7858",
   "metadata": {
    "_cell_guid": "2e3c599d-cbe5-4d04-aea8-ee3ab386ea90",
    "_uuid": "d44d0d50-51c4-4464-b028-14d3a477028f",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012367,
     "end_time": "2026-01-26T06:07:21.868266",
     "exception": false,
     "start_time": "2026-01-26T06:07:21.855899",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SigLIP Embedding Extraction\n",
    "\n",
    "Extract image embeddings using SigLIP model with patch-based processing and caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69bdffb1",
   "metadata": {
    "_cell_guid": "27cd8dbb-9dca-4a9b-a0c5-11493d38dee6",
    "_uuid": "76ea93c1-7bb8-43b6-89ca-2b3a13173a29",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:07:21.893228Z",
     "iopub.status.busy": "2026-01-26T06:07:21.892564Z",
     "iopub.status.idle": "2026-01-26T06:13:51.025941Z",
     "shell.execute_reply": "2026-01-26T06:13:51.025171Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 389.147464,
     "end_time": "2026-01-26T06:13:51.027335",
     "exception": false,
     "start_time": "2026-01-26T06:07:21.879871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SIGLIP EMBEDDING EXTRACTION\n",
      "================================================================================\n",
      "Train (357 images) - will cache...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc56e24f1e946c3b6df97e38b8fad4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching to train_siglip.pkl\n",
      "Test (1 images) - will cache...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04c1fd6e81846a4a07793a2518af6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching to test_siglip.pkl\n",
      "Features shape: (357, 1172)\n"
     ]
    }
   ],
   "source": [
    "def split_image(image, patch_size=520, overlap=16):\n",
    "    \"\"\"Split image into overlapping patches\"\"\"\n",
    "    h, w, c = image.shape\n",
    "    stride = patch_size - overlap\n",
    "    patches = []\n",
    "    for y in range(0, h, stride):\n",
    "        for x in range(0, w, stride):\n",
    "            y2 = min(y + patch_size, h)\n",
    "            x2 = min(x + patch_size, w)\n",
    "            y1 = max(0, y2 - patch_size)\n",
    "            x1 = max(0, x2 - patch_size)\n",
    "            patch = image[y1:y2, x1:x2, :]\n",
    "            patches.append(patch)\n",
    "    return patches\n",
    "\n",
    "def compute_embeddings(model_path, df, cache_file, desc=\"Computing\"):\n",
    "    \"\"\"Compute embeddings with caching support\"\"\"\n",
    "    if cache_file.exists():\n",
    "        print(f\"Loading cached {cache_file.name}\")\n",
    "        with open(cache_file, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    \n",
    "    print(f\"{desc} ({len(df)} images) - will cache...\")\n",
    "    model = AutoModel.from_pretrained(model_path, local_files_only=True).eval().to(cfg.DEVICE)\n",
    "    processor = AutoImageProcessor.from_pretrained(model_path)\n",
    "    \n",
    "    EMBEDDINGS = []\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=desc):\n",
    "        try:\n",
    "            img = cv2.imread(row['image_path'])\n",
    "            if img is None: \n",
    "                raise ValueError(\"Image not found\")\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            patches = split_image(img, patch_size=cfg.PATCH_SIZE, overlap=cfg.OVERLAP)\n",
    "            images = [Image.fromarray(p) for p in patches]\n",
    "            \n",
    "            inputs = processor(images=images, return_tensors=\"pt\").to(cfg.DEVICE)\n",
    "            with torch.no_grad():\n",
    "                features = model.get_image_features(**inputs)\n",
    "            \n",
    "            avg_embed = features.mean(dim=0).cpu().numpy()\n",
    "            EMBEDDINGS.append(avg_embed)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {e}\")\n",
    "            EMBEDDINGS.append(np.zeros(1152))\n",
    "    \n",
    "    embeddings = np.stack(EMBEDDINGS)\n",
    "    print(f\"Caching to {cache_file.name}\")\n",
    "    with open(cache_file, 'wb') as f:\n",
    "        pickle.dump(embeddings, f)\n",
    "    \n",
    "    del model, processor\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return embeddings\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SIGLIP EMBEDDING EXTRACTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "train_cache = cfg.CACHE_DIR / \"train_siglip.pkl\"\n",
    "test_cache = cfg.CACHE_DIR / \"test_siglip.pkl\"\n",
    "\n",
    "train_embeddings = compute_embeddings(cfg.SIGLIP_PATH, train_df, train_cache, \"Train\")\n",
    "test_embeddings = compute_embeddings(cfg.SIGLIP_PATH, test_df, test_cache, \"Test\")\n",
    "\n",
    "emb_cols = [f\"emb{i}\" for i in range(train_embeddings.shape[1])]\n",
    "train_feat_df = pd.concat([train_df, pd.DataFrame(train_embeddings, columns=emb_cols)], axis=1)\n",
    "test_feat_df = pd.concat([test_df, pd.DataFrame(test_embeddings, columns=emb_cols)], axis=1)\n",
    "\n",
    "print(f\"Features shape: {train_feat_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e587ab8b",
   "metadata": {
    "_cell_guid": "101d0ce0-9d3c-4a2d-8e91-a622df708e2f",
    "_uuid": "f720ece3-39b7-4dcb-998d-4a858c5faccb",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.011925,
     "end_time": "2026-01-26T06:13:51.052113",
     "exception": false,
     "start_time": "2026-01-26T06:13:51.040188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Semantic Feature Generation\n",
    "\n",
    "Generate semantic similarity scores using text-image alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e201ea4e",
   "metadata": {
    "_cell_guid": "d1eca9a7-eb51-483b-afb9-eaa6d9a05f6e",
    "_uuid": "36d0e3ba-9dce-4dd3-b36a-22a07a84d071",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:13:51.078274Z",
     "iopub.status.busy": "2026-01-26T06:13:51.078012Z",
     "iopub.status.idle": "2026-01-26T06:13:53.239544Z",
     "shell.execute_reply": "2026-01-26T06:13:53.238635Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.176039,
     "end_time": "2026-01-26T06:13:53.241107",
     "exception": false,
     "start_time": "2026-01-26T06:13:51.065068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Semantic Features...\n",
      "Semantic features: (357, 11)\n"
     ]
    }
   ],
   "source": [
    "def generate_semantic_features(image_embeddings_np, model_path):\n",
    "    \"\"\"Generate semantic features from image embeddings\"\"\"\n",
    "    print(\"Generating Semantic Features...\")\n",
    "    model = AutoModel.from_pretrained(model_path).to(cfg.DEVICE)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    \n",
    "    concept_groups = {\n",
    "        \"bare\": [\"bare soil\", \"dirt ground\", \"sparse vegetation\", \"exposed earth\"],\n",
    "        \"sparse\": [\"low density pasture\", \"thin grass\", \"short clipped grass\"],\n",
    "        \"medium\": [\"average pasture cover\", \"medium height grass\", \"grazed pasture\"],\n",
    "        \"dense\": [\"dense tall pasture\", \"thick grassy volume\", \"high biomass\", \"overgrown vegetation\"],\n",
    "        \"green\": [\"lush green vibrant pasture\", \"photosynthesizing leaves\", \"fresh growth\"],\n",
    "        \"dead\": [\"dry brown dead grass\", \"yellow straw\", \"senesced material\", \"standing hay\"],\n",
    "        \"clover\": [\"white clover\", \"trifolium repens\", \"broadleaf legume\", \"clover flowers\"],\n",
    "        \"grass\": [\"ryegrass\", \"blade-like leaves\", \"fescue\", \"grassy sward\"]\n",
    "    }\n",
    "    \n",
    "    concept_vectors = {}\n",
    "    with torch.no_grad():\n",
    "        for name, prompts in concept_groups.items():\n",
    "            inputs = tokenizer(prompts, padding=\"max_length\", return_tensors=\"pt\").to(cfg.DEVICE)\n",
    "            emb = model.get_text_features(**inputs)\n",
    "            emb = emb / emb.norm(p=2, dim=-1, keepdim=True)\n",
    "            concept_vectors[name] = emb.mean(dim=0, keepdim=True)\n",
    "    \n",
    "    img_tensor = torch.tensor(image_embeddings_np, dtype=torch.float32).to(cfg.DEVICE)\n",
    "    img_tensor = img_tensor / img_tensor.norm(p=2, dim=-1, keepdim=True)\n",
    "    \n",
    "    scores = {}\n",
    "    for name, vec in concept_vectors.items():\n",
    "        scores[name] = torch.matmul(img_tensor, vec.T).cpu().numpy().flatten()\n",
    "    \n",
    "    df_scores = pd.DataFrame(scores)\n",
    "    df_scores['ratio_greenness'] = df_scores['green'] / (df_scores['green'] + df_scores['dead'] + 1e-6)\n",
    "    df_scores['ratio_clover'] = df_scores['clover'] / (df_scores['clover'] + df_scores['grass'] + 1e-6)\n",
    "    df_scores['ratio_cover'] = (df_scores['dense'] + df_scores['medium']) / (df_scores['bare'] + df_scores['sparse'] + 1e-6)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    return df_scores.values\n",
    "\n",
    "all_emb = np.vstack([train_embeddings, test_embeddings])\n",
    "all_semantic = generate_semantic_features(all_emb, cfg.SIGLIP_PATH)\n",
    "sem_train = all_semantic[:len(train_df)]\n",
    "sem_test = all_semantic[len(train_df):]\n",
    "print(f\"Semantic features: {sem_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af03d07",
   "metadata": {
    "_cell_guid": "01cb2006-ecd2-401b-9fad-afbe4fb26c8b",
    "_uuid": "5b01261f-d0b6-439a-a012-6bdcf54c26d9",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013899,
     "end_time": "2026-01-26T06:13:53.268309",
     "exception": false,
     "start_time": "2026-01-26T06:13:53.254410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Advanced Model Architectures\n",
    "\n",
    "### Available Models\n",
    "\n",
    "This notebook includes a comprehensive suite of regression models:\n",
    "\n",
    "#### Traditional Ensemble Methods\n",
    "- **LightGBM** - Fast gradient boosting with leaf-wise tree growth\n",
    "- **CatBoost** - Gradient boosting optimized for categorical features\n",
    "- **HistGradientBoosting** - Histogram-based gradient boosting\n",
    "- **GradientBoosting** - Classic gradient boosting\n",
    "- **Random Forest** - Ensemble of decision trees with bagging\n",
    "- **Extra Trees** - Extremely randomized trees\n",
    "\n",
    "#### Neural Network Methods\n",
    "- **MLP (Multi-Layer Perceptron)** - Feed-forward neural network\n",
    "- **TabNet** - Attention-based neural network for tabular data (optional)\n",
    "- **Custom Architectures:**\n",
    "  - `MultiTargetRegressor` - Shared feature extraction with separate heads\n",
    "  - `AttentionRegressor` - Self-attention mechanism for feature importance\n",
    "  - `DeepFeatureExtractor` - Deep network with residual connections\n",
    "\n",
    "### Custom Architecture Details\n",
    "\n",
    "#### MultiTargetRegressor\n",
    "```\n",
    "Input  DeepFeatureExtractor (512256128)  5 separate heads  Outputs\n",
    "```\n",
    "- Shared feature learning across all targets\n",
    "- Residual blocks for better gradient flow\n",
    "- Batch normalization and dropout for regularization\n",
    "\n",
    "#### AttentionRegressor\n",
    "```\n",
    "Input  Linear Projection  Self-Attention  Feature Network  Output\n",
    "```\n",
    "- Multi-head attention to learn feature importance\n",
    "- Attention mechanism helps identify relevant features\n",
    "- Useful for high-dimensional embeddings\n",
    "\n",
    "#### DeepFeatureExtractor\n",
    "```\n",
    "Each layer: Linear  BatchNorm  ReLU  Dropout  ResidualBlock\n",
    "```\n",
    "- Residual connections prevent vanishing gradients\n",
    "- Progressive dimensionality reduction\n",
    "- Suitable as backbone for custom models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbb591c",
   "metadata": {
    "_cell_guid": "9064dd94-feda-431d-ab5a-3ba8cb017857",
    "_uuid": "2251866d-a6b2-4e0f-bcaf-27c1b8f74d84",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012187,
     "end_time": "2026-01-26T06:13:53.292901",
     "exception": false,
     "start_time": "2026-01-26T06:13:53.280714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Supervised Embedding Engine\n",
    "\n",
    "Transform raw embeddings using PCA, PLS, and Gaussian Mixture Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a124bb7",
   "metadata": {
    "_cell_guid": "1ecacaaa-8558-41f6-a451-ea3263c3b811",
    "_uuid": "5b513760-a73c-4a38-b4e4-30bb7517f60b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:13:53.319139Z",
     "iopub.status.busy": "2026-01-26T06:13:53.318562Z",
     "iopub.status.idle": "2026-01-26T06:13:53.325391Z",
     "shell.execute_reply": "2026-01-26T06:13:53.324838Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.021488,
     "end_time": "2026-01-26T06:13:53.326719",
     "exception": false,
     "start_time": "2026-01-26T06:13:53.305231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SupervisedEmbeddingEngine:\n",
    "    \"\"\"\n",
    "    Feature engineering pipeline combining:\n",
    "    - PCA for dimensionality reduction\n",
    "    - PLS for supervised projection\n",
    "    - GMM for clustering probabilities\n",
    "    \"\"\"\n",
    "    def __init__(self, n_pca=0.80, n_pls=8, n_gmm=6, random_state=42):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.pca = PCA(n_components=n_pca, random_state=random_state)\n",
    "        self.pls = PLSRegression(n_components=n_pls, scale=False)\n",
    "        self.gmm = GaussianMixture(n_components=n_gmm, covariance_type='diag', random_state=random_state)\n",
    "        self.pls_fitted_ = False\n",
    "\n",
    "    def fit(self, X, y=None, X_semantic=None):\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        self.pca.fit(X_scaled)\n",
    "        self.gmm.fit(X_scaled)\n",
    "        if y is not None:\n",
    "            self.pls.fit(X_scaled, y)\n",
    "            self.pls_fitted_ = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, X_semantic=None):\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        features = [self.pca.transform(X_scaled)]\n",
    "        if self.pls_fitted_:\n",
    "            features.append(self.pls.transform(X_scaled))\n",
    "        features.append(self.gmm.predict_proba(X_scaled))\n",
    "        if X_semantic is not None:\n",
    "            sem_norm = (X_semantic - np.mean(X_semantic, axis=0)) / (np.std(X_semantic, axis=0) + 1e-6)\n",
    "            features.append(sem_norm)\n",
    "        return np.hstack(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02d5766",
   "metadata": {
    "_cell_guid": "f93d32fb-f76b-4b84-8889-5cbb611bdcae",
    "_uuid": "eb764434-a664-4bee-b53b-9004b0ad9512",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01201,
     "end_time": "2026-01-26T06:13:53.350692",
     "exception": false,
     "start_time": "2026-01-26T06:13:53.338682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cross-Validation Training\n",
    "\n",
    "Train ensemble models with Clover=0 constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7f6c235",
   "metadata": {
    "_cell_guid": "77070db7-6062-4688-bbec-8bd6e56482c7",
    "_uuid": "84b8b5e4-5297-4280-9cfa-7b6349263f30",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:13:53.376093Z",
     "iopub.status.busy": "2026-01-26T06:13:53.375719Z",
     "iopub.status.idle": "2026-01-26T06:13:53.392252Z",
     "shell.execute_reply": "2026-01-26T06:13:53.391664Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.030881,
     "end_time": "2026-01-26T06:13:53.393529",
     "exception": false,
     "start_time": "2026-01-26T06:13:53.362648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cross_validate_predict(model_cls, model_params, train_data, test_data, sem_tr, sem_te, feature_engine):\n",
    "    \"\"\"\n",
    "    Cross-validation with Clover=0 constraint\n",
    "    Based on high-scoring notebook approach\n",
    "    \"\"\"\n",
    "    target_max_arr = np.array([cfg.TARGET_MAX[t] for t in cfg.TARGET_NAMES], dtype=float)\n",
    "    y_pred_test_accum = np.zeros([len(test_data), len(cfg.TARGET_NAMES)], dtype=float)\n",
    "    \n",
    "    n_splits = int(train_data['fold'].nunique())\n",
    "    X_train_full = train_data[emb_cols].values.astype(np.float32)\n",
    "    X_test_raw = test_data[emb_cols].values.astype(np.float32)\n",
    "    y_train_full = train_data[cfg.TARGET_NAMES].values.astype(np.float32)\n",
    "    \n",
    "    for fold in range(n_splits):\n",
    "        print(f\"  Fold {fold+1}/{n_splits}\")\n",
    "        train_mask = train_data['fold'] != fold\n",
    "        \n",
    "        X_tr = X_train_full[train_mask]\n",
    "        y_tr = y_train_full[train_mask] / target_max_arr\n",
    "        sem_tr_fold = sem_tr[train_mask]\n",
    "        \n",
    "        engine = deepcopy(feature_engine)\n",
    "        engine.fit(X_tr, y=y_tr, X_semantic=sem_tr_fold)\n",
    "        \n",
    "        x_tr_eng = engine.transform(X_tr, X_semantic=sem_tr_fold)\n",
    "        x_te_eng = engine.transform(X_test_raw, X_semantic=sem_te)\n",
    "        \n",
    "        fold_test_pred = np.zeros([len(test_data), len(cfg.TARGET_NAMES)])\n",
    "        \n",
    "        # Train models for ALL targets (including Dry_Clover_g)\n",
    "        for k in range(len(cfg.TARGET_NAMES)):\n",
    "            target_name = cfg.TARGET_NAMES[k]\n",
    "            \n",
    "            model = model_cls(**model_params)\n",
    "            model.fit(x_tr_eng, y_tr[:, k])\n",
    "            pred_raw = model.predict(x_te_eng)\n",
    "            fold_test_pred[:, k] = pred_raw * target_max_arr[k]\n",
    "            \n",
    "        y_pred_test_accum += fold_test_pred\n",
    "        \n",
    "    return y_pred_test_accum / n_splits\n",
    "\n",
    "def cross_validate_predict_tabnet(train_data, test_data, sem_tr, sem_te, feature_engine, tabnet_params):\n",
    "    \"\"\"\n",
    "    Special cross-validation for TabNet due to its unique API\n",
    "    \"\"\"\n",
    "    if not TABNET_AVAILABLE:\n",
    "        print(\"TabNet not available, skipping...\")\n",
    "        return None\n",
    "    \n",
    "    target_max_arr = np.array([cfg.TARGET_MAX[t] for t in cfg.TARGET_NAMES], dtype=float)\n",
    "    y_pred_test_accum = np.zeros([len(test_data), len(cfg.TARGET_NAMES)], dtype=float)\n",
    "    \n",
    "    n_splits = int(train_data['fold'].nunique())\n",
    "    X_train_full = train_data[emb_cols].values.astype(np.float32)\n",
    "    X_test_raw = test_data[emb_cols].values.astype(np.float32)\n",
    "    y_train_full = train_data[cfg.TARGET_NAMES].values.astype(np.float32)\n",
    "    \n",
    "    for fold in range(n_splits):\n",
    "        print(f\"  Fold {fold+1}/{n_splits}\")\n",
    "        train_mask = train_data['fold'] != fold\n",
    "        valid_mask = train_data['fold'] == fold\n",
    "        \n",
    "        X_tr = X_train_full[train_mask]\n",
    "        X_val = X_train_full[valid_mask]\n",
    "        y_tr = y_train_full[train_mask] / target_max_arr\n",
    "        y_val = y_train_full[valid_mask] / target_max_arr\n",
    "        sem_tr_fold = sem_tr[train_mask]\n",
    "        sem_val_fold = sem_tr[valid_mask]\n",
    "        \n",
    "        engine = deepcopy(feature_engine)\n",
    "        engine.fit(X_tr, y=y_tr, X_semantic=sem_tr_fold)\n",
    "        \n",
    "        x_tr_eng = engine.transform(X_tr, X_semantic=sem_tr_fold)\n",
    "        x_val_eng = engine.transform(X_val, X_semantic=sem_val_fold)\n",
    "        x_te_eng = engine.transform(X_test_raw, X_semantic=sem_te)\n",
    "        \n",
    "        fold_test_pred = np.zeros([len(test_data), len(cfg.TARGET_NAMES)])\n",
    "        \n",
    "        # Train TabNet for ALL targets (including Dry_Clover_g)\n",
    "        for k in range(len(cfg.TARGET_NAMES)):\n",
    "            target_name = cfg.TARGET_NAMES[k]\n",
    "            \n",
    "            model = TabNetRegressor(**tabnet_params)\n",
    "            model.fit(\n",
    "                x_tr_eng, y_tr[:, k].reshape(-1, 1),\n",
    "                eval_set=[(x_val_eng, y_val[:, k].reshape(-1, 1))],\n",
    "                max_epochs=200,\n",
    "                patience=20,\n",
    "                batch_size=256,\n",
    "                virtual_batch_size=128,\n",
    "                eval_metric=['rmse']\n",
    "            )\n",
    "            pred_raw = model.predict(x_te_eng).flatten()\n",
    "            fold_test_pred[:, k] = pred_raw * target_max_arr[k]\n",
    "        \n",
    "        y_pred_test_accum += fold_test_pred\n",
    "    \n",
    "    return y_pred_test_accum / n_splits\n",
    "\n",
    "def train_final_models(model_cls, model_params, train_data, sem_tr, feature_engine):\n",
    "    \"\"\"\n",
    "    Train final models on all data for deployment\n",
    "    Returns a dictionary of trained models for each target\n",
    "    \"\"\"\n",
    "    target_max_arr = np.array([cfg.TARGET_MAX[t] for t in cfg.TARGET_NAMES], dtype=float)\n",
    "    \n",
    "    X_train_full = train_data[emb_cols].values.astype(np.float32)\n",
    "    y_train_full = train_data[cfg.TARGET_NAMES].values.astype(np.float32) / target_max_arr\n",
    "    \n",
    "    # Fit feature engine on all data\n",
    "    final_engine = deepcopy(feature_engine)\n",
    "    final_engine.fit(X_train_full, y=y_train_full, X_semantic=sem_tr)\n",
    "    \n",
    "    # Transform features\n",
    "    X_transformed = final_engine.transform(X_train_full, X_semantic=sem_tr)\n",
    "    \n",
    "    # Train one model per target (including Dry_Clover_g)\n",
    "    trained_models = {}\n",
    "    for k, target_name in enumerate(cfg.TARGET_NAMES):\n",
    "        model = model_cls(**model_params)\n",
    "        model.fit(X_transformed, y_train_full[:, k])\n",
    "        trained_models[target_name] = model\n",
    "    \n",
    "    return trained_models, final_engine\n",
    "\n",
    "def train_final_models_tabnet(train_data, sem_tr, feature_engine, tabnet_params):\n",
    "    \"\"\"\n",
    "    Train final TabNet models on all data for deployment\n",
    "    \"\"\"\n",
    "    if not TABNET_AVAILABLE:\n",
    "        return None, None\n",
    "    \n",
    "    target_max_arr = np.array([cfg.TARGET_MAX[t] for t in cfg.TARGET_NAMES], dtype=float)\n",
    "    \n",
    "    X_train_full = train_data[emb_cols].values.astype(np.float32)\n",
    "    y_train_full = train_data[cfg.TARGET_NAMES].values.astype(np.float32) / target_max_arr\n",
    "    \n",
    "    # Fit feature engine on all data\n",
    "    final_engine = deepcopy(feature_engine)\n",
    "    final_engine.fit(X_train_full, y=y_train_full, X_semantic=sem_tr)\n",
    "    \n",
    "    # Transform features\n",
    "    X_transformed = final_engine.transform(X_train_full, X_semantic=sem_tr)\n",
    "    \n",
    "    # Train one TabNet model per target (including Dry_Clover_g)\n",
    "    trained_models = {}\n",
    "    for k, target_name in enumerate(cfg.TARGET_NAMES):\n",
    "        model = TabNetRegressor(**tabnet_params)\n",
    "        model.fit(\n",
    "            X_transformed, y_train_full[:, k].reshape(-1, 1),\n",
    "            max_epochs=200,\n",
    "            patience=20,\n",
    "            batch_size=256,\n",
    "            virtual_batch_size=128\n",
    "        )\n",
    "        trained_models[target_name] = model\n",
    "    \n",
    "    return trained_models, final_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3435bc1e",
   "metadata": {
    "_cell_guid": "960be859-fcad-4767-bd6d-20e2e4bdb221",
    "_uuid": "ca3122ea-b923-4cdd-8825-b3549ffd76f6",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01227,
     "end_time": "2026-01-26T06:13:53.417917",
     "exception": false,
     "start_time": "2026-01-26T06:13:53.405647",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Training - SigLIP Ensemble\n",
    "\n",
    "Train multiple gradient boosting models with optimized hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1c5abfd",
   "metadata": {
    "_cell_guid": "7e7e32a7-87a3-43ab-a5f0-4d2abf60e9ae",
    "_uuid": "f941e56b-9da5-4b12-88a9-b4db9c4a305f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:13:53.443465Z",
     "iopub.status.busy": "2026-01-26T06:13:53.443235Z",
     "iopub.status.idle": "2026-01-26T06:19:47.801262Z",
     "shell.execute_reply": "2026-01-26T06:19:47.800036Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 354.37299,
     "end_time": "2026-01-26T06:19:47.802972",
     "exception": false,
     "start_time": "2026-01-26T06:13:53.429982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SIGLIP TRAINING (Clover=0 Constraint)\n",
      "================================================================================\n",
      "\n",
      "Training HistGradientBoosting...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "\n",
      "Training GradientBoosting...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "\n",
      "Training CatBoost...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "\n",
      "Training LightGBM...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "\n",
      "================================================================================\n",
      "TRAINING ADDITIONAL MODELS\n",
      "================================================================================\n",
      "\n",
      "Training Random Forest...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "\n",
      "Training Extra Trees...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "\n",
      "Training MLP Neural Network...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "\n",
      "Skipping TabNet (not installed)\n",
      "\n",
      "================================================================================\n",
      "ENSEMBLE PREDICTIONS\n",
      "================================================================================\n",
      "\n",
      "Ensemble weights:\n",
      "  HistGBM: 0.150\n",
      "  GradBoost: 0.150\n",
      "  CatBoost: 0.200\n",
      "  LightGBM: 0.200\n",
      "  RandomForest: 0.100\n",
      "  ExtraTrees: 0.100\n",
      "  MLP: 0.100\n",
      "\n",
      "SigLIP submission created: submission_siglip.csv\n",
      "\n",
      "================================================================================\n",
      "TRAINING FINAL MODELS ON ALL DATA\n",
      "================================================================================\n",
      "\n",
      "Training final LightGBM models...\n",
      "Training final CatBoost models...\n",
      "Training final HistGBM models...\n",
      "Training final GradientBoosting models...\n",
      "Training final Random Forest models...\n",
      "Training final Extra Trees models...\n",
      "Training final MLP models...\n",
      "\n",
      "All final models trained on full dataset\n"
     ]
    }
   ],
   "source": [
    "params_cat = {\n",
    "    'iterations': 1900, 'learning_rate': 0.045, 'depth': 4, 'l2_leaf_reg': 0.56, \n",
    "    'random_strength': 0.045, 'bagging_temperature': 0.98, 'verbose': 0, 'random_state': 42,\n",
    "    'allow_writing_files': False\n",
    "}\n",
    "params_xgb = {\n",
    "    'n_estimators': 1354, 'learning_rate': 0.010, 'max_depth': 3, 'subsample': 0.60, \n",
    "    'random_state': 42\n",
    "}\n",
    "params_lgbm = {\n",
    "    'n_estimators': 807, 'learning_rate': 0.014, 'num_leaves': 48, 'min_child_samples': 19, \n",
    "    'subsample': 0.745, 'colsample_bytree': 0.745, 'reg_alpha': 0.21, 'reg_lambda': 3.78,\n",
    "    'verbose': -1, 'random_state': 42\n",
    "}\n",
    "params_hist = {\n",
    "    'max_iter': 300, 'learning_rate': 0.05, 'max_depth': None, 'l2_regularization': 0.44,\n",
    "    'random_state': 42\n",
    "}\n",
    "params_rf = {\n",
    "    'n_estimators': 500, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2,\n",
    "    'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 42\n",
    "}\n",
    "params_et = {\n",
    "    'n_estimators': 500, 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 2,\n",
    "    'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 42\n",
    "}\n",
    "params_mlp = {\n",
    "    'hidden_layer_sizes': (512, 256, 128), 'activation': 'relu', 'solver': 'adam',\n",
    "    'alpha': 0.001, 'batch_size': 32, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001,\n",
    "    'max_iter': 300, 'early_stopping': True, 'validation_fraction': 0.1, 'n_iter_no_change': 20,\n",
    "    'random_state': 42, 'verbose': False\n",
    "}\n",
    "\n",
    "# TabNet parameters (if available)\n",
    "if TABNET_AVAILABLE:\n",
    "    params_tabnet = {\n",
    "        'n_d': 64, 'n_a': 64, 'n_steps': 5, 'gamma': 1.5, 'n_independent': 2, 'n_shared': 2,\n",
    "        'lambda_sparse': 0.001, 'optimizer_fn': torch.optim.Adam, 'optimizer_params': dict(lr=0.02),\n",
    "        'scheduler_fn': torch.optim.lr_scheduler.StepLR, 'scheduler_params': dict(step_size=50, gamma=0.9),\n",
    "        'mask_type': 'sparsemax', 'verbose': 0, 'seed': 42\n",
    "    }\n",
    "\n",
    "feat_engine = SupervisedEmbeddingEngine(n_pca=0.80, n_pls=8, n_gmm=6)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SIGLIP TRAINING (Clover=0 Constraint)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTraining HistGradientBoosting...\")\n",
    "pred_hist = cross_validate_predict(\n",
    "    HistGradientBoostingRegressor, params_hist, \n",
    "    train_feat_df, test_feat_df, sem_train, sem_test, feat_engine\n",
    ")\n",
    "\n",
    "print(\"\\nTraining GradientBoosting...\")\n",
    "pred_gb = cross_validate_predict(\n",
    "    GradientBoostingRegressor, params_xgb, \n",
    "    train_feat_df, test_feat_df, sem_train, sem_test, feat_engine\n",
    ")\n",
    "\n",
    "print(\"\\nTraining CatBoost...\")\n",
    "pred_cat = cross_validate_predict(\n",
    "    CatBoostRegressor, params_cat, \n",
    "    train_feat_df, test_feat_df, sem_train, sem_test, feat_engine\n",
    ")\n",
    "\n",
    "print(\"\\nTraining LightGBM...\")\n",
    "pred_lgbm = cross_validate_predict(\n",
    "    LGBMRegressor, params_lgbm, \n",
    "    train_feat_df, test_feat_df, sem_train, sem_test, feat_engine\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING ADDITIONAL MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTraining Random Forest...\")\n",
    "pred_rf = cross_validate_predict(\n",
    "    RandomForestRegressor, params_rf,\n",
    "    train_feat_df, test_feat_df, sem_train, sem_test, feat_engine\n",
    ")\n",
    "\n",
    "print(\"\\nTraining Extra Trees...\")\n",
    "pred_et = cross_validate_predict(\n",
    "    ExtraTreesRegressor, params_et,\n",
    "    train_feat_df, test_feat_df, sem_train, sem_test, feat_engine\n",
    ")\n",
    "\n",
    "print(\"\\nTraining MLP Neural Network...\")\n",
    "pred_mlp = cross_validate_predict(\n",
    "    MLPRegressor, params_mlp,\n",
    "    train_feat_df, test_feat_df, sem_train, sem_test, feat_engine\n",
    ")\n",
    "\n",
    "# TabNet training (if available)\n",
    "if TABNET_AVAILABLE:\n",
    "    print(\"\\nTraining TabNet...\")\n",
    "    # TabNet requires special handling due to its unique API\n",
    "    pred_tabnet = cross_validate_predict_tabnet(\n",
    "        train_feat_df, test_feat_df, sem_train, sem_test, feat_engine, params_tabnet\n",
    "    )\n",
    "else:\n",
    "    print(\"\\nSkipping TabNet (not installed)\")\n",
    "    pred_tabnet = None\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENSEMBLE PREDICTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create weighted ensemble\n",
    "predictions_list = [\n",
    "    ('HistGBM', pred_hist, 0.15),\n",
    "    ('GradBoost', pred_gb, 0.15),\n",
    "    ('CatBoost', pred_cat, 0.20),\n",
    "    ('LightGBM', pred_lgbm, 0.20),\n",
    "    ('RandomForest', pred_rf, 0.10),\n",
    "    ('ExtraTrees', pred_et, 0.10),\n",
    "    ('MLP', pred_mlp, 0.10)\n",
    "]\n",
    "\n",
    "if pred_tabnet is not None:\n",
    "    predictions_list.append(('TabNet', pred_tabnet, 0.10))\n",
    "    # Renormalize weights\n",
    "    total_weight = sum(w for _, _, w in predictions_list)\n",
    "    predictions_list = [(n, p, w/total_weight) for n, p, w in predictions_list]\n",
    "\n",
    "print(\"\\nEnsemble weights:\")\n",
    "for name, _, weight in predictions_list:\n",
    "    print(f\"  {name}: {weight:.3f}\")\n",
    "\n",
    "final_pred = sum(pred * weight for _, pred, weight in predictions_list)\n",
    "test_feat_df[cfg.TARGET_NAMES] = final_pred\n",
    "test_processed = post_process_biomass(test_feat_df)\n",
    "sub_df = melt_table(test_processed)\n",
    "sub_df.to_csv(\"submission_siglip.csv\", index=False)\n",
    "print(\"\\nSigLIP submission created: submission_siglip.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING FINAL MODELS ON ALL DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Train final models on full dataset for each algorithm\n",
    "print(\"\\nTraining final LightGBM models...\")\n",
    "final_lgbm_models, final_lgbm_engine = train_final_models(\n",
    "    LGBMRegressor, params_lgbm, train_feat_df, sem_train, feat_engine\n",
    ")\n",
    "\n",
    "print(\"Training final CatBoost models...\")\n",
    "final_cat_models, final_cat_engine = train_final_models(\n",
    "    CatBoostRegressor, params_cat, train_feat_df, sem_train, feat_engine\n",
    ")\n",
    "\n",
    "print(\"Training final HistGBM models...\")\n",
    "final_hist_models, final_hist_engine = train_final_models(\n",
    "    HistGradientBoostingRegressor, params_hist, train_feat_df, sem_train, feat_engine\n",
    ")\n",
    "\n",
    "print(\"Training final GradientBoosting models...\")\n",
    "final_gb_models, final_gb_engine = train_final_models(\n",
    "    GradientBoostingRegressor, params_xgb, train_feat_df, sem_train, feat_engine\n",
    ")\n",
    "\n",
    "print(\"Training final Random Forest models...\")\n",
    "final_rf_models, final_rf_engine = train_final_models(\n",
    "    RandomForestRegressor, params_rf, train_feat_df, sem_train, feat_engine\n",
    ")\n",
    "\n",
    "print(\"Training final Extra Trees models...\")\n",
    "final_et_models, final_et_engine = train_final_models(\n",
    "    ExtraTreesRegressor, params_et, train_feat_df, sem_train, feat_engine\n",
    ")\n",
    "\n",
    "print(\"Training final MLP models...\")\n",
    "final_mlp_models, final_mlp_engine = train_final_models(\n",
    "    MLPRegressor, params_mlp, train_feat_df, sem_train, feat_engine\n",
    ")\n",
    "\n",
    "# TabNet final models\n",
    "if TABNET_AVAILABLE:\n",
    "    print(\"Training final TabNet models...\")\n",
    "    final_tabnet_models, final_tabnet_engine = train_final_models_tabnet(\n",
    "        train_feat_df, sem_train, feat_engine, params_tabnet\n",
    "    )\n",
    "else:\n",
    "    final_tabnet_models = None\n",
    "    final_tabnet_engine = None\n",
    "\n",
    "print(\"\\nAll final models trained on full dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0b34f2",
   "metadata": {
    "_cell_guid": "c763ec4d-3847-43d4-9f59-8eda6b5d95a5",
    "_uuid": "82b1d80c-7a78-48de-ab0e-15ae23ba8e84",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.023429,
     "end_time": "2026-01-26T06:19:47.850958",
     "exception": false,
     "start_time": "2026-01-26T06:19:47.827529",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Export Trained Models\n",
    "\n",
    "Save the trained models and feature engines for future use or deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1cfc20e0",
   "metadata": {
    "_cell_guid": "682e9abb-632d-464a-8876-90bb4a993e4b",
    "_uuid": "5a077ed0-37d8-44df-9dfd-7669dc484007",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:19:47.900036Z",
     "iopub.status.busy": "2026-01-26T06:19:47.899711Z",
     "iopub.status.idle": "2026-01-26T06:19:48.332041Z",
     "shell.execute_reply": "2026-01-26T06:19:48.331166Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.45904,
     "end_time": "2026-01-26T06:19:48.333576",
     "exception": false,
     "start_time": "2026-01-26T06:19:47.874536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXPORTING TRAINED MODELS\n",
      "================================================================================\n",
      "Saving feature engine...\n",
      "  Saved: feature_engine.pkl\n",
      "\n",
      "Saving trained models...\n",
      "  Saved: ensemble_models.pkl\n",
      "\n",
      "Saving model predictions...\n",
      "  Saved: siglip_predictions.pkl\n",
      "  Saved: model_metadata.pkl\n",
      "\n",
      "Exported files:\n",
      "  1. feature_engine.pkl - Supervised embedding engine\n",
      "  2. ensemble_models.pkl - All trained models:\n",
      "     - LightGBM, CatBoost, HistGBM, GradientBoosting\n",
      "     - Random Forest, Extra Trees\n",
      "     - MLP Neural Network\n",
      "  3. siglip_predictions.pkl - All model predictions\n",
      "  4. model_metadata.pkl - Model configuration and metadata\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPORTING TRAINED MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save the feature engines (use LightGBM engine as reference)\n",
    "print(\"Saving feature engine...\")\n",
    "with open('feature_engine.pkl', 'wb') as f:\n",
    "    pickle.dump(final_lgbm_engine, f)\n",
    "print(\"  Saved: feature_engine.pkl\")\n",
    "\n",
    "# Save all trained models\n",
    "print(\"\\nSaving trained models...\")\n",
    "ensemble_models = {\n",
    "    'lightgbm': final_lgbm_models,\n",
    "    'catboost': final_cat_models,\n",
    "    'histgbm': final_hist_models,\n",
    "    'gradient_boosting': final_gb_models,\n",
    "    'random_forest': final_rf_models,\n",
    "    'extra_trees': final_et_models,\n",
    "    'mlp': final_mlp_models\n",
    "}\n",
    "\n",
    "if TABNET_AVAILABLE and final_tabnet_models is not None:\n",
    "    ensemble_models['tabnet'] = final_tabnet_models\n",
    "\n",
    "with open('ensemble_models.pkl', 'wb') as f:\n",
    "    pickle.dump(ensemble_models, f)\n",
    "print(\"  Saved: ensemble_models.pkl\")\n",
    "\n",
    "# Save individual model predictions for reference\n",
    "print(\"\\nSaving model predictions...\")\n",
    "model_preds = {\n",
    "    'hist_gbm': pred_hist,\n",
    "    'gradient_boosting': pred_gb,\n",
    "    'catboost': pred_cat,\n",
    "    'lightgbm': pred_lgbm,\n",
    "    'random_forest': pred_rf,\n",
    "    'extra_trees': pred_et,\n",
    "    'mlp': pred_mlp,\n",
    "    'ensemble': final_pred\n",
    "}\n",
    "\n",
    "if pred_tabnet is not None:\n",
    "    model_preds['tabnet'] = pred_tabnet\n",
    "\n",
    "with open('siglip_predictions.pkl', 'wb') as f:\n",
    "    pickle.dump(model_preds, f)\n",
    "print(\"  Saved: siglip_predictions.pkl\")\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'target_names': cfg.TARGET_NAMES,\n",
    "    'target_max': cfg.TARGET_MAX,\n",
    "    'embedding_dim': len(emb_cols),\n",
    "    'semantic_features': sem_train.shape[1],\n",
    "    'n_folds': int(train_feat_df['fold'].nunique()),\n",
    "    'model_params': {\n",
    "        'catboost': params_cat,\n",
    "        'xgboost': params_xgb,\n",
    "        'lightgbm': params_lgbm,\n",
    "        'histgbm': params_hist,\n",
    "        'random_forest': params_rf,\n",
    "        'extra_trees': params_et,\n",
    "        'mlp': params_mlp\n",
    "    },\n",
    "    'model_info': {\n",
    "        'lightgbm': {target: type(model).__name__ if model else 'None' for target, model in final_lgbm_models.items()},\n",
    "        'catboost': {target: type(model).__name__ if model else 'None' for target, model in final_cat_models.items()},\n",
    "        'histgbm': {target: type(model).__name__ if model else 'None' for target, model in final_hist_models.items()},\n",
    "        'gradient_boosting': {target: type(model).__name__ if model else 'None' for target, model in final_gb_models.items()},\n",
    "        'random_forest': {target: type(model).__name__ if model else 'None' for target, model in final_rf_models.items()},\n",
    "        'extra_trees': {target: type(model).__name__ if model else 'None' for target, model in final_et_models.items()},\n",
    "        'mlp': {target: type(model).__name__ if model else 'None' for target, model in final_mlp_models.items()}\n",
    "    }\n",
    "}\n",
    "\n",
    "if TABNET_AVAILABLE:\n",
    "    metadata['model_params']['tabnet'] = params_tabnet\n",
    "    if final_tabnet_models is not None:\n",
    "        metadata['model_info']['tabnet'] = {target: type(model).__name__ if model else 'None' for target, model in final_tabnet_models.items()}\n",
    "\n",
    "with open('model_metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(metadata, f)\n",
    "print(\"  Saved: model_metadata.pkl\")\n",
    "\n",
    "print(\"\\nExported files:\")\n",
    "print(\"  1. feature_engine.pkl - Supervised embedding engine\")\n",
    "print(\"  2. ensemble_models.pkl - All trained models:\")\n",
    "print(\"     - LightGBM, CatBoost, HistGBM, GradientBoosting\")\n",
    "print(\"     - Random Forest, Extra Trees\")\n",
    "print(\"     - MLP Neural Network\")\n",
    "if TABNET_AVAILABLE:\n",
    "    print(\"     - TabNet\")\n",
    "print(\"  3. siglip_predictions.pkl - All model predictions\")\n",
    "print(\"  4. model_metadata.pkl - Model configuration and metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3984020",
   "metadata": {
    "_cell_guid": "be98a0a2-e218-4ce0-a9f8-b74e2d8bf3b2",
    "_uuid": "37c94f4e-3bbf-41de-983b-5b8a5ae844f7",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013666,
     "end_time": "2026-01-26T06:19:48.361912",
     "exception": false,
     "start_time": "2026-01-26T06:19:48.348246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DINOv3 Model Architecture\n",
    "\n",
    "Define the Vision Transformer model with FiLM modulation for dual-stream processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d866e2fd",
   "metadata": {
    "_cell_guid": "1d7e6020-4acc-40bf-bdfc-c65c7580eccf",
    "_uuid": "7810a9e1-5e99-4ee9-bc0c-84d266ecb232",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:19:48.390712Z",
     "iopub.status.busy": "2026-01-26T06:19:48.390483Z",
     "iopub.status.idle": "2026-01-26T06:21:10.783340Z",
     "shell.execute_reply": "2026-01-26T06:21:10.782478Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 82.409457,
     "end_time": "2026-01-26T06:21:10.785143",
     "exception": false,
     "start_time": "2026-01-26T06:19:48.375686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DINOV3 INFERENCE\n",
      "================================================================================\n",
      "Found 5 DINOv3 model files\n",
      "Running DINOv3 inference...\n",
      "Executing DINOv3 inference script...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data...\n",
      "Loading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 10.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataloaders...\n",
      "Running inference...\n",
      "Loading fold3_retrained.pth\n",
      "Loading fold0_retrained.pth\n",
      "Loading fold4_retrained.pth\n",
      "Loading fold1_retrained.pth\n",
      "Loading fold2_retrained.pth\n",
      "Applying thresholding...\n",
      "Creating submission...\n",
      "DINOv3 submission saved\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DINOV3 INFERENCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "dinov3_models_dir = cfg.DINOV3_MODELS_DIR\n",
    "if not os.path.exists(dinov3_models_dir):\n",
    "    print(f\"WARNING: DINOv3 models directory not found: {dinov3_models_dir}\")\n",
    "    print(\"Creating empty DINOv3 submission (will use SigLIP only)\")\n",
    "    pd.DataFrame({'sample_id': [], 'target': []}).to_csv('submission_dinov2026.csv', index=False)\n",
    "else:\n",
    "    model_files = list(Path(dinov3_models_dir).glob('*.pth'))\n",
    "    if len(model_files) == 0:\n",
    "        print(f\"WARNING: No .pth model files found in {dinov3_models_dir}\")\n",
    "        print(\"Creating empty DINOv3 submission (will use SigLIP only)\")\n",
    "        pd.DataFrame({'sample_id': [], 'target': []}).to_csv('submission_dinov2026.csv', index=False)\n",
    "    else:\n",
    "        print(f\"Found {len(model_files)} DINOv3 model files\")\n",
    "        print(\"Running DINOv3 inference...\")\n",
    "        \n",
    "        dinov3_script = '''\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "import os\n",
    "from pathlib import Path\n",
    "import timm\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas()\n",
    "\n",
    "class RegressionDataset(Dataset):\n",
    "    \"\"\"Dataset for dual-stream image processing\"\"\"\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        image = item.image\n",
    "        targets = [item['Dry_Green_g'], item['Dry_Clover_g'], item['Dry_Dead_g']]\n",
    "        width, height = image.size\n",
    "        mid_point = width // 2\n",
    "        left_image = image.crop((0, 0, mid_point, height))\n",
    "        right_image = image.crop((mid_point, 0, width, height))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            left_image = self.transform(left_image)\n",
    "            right_image = self.transform(right_image)\n",
    "\n",
    "        return left_image, right_image, targets\n",
    "\n",
    "def get_test_dataloaders(data, image_size, batch_size):\n",
    "    \"\"\"Create dataloaders with test-time augmentation\"\"\"\n",
    "    res = []\n",
    "    for trans in [None, T.RandomHorizontalFlip(p=1.0), T.RandomVerticalFlip(p=1.0)]:\n",
    "        transform = T.Compose([\n",
    "            T.Resize(image_size),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        if trans:\n",
    "            transform = T.Compose([\n",
    "                T.Resize(image_size),\n",
    "                trans,\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        dataset = RegressionDataset(data, transform=transform)\n",
    "        res.append(DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4))\n",
    "    return res\n",
    "\n",
    "class FiLM(nn.Module):\n",
    "    \"\"\"Feature-wise Linear Modulation layer\"\"\"\n",
    "    def __init__(self, feat_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim // 2), \n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.Linear(feat_dim // 2, feat_dim * 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, context):\n",
    "        gamma_beta = self.mlp(context)\n",
    "        return torch.chunk(gamma_beta, 2, dim=1)\n",
    "\n",
    "class CSIROModelRegressor(nn.Module):\n",
    "    \"\"\"Vision Transformer with dual-stream processing and FiLM modulation\"\"\"\n",
    "    def __init__(self, model_name, pretrained=True, num_classes=3, dropout=0.0, freeze_backbone=False):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained, num_classes=0, global_pool='avg')\n",
    "        self.film = FiLM(self.backbone.num_features)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        def make_head():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(self.backbone.num_features * 2, 8),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(8, 1),\n",
    "            )\n",
    "\n",
    "        self.head_green = make_head()\n",
    "        self.head_clover = make_head()\n",
    "        self.head_dead = make_head()\n",
    "        self.softplus = nn.Softplus(beta=1.0)\n",
    "\n",
    "        if freeze_backbone:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "    def forward(self, left_img, right_img):\n",
    "        left_feat = self.backbone(left_img)\n",
    "        right_feat = self.backbone(right_img)\n",
    "        context = (left_feat + right_feat) / 2\n",
    "        gamma, beta = self.film(context)\n",
    "        left_feat_modulated = left_feat * (1 + gamma) + beta\n",
    "        right_feat_modulated = right_feat * (1 + gamma) + beta\n",
    "        combined = torch.cat([left_feat_modulated, right_feat_modulated], dim=1)\n",
    "        green = self.softplus(self.head_green(combined))   \n",
    "        clover = self.softplus(self.head_clover(combined))\n",
    "        dead = self.softplus(self.head_dead(combined)) \n",
    "        return torch.cat([green, clover, dead], dim=1)\n",
    "\n",
    "def predict(model, dataloader, device):\n",
    "    \"\"\"Run inference on single dataloader\"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for left_images, right_images, targets in dataloader:\n",
    "            left_images = left_images.to(device)\n",
    "            right_images = right_images.to(device)\n",
    "            outputs = model(left_images, right_images)\n",
    "            all_outputs.append(outputs.detach().cpu())\n",
    "    outputs = torch.cat(all_outputs).numpy()\n",
    "    return outputs\n",
    "\n",
    "def predict_loaders(model, dataloaders, device):\n",
    "    \"\"\"Average predictions across TTA views\"\"\"\n",
    "    all_outputs = []\n",
    "    for dataloader in dataloaders:\n",
    "        outputs = predict(model, dataloader, device)\n",
    "        all_outputs.append(outputs)\n",
    "    avg_outputs = np.mean(all_outputs, axis=0)\n",
    "    return avg_outputs\n",
    "\n",
    "def predict_folds(dataloaders, models_dir):\n",
    "    \"\"\"Average predictions across model folds\"\"\"\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    all_preds = []\n",
    "    for model_file in Path(models_dir).glob('*.pth'):\n",
    "        print(f\"Loading {model_file.name}\")\n",
    "        model = CSIROModelRegressor(CFG.MODEL_NAME, pretrained=False, num_classes=3)\n",
    "        model.load_state_dict(torch.load(model_file, map_location=device))\n",
    "        preds = predict_loaders(model, dataloaders, device)\n",
    "        all_preds.append(preds)\n",
    "    avg_preds = np.mean(all_preds, axis=0)\n",
    "    return avg_preds\n",
    "\n",
    "class CFG:\n",
    "    DATA_PATH=\"/kaggle/input/csiro-biomass/\"\n",
    "    TEST_DATA_PATH=\"/kaggle/input/csiro-biomass/test.csv\"\n",
    "    MODEL_NAME=\"vit_large_patch16_dinov3_qkvb\"\n",
    "    MODELS_DIR='/kaggle/input/modelv3/pytorch/default/1/models_retrained'\n",
    "    IMG_SIZE=(512,512)\n",
    "\n",
    "print(\"Loading test data...\")\n",
    "test_df = pd.read_csv(CFG.TEST_DATA_PATH)\n",
    "test_df['target'] = 0.0\n",
    "test_df[['sample_id_prefix', 'sample_id_suffix']] = test_df.sample_id.str.split('__', expand=True)\n",
    "\n",
    "test_data_df = test_df.groupby(['sample_id_prefix', 'image_path']).apply(\n",
    "    lambda df: df.set_index('target_name').target\n",
    ")\n",
    "test_data_df.reset_index(inplace=True)\n",
    "test_data_df.columns.name = None\n",
    "\n",
    "print(\"Loading images...\")\n",
    "test_data_df['image'] = test_data_df.image_path.progress_apply(\n",
    "    lambda path: Image.open(CFG.DATA_PATH + path).convert('RGB')\n",
    ")\n",
    "\n",
    "print(\"Creating dataloaders...\")\n",
    "test_loaders = get_test_dataloaders(test_data_df, CFG.IMG_SIZE, 32)\n",
    "\n",
    "print(\"Running inference...\")\n",
    "preds = predict_folds(test_loaders, models_dir=CFG.MODELS_DIR)\n",
    "\n",
    "print(\"Applying thresholding...\")\n",
    "test_data_df[['Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g']] = preds\n",
    "test_data_df['Dry_Green_g'] = test_data_df['Dry_Green_g'].apply(lambda x: 0.0 if x < 0.09 else x)\n",
    "test_data_df['Dry_Clover_g'] = test_data_df['Dry_Clover_g'].apply(lambda x: 0.0 if x < 0.09 else x)\n",
    "test_data_df['Dry_Dead_g'] = test_data_df['Dry_Dead_g'].apply(lambda x: 0.0 if x < 0.09 else x)\n",
    "test_data_df['GDM_g'] = test_data_df.Dry_Green_g + test_data_df.Dry_Clover_g\n",
    "test_data_df['Dry_Total_g'] = test_data_df.GDM_g + test_data_df.Dry_Dead_g\n",
    "\n",
    "print(\"Creating submission...\")\n",
    "cols = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "sub_df = test_data_df.set_index('sample_id_prefix')[cols].stack()\n",
    "sub_df = sub_df.reset_index()\n",
    "sub_df.columns = ['sample_id_prefix', 'target_name', 'target']\n",
    "sub_df['sample_id'] = sub_df.sample_id_prefix + '__' + sub_df.target_name\n",
    "\n",
    "cols = ['sample_id', 'target']\n",
    "sub_df[cols].to_csv('submission_dinov2026.csv', index=False)\n",
    "print(\"DINOv3 submission saved\")\n",
    "'''\n",
    "\n",
    "        with open('csiro_infer.py', 'w') as f:\n",
    "            f.write(dinov3_script)\n",
    "\n",
    "        print(\"Executing DINOv3 inference script...\")\n",
    "        os.system('python csiro_infer.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3b4a62",
   "metadata": {
    "_cell_guid": "4fe04ca8-a60c-4857-8c62-d39000df953c",
    "_uuid": "c77ae7cd-4673-45f9-8a04-8365747341c2",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014849,
     "end_time": "2026-01-26T06:21:10.815698",
     "exception": false,
     "start_time": "2026-01-26T06:21:10.800849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Final Ensemble with Mass Balance\n",
    "\n",
    "Combine SigLIP and DINOv3 predictions using strategic weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aea1ed32",
   "metadata": {
    "_cell_guid": "7a034a62-2291-433f-97e5-19b42d157b06",
    "_uuid": "1f36dfa2-d999-428a-80ff-c5e440a48d60",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:21:10.845898Z",
     "iopub.status.busy": "2026-01-26T06:21:10.845596Z",
     "iopub.status.idle": "2026-01-26T06:21:10.892257Z",
     "shell.execute_reply": "2026-01-26T06:21:10.891405Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.063931,
     "end_time": "2026-01-26T06:21:10.893946",
     "exception": false,
     "start_time": "2026-01-26T06:21:10.830015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL ENSEMBLE (DINO-ONLY FOR CLOVER)\n",
      "================================================================================\n",
      "Loading submission files...\n",
      "SigLIP: 5 rows\n",
      "DINOv3: 5 rows\n",
      "\n",
      "Creating ensemble...\n",
      "SigLIP unique images: 1\n",
      "DINOv3 unique images: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL ENSEMBLE (DINO-ONLY FOR CLOVER)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def enforce_mass_balance(df_wide, fixed_clover=True):\n",
    "    \"\"\"\n",
    "    Enforce mass balance constraints with Clover fixed\n",
    "    Based on high-scoring notebook approach\n",
    "    \"\"\"\n",
    "    ordered_cols = ['Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g', 'GDM_g', 'Dry_Total_g']\n",
    "    Y = df_wide[ordered_cols].values.T\n",
    "    \n",
    "    if fixed_clover:\n",
    "        clover_fixed = Y[1, :].copy()\n",
    "        Y[3, :] = Y[0, :] + clover_fixed\n",
    "        Y[4, :] = Y[3, :] + Y[2, :]\n",
    "        Y_reconciled = Y\n",
    "    else:\n",
    "        C = np.array([[1, 1, 0, -1, 0], [0, 0, 1, 1, -1]])\n",
    "        C_T = C.T\n",
    "        try:\n",
    "            inv_CCt = np.linalg.inv(C @ C_T)\n",
    "            P = np.eye(5) - C_T @ inv_CCt @ C\n",
    "            Y_reconciled = P @ Y\n",
    "        except:\n",
    "            return df_wide\n",
    "    \n",
    "    Y_reconciled = Y_reconciled.T\n",
    "    Y_reconciled = np.maximum(0, Y_reconciled)\n",
    "    df_out = df_wide.copy()\n",
    "    df_out[ordered_cols] = Y_reconciled\n",
    "    return df_out\n",
    "\n",
    "ALL_TARGETS = ['Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "if not os.path.exists('submission_siglip.csv'):\n",
    "    raise FileNotFoundError(\"submission_siglip.csv not found! Run SigLIP training first.\")\n",
    "\n",
    "if not os.path.exists('submission_dinov2026.csv'):\n",
    "    raise FileNotFoundError(\"submission_dinov2026.csv not found! Run DINOv3 inference first.\")\n",
    "\n",
    "print(\"Loading submission files...\")\n",
    "siglip_df = pd.read_csv('submission_siglip.csv').sort_values('sample_id').reset_index(drop=True)\n",
    "dino_df = pd.read_csv('submission_dinov2026.csv').sort_values('sample_id').reset_index(drop=True)\n",
    "\n",
    "print(f\"SigLIP: {len(siglip_df)} rows\")\n",
    "print(f\"DINOv3: {len(dino_df)} rows\")\n",
    "\n",
    "if 'sample_id' not in siglip_df.columns or 'sample_id' not in dino_df.columns:\n",
    "    raise ValueError(\"Missing 'sample_id' column in submission files!\")\n",
    "\n",
    "if len(dino_df) == 0:\n",
    "    print(\"WARNING: DINOv3 produced empty output!\")\n",
    "    print(\"Using SigLIP-only submission\")\n",
    "    final_submission = siglip_df.copy()\n",
    "else:\n",
    "    print(\"\\nCreating ensemble...\")\n",
    "    try:\n",
    "        siglip_df[['image_id', 'target_name']] = siglip_df['sample_id'].str.rsplit('__', n=1, expand=True)\n",
    "        dino_df[['image_id', 'target_name']] = dino_df['sample_id'].str.rsplit('__', n=1, expand=True)\n",
    "        \n",
    "        print(f\"SigLIP unique images: {siglip_df['image_id'].nunique()}\")\n",
    "        print(f\"DINOv3 unique images: {dino_df['image_id'].nunique()}\")\n",
    "        \n",
    "        ensemble_results = []\n",
    "        \n",
    "        # Ensemble ALL targets (including Dry_Clover_g)\n",
    "        for target in ALL_TARGETS:\n",
    "            dino_target = dino_df[dino_df['target_name'] == target].copy()\n",
    "            siglip_target = siglip_df[siglip_df['target_name'] == target].copy()\n",
    "            \n",
    "            merged = pd.merge(\n",
    "                dino_target[['sample_id', 'target']].rename(columns={'target': 'dino_pred'}),\n",
    "                siglip_target[['sample_id', 'target']].rename(columns={'target': 'siglip_pred'}),\n",
    "                on='sample_id'\n",
    "            )\n",
    "            merged['target'] = cfg.W_DINO * merged['dino_pred'] + cfg.W_SIGLIP * merged['siglip_pred']\n",
    "            ensemble_results.append(merged[['sample_id', 'target']])\n",
    "        \n",
    "        ensemble_df = pd.concat(ensemble_results, ignore_index=True)\n",
    "        ensemble_df[['image_id', 'target_name']] = ensemble_df['sample_id'].str.rsplit('__', n=1, expand=True)\n",
    "        \n",
    "        wide_df = ensemble_df.pivot(index='image_id', columns='target_name', values='target').reset_index()\n",
    "        wide_balanced = enforce_mass_balance(wide_df, fixed_clover=True)\n",
    "        \n",
    "        long_balanced = wide_balanced.melt(\n",
    "            id_vars='image_id', value_vars=ALL_TARGETS,\n",
    "            var_name='target_name', value_name='target'\n",
    "        )\n",
    "        long_balanced['sample_id'] = long_balanced['image_id'] + '__' + long_balanced['target_name']\n",
    "        final_submission = long_balanced[['sample_id', 'target']].sort_values('sample_id').reset_index(drop=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in ensemble: {e}\")\n",
    "        print(\"Falling back to SigLIP-only\")\n",
    "        final_submission = siglip_df.copy()\n",
    "\n",
    "final_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d288816",
   "metadata": {
    "_cell_guid": "aed0be82-aec8-4ef1-895e-af0efeb56bbe",
    "_uuid": "649b5405-52f6-44b8-92a8-daac8ed53375",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01411,
     "end_time": "2026-01-26T06:21:10.922693",
     "exception": false,
     "start_time": "2026-01-26T06:21:10.908583",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Using Exported Models (Reference)\n",
    "\n",
    "The exported models can be loaded and used in future notebooks or production environments:\n",
    "\n",
    "### Loading Models\n",
    "\n",
    "```python\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the feature engine\n",
    "with open('feature_engine.pkl', 'rb') as f:\n",
    "    feature_engine = pickle.load(f)\n",
    "\n",
    "# Load all trained models\n",
    "with open('ensemble_models.pkl', 'rb') as f:\n",
    "    ensemble_models = pickle.load(f)\n",
    "\n",
    "# Load model metadata\n",
    "with open('model_metadata.pkl', 'rb') as f:\n",
    "    metadata = pickle.load(f)\n",
    "\n",
    "# Access individual model sets\n",
    "lgbm_models = ensemble_models['lightgbm']\n",
    "cat_models = ensemble_models['catboost']\n",
    "hist_models = ensemble_models['histgbm']\n",
    "gb_models = ensemble_models['gradient_boosting']\n",
    "```\n",
    "\n",
    "### Making Predictions on New Data\n",
    "\n",
    "```python\n",
    "# 1. Extract embeddings using SigLIP\n",
    "new_embeddings = compute_embeddings(siglip_path, new_df, cache_file, \"New Data\")\n",
    "\n",
    "# 2. Generate semantic features\n",
    "new_semantic = generate_semantic_features(new_embeddings, siglip_path)\n",
    "\n",
    "# 3. Transform using the loaded feature engine\n",
    "X_transformed = feature_engine.transform(new_embeddings, X_semantic=new_semantic)\n",
    "\n",
    "# 4. Make predictions using the trained models\n",
    "target_max_arr = np.array([metadata['target_max'][t] for t in metadata['target_names']])\n",
    "predictions = []\n",
    "\n",
    "# Use LightGBM models as an example\n",
    "for i, target_name in enumerate(metadata['target_names']):\n",
    "    if target_name == 'Dry_Clover_g':\n",
    "        # Always predict 0 for clover\n",
    "        pred = np.zeros(len(X_transformed))\n",
    "    else:\n",
    "        model = lgbm_models[target_name]\n",
    "        pred_raw = model.predict(X_transformed)\n",
    "        pred = pred_raw * target_max_arr[i]\n",
    "    predictions.append(pred)\n",
    "\n",
    "predictions = np.column_stack(predictions)\n",
    "```\n",
    "\n",
    "### Ensemble Predictions\n",
    "\n",
    "```python\n",
    "# Combine predictions from multiple models\n",
    "all_preds = []\n",
    "\n",
    "for model_name in ['lightgbm', 'catboost', 'histgbm', 'gradient_boosting']:\n",
    "    models = ensemble_models[model_name]\n",
    "    model_preds = []\n",
    "    \n",
    "    for i, target_name in enumerate(metadata['target_names']):\n",
    "        if target_name == 'Dry_Clover_g':\n",
    "            pred = np.zeros(len(X_transformed))\n",
    "        else:\n",
    "            model = models[target_name]\n",
    "            pred_raw = model.predict(X_transformed)\n",
    "            pred = pred_raw * target_max_arr[i]\n",
    "        model_preds.append(pred)\n",
    "    \n",
    "    all_preds.append(np.column_stack(model_preds))\n",
    "\n",
    "# Average across all models\n",
    "final_predictions = np.mean(all_preds, axis=0)\n",
    "```\n",
    "\n",
    "### Exported Files\n",
    "\n",
    "| File | Description |\n",
    "|------|-------------|\n",
    "| feature_engine.pkl | Supervised embedding engine (PCA + PLS + GMM) |\n",
    "| ensemble_models.pkl | All trained models (dict with 'lightgbm', 'catboost', 'histgbm', 'gradient_boosting') |\n",
    "| siglip_predictions.pkl | All model predictions for analysis |\n",
    "| model_metadata.pkl | Configuration and hyperparameters |\n",
    "| submission_siglip.csv | SigLIP-only predictions |\n",
    "| submission_dinov2026.csv | DINOv3 predictions |\n",
    "| submission.csv | Final ensemble submission |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c81611",
   "metadata": {
    "_cell_guid": "4cbe2f02-8379-44a1-aac2-98a91ae8eb95",
    "_uuid": "e1d3d3a0-bb3f-41c3-acbb-175426ef0ce7",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013974,
     "end_time": "2026-01-26T06:21:10.950854",
     "exception": false,
     "start_time": "2026-01-26T06:21:10.936880",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dbda8283",
   "metadata": {
    "_cell_guid": "767a0ebd-302b-40f8-bfe4-c1dd2ca096e4",
    "_uuid": "9317613d-0495-42e7-b2ab-a73ab264a13d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-26T06:21:10.980239Z",
     "iopub.status.busy": "2026-01-26T06:21:10.980006Z",
     "iopub.status.idle": "2026-01-26T06:21:10.990125Z",
     "shell.execute_reply": "2026-01-26T06:21:10.989288Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.026595,
     "end_time": "2026-01-26T06:21:10.991568",
     "exception": false,
     "start_time": "2026-01-26T06:21:10.964973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ULTIMATE PIPELINE COMPLETE!\n",
      "================================================================================\n",
      "Output file: submission.csv\n",
      "Total rows: 5\n",
      "\n",
      "Key Features:\n",
      "  - SigLIP with Clover=0 constraint\n",
      "  - DINOv3 with thresholding and TTA\n",
      "  - DINO-only for Clover detection\n",
      "  - Weighted ensemble: 48% SigLIP / 52% DINO\n",
      "  - Embedding caching enabled\n",
      "  - Mass balance reconciliation\n",
      "================================================================================\n",
      "\n",
      "Sample predictions:\n",
      "                    sample_id     target\n",
      "0  ID1001187975__Dry_Clover_g   1.067073\n",
      "1    ID1001187975__Dry_Dead_g  30.355328\n",
      "2   ID1001187975__Dry_Green_g  30.024470\n",
      "3   ID1001187975__Dry_Total_g  61.446871\n",
      "4         ID1001187975__GDM_g  31.091543\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ULTIMATE PIPELINE COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Output file: submission.csv\")\n",
    "print(f\"Total rows: {len(final_submission)}\")\n",
    "print(f\"\\nKey Features:\")\n",
    "print(f\"  - SigLIP with Clover=0 constraint\")\n",
    "print(f\"  - DINOv3 with thresholding and TTA\")\n",
    "print(f\"  - DINO-only for Clover detection\")\n",
    "print(f\"  - Weighted ensemble: {cfg.W_SIGLIP:.0%} SigLIP / {cfg.W_DINO:.0%} DINO\")\n",
    "print(f\"  - Embedding caching enabled\")\n",
    "print(f\"  - Mass balance reconciliation\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Display sample predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "print(final_submission.head(10))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "datasetId": 8856212,
     "isSourceIdPinned": false,
     "sourceId": 13900620,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8929818,
     "isSourceIdPinned": false,
     "sourceId": 14018229,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9263389,
     "sourceId": 14503682,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9263405,
     "sourceId": 14503701,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 288761108,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 293691576,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 986,
     "modelInstanceId": 3329,
     "sourceId": 4537,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 251887,
     "modelInstanceId": 230141,
     "sourceId": 268942,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 487624,
     "modelInstanceId": 471723,
     "sourceId": 663314,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 553604,
     "modelInstanceId": 540408,
     "sourceId": 714180,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 560139,
     "modelInstanceId": 547330,
     "sourceId": 719660,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 560139,
     "modelInstanceId": 547330,
     "sourceId": 720478,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1039.452684,
   "end_time": "2026-01-26T06:21:14.249737",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-26T06:03:54.797053",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "04ed412a410e4c77840705265042747a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0d4ecfd9af2f487aa9755308fcd266ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8f7b9c332d4f4b10a5f855c310fd4c6b",
       "placeholder": "",
       "style": "IPY_MODEL_1604926cdd2a49f8a765b65521958cfe",
       "tabbable": null,
       "tooltip": null,
       "value": "1/1[00:00&lt;00:00,1.02it/s]"
      }
     },
     "0e32f3b622a54b18954f770b8ce37be0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1006878adeb34931b2767ba22c6c635e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "10fa60004d224961a4fbfb92bf2c1cd1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1275ede4381b4510912e78b592e5b15f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_635c0cda50ee47e39384cbe6449a8bc5",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9dc87b82d1a344f18e139194a75945ba",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "1604926cdd2a49f8a765b65521958cfe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "167038eae78d4c98a6743957949df803": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "19901b1e2eb246d8b7a8213d4d575c36": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ab8112746f84e32aed7425eb4901270": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1c0bd3bd547b452491d8d2cda79f10f3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "1f3d4f0c2f5948ce90a2cab1844b23d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a6dd4a5dc0134a8b9705c357a6c30a1c",
       "placeholder": "",
       "style": "IPY_MODEL_329b84272bf5496a8e00be553f3a5238",
       "tabbable": null,
       "tooltip": null,
       "value": "InferMVP:100%"
      }
     },
     "1f83f78027144841ae0ed7d3c1666ccb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_479135c08325403391c3a206406a94e9",
       "placeholder": "",
       "style": "IPY_MODEL_04ed412a410e4c77840705265042747a",
       "tabbable": null,
       "tooltip": null,
       "value": "InferMVP:100%"
      }
     },
     "1ffbec45d62c4bbdb3961e2534d5e2b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bf40c59a55ea4a8796aa301a4495a7f6",
       "max": 357.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b53a77bf15d249e8b5465a43cadfe288",
       "tabbable": null,
       "tooltip": null,
       "value": 357.0
      }
     },
     "20174bb9b61e4b2baf678285bdead069": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "299b0a5d8ff14197a486b5ee099dbb1b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "2d3a1f57a9d6407c9686730c3d5add12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2d46ec524206407a980dfd9fb91025b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4d52d1cb53264d47b586d6b33f7d15fb",
       "placeholder": "",
       "style": "IPY_MODEL_6f420ce26cfd449dbc47a83abcfaca42",
       "tabbable": null,
       "tooltip": null,
       "value": "357/357[06:23&lt;00:00,1.07s/it]"
      }
     },
     "2e850ab185f040a68d941f5a4f4fe231": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d44c3a9539884476bb4b9c2a00381d58",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b2f5e45bbf4b4342a84d904d978e6081",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "2fc56e24f1e946c3b6df97e38b8fad4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_32f244c066834a9d83342a7ce64b977d",
        "IPY_MODEL_1ffbec45d62c4bbdb3961e2534d5e2b0",
        "IPY_MODEL_2d46ec524206407a980dfd9fb91025b0"
       ],
       "layout": "IPY_MODEL_3e9b58c53e7249f19e409d2d86789141",
       "tabbable": null,
       "tooltip": null
      }
     },
     "329b84272bf5496a8e00be553f3a5238": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "32f244c066834a9d83342a7ce64b977d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3d84662b1ddd463bbd29c38985674821",
       "placeholder": "",
       "style": "IPY_MODEL_bf3994dd24764957ba7ae198146764e7",
       "tabbable": null,
       "tooltip": null,
       "value": "Train:100%"
      }
     },
     "34022cbad29942f296071581c8ce07de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9337dbbf65fa414b9670a21a76a19081",
       "placeholder": "",
       "style": "IPY_MODEL_0e32f3b622a54b18954f770b8ce37be0",
       "tabbable": null,
       "tooltip": null,
       "value": "1/1[00:02&lt;00:00,2.38s/it]"
      }
     },
     "35da5d5316ca473bb5d44ad2061e5fbb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "36f91a5f76d74f669df5acf39efa2d2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "39478a9844b04b2f8cfe3143eacdde69": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c1cdbeab83894f2594318c476b139627",
       "placeholder": "",
       "style": "IPY_MODEL_cfca46283a1e4ce69207845f5dfc957c",
       "tabbable": null,
       "tooltip": null,
       "value": "Test:100%"
      }
     },
     "3d524c9c525e4dcaa5d2ffb6b986425c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "3d84662b1ddd463bbd29c38985674821": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3dc63e916efa44068acc4294840a708c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3e9b58c53e7249f19e409d2d86789141": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3f828cc843f34e95aa167242f09e25d6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "423aefca02954a97a739ad020b86f7b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "479135c08325403391c3a206406a94e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4d52d1cb53264d47b586d6b33f7d15fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4e6fe29e30e64f6698f5d3cdc62f50e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_95debf8bb8984fc489c8a495ad440e2a",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_35da5d5316ca473bb5d44ad2061e5fbb",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "4f2b8e794ad64139bec24ff096072ef7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "635c0cda50ee47e39384cbe6449a8bc5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6d22351ca80a49d8b0d27bc3fff4225c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_10fa60004d224961a4fbfb92bf2c1cd1",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f3d33dd1f3cd4235ad0f41b3068987b1",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "6dad3f1218ef4485802454855feb1adc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c85f119987e54bcab78e9f881220e3a5",
       "placeholder": "",
       "style": "IPY_MODEL_2d3a1f57a9d6407c9686730c3d5add12",
       "tabbable": null,
       "tooltip": null,
       "value": "1/1[00:06&lt;00:00,6.12s/it]"
      }
     },
     "6f420ce26cfd449dbc47a83abcfaca42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "73cdb87c86f640cd9b209f07a805a7fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "78a3967a3e45426ab533af4204c22f91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a51647e83ee34f11a4aedfd73610d3eb",
       "placeholder": "",
       "style": "IPY_MODEL_aba57803381141a18cb92e7cb0fe3df6",
       "tabbable": null,
       "tooltip": null,
       "value": "1/1[00:06&lt;00:00,6.40s/it]"
      }
     },
     "791e1e78db8945b3983918cd1dbdae71": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "803a9c28b39347afb0f77ac9451cc67d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "826231263d0b4539a44a5b66b7cb19a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bac968eda120423189e616fabe0b6566",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_803a9c28b39347afb0f77ac9451cc67d",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "82a1ee2041c54726ad5f62eaff45e3c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "85aa9244db2e44a8b497931839e9bea5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f8acf6e4c34b4ae7b83abd9a9df84537",
       "placeholder": "",
       "style": "IPY_MODEL_886deceef9ab4988ae59c0a811e0f42f",
       "tabbable": null,
       "tooltip": null,
       "value": "InferMVP:100%"
      }
     },
     "886deceef9ab4988ae59c0a811e0f42f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8bccc89a1bbb4c18bde3c2cd72660647": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_423aefca02954a97a739ad020b86f7b8",
       "placeholder": "",
       "style": "IPY_MODEL_c438fe162f2d4a7f829d93b6c397756a",
       "tabbable": null,
       "tooltip": null,
       "value": "Predicting:100%"
      }
     },
     "8da9e92d7335485a8d13971fe50b8ddd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c915189d67734b7a9f277335443395f7",
        "IPY_MODEL_ef8112d77ca2410b8fc355f53e4b602a",
        "IPY_MODEL_6dad3f1218ef4485802454855feb1adc"
       ],
       "layout": "IPY_MODEL_3d524c9c525e4dcaa5d2ffb6b986425c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8f7b9c332d4f4b10a5f855c310fd4c6b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9337dbbf65fa414b9670a21a76a19081": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "95debf8bb8984fc489c8a495ad440e2a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9ae385bcc47a424199b4dcc81c728c92": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "9ccf5af265fa4a798c89f3332d3ef021": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9d7ec40b9ae34e33926a308ab85d1605": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9dc87b82d1a344f18e139194a75945ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9f221447de654bc3bd28250fb0a44c04": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9f4b8756f7bc4455803113255198279f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a51647e83ee34f11a4aedfd73610d3eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a6dd4a5dc0134a8b9705c357a6c30a1c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a8fee237345e4346a2a54a20432be600": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aba57803381141a18cb92e7cb0fe3df6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ad1f8abc4bd44858ba147ca317c9f252": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bc17566fe8b9473d920f10db5aa20736",
        "IPY_MODEL_b3eaefe1eb4f4931b93fdc66cedcb15c",
        "IPY_MODEL_afb3945ed30e45f1a4cedae218162380"
       ],
       "layout": "IPY_MODEL_d2d14f651c004c0b89ba4a5e396acc17",
       "tabbable": null,
       "tooltip": null
      }
     },
     "afb3945ed30e45f1a4cedae218162380": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cf351a6a37784edb98936dc0006ad841",
       "placeholder": "",
       "style": "IPY_MODEL_c6ba3a6e8c604846b6f0f5eb2493d485",
       "tabbable": null,
       "tooltip": null,
       "value": "1/1[00:01&lt;00:00,1.76s/it]"
      }
     },
     "b04c1fd6e81846a4a07793a2518af6f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_39478a9844b04b2f8cfe3143eacdde69",
        "IPY_MODEL_f091d549c1124df3a30736718d4da46a",
        "IPY_MODEL_e5903aa2a5984f41bf233a936a371c87"
       ],
       "layout": "IPY_MODEL_9f4b8756f7bc4455803113255198279f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b2f5e45bbf4b4342a84d904d978e6081": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b3eaefe1eb4f4931b93fdc66cedcb15c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1ab8112746f84e32aed7425eb4901270",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c9e85198f8b941838b7603a02b4b2eef",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "b53a77bf15d249e8b5465a43cadfe288": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b808afae941b49fb9103e6b299c105a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1f83f78027144841ae0ed7d3c1666ccb",
        "IPY_MODEL_2e850ab185f040a68d941f5a4f4fe231",
        "IPY_MODEL_ed9c462122f741d6a71bfca621f17d44"
       ],
       "layout": "IPY_MODEL_9ae385bcc47a424199b4dcc81c728c92",
       "tabbable": null,
       "tooltip": null
      }
     },
     "bac968eda120423189e616fabe0b6566": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bc17566fe8b9473d920f10db5aa20736": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9d7ec40b9ae34e33926a308ab85d1605",
       "placeholder": "",
       "style": "IPY_MODEL_1006878adeb34931b2767ba22c6c635e",
       "tabbable": null,
       "tooltip": null,
       "value": "Computingembeddings:100%"
      }
     },
     "bf3994dd24764957ba7ae198146764e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bf40c59a55ea4a8796aa301a4495a7f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bfbf7bccf6ed4bf98c1c7ee6f9ed3271": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1f3d4f0c2f5948ce90a2cab1844b23d2",
        "IPY_MODEL_1275ede4381b4510912e78b592e5b15f",
        "IPY_MODEL_0d4ecfd9af2f487aa9755308fcd266ee"
       ],
       "layout": "IPY_MODEL_20174bb9b61e4b2baf678285bdead069",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c1cdbeab83894f2594318c476b139627": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c438fe162f2d4a7f829d93b6c397756a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c6ba3a6e8c604846b6f0f5eb2493d485": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c85f119987e54bcab78e9f881220e3a5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c91239d618ef44f0bbf6f830d77cd48e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c915189d67734b7a9f277335443395f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_73cdb87c86f640cd9b209f07a805a7fa",
       "placeholder": "",
       "style": "IPY_MODEL_3dc63e916efa44068acc4294840a708c",
       "tabbable": null,
       "tooltip": null,
       "value": "Predicting:100%"
      }
     },
     "c9e85198f8b941838b7603a02b4b2eef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ca447185343a427aa9b8760d93491991": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e4f883912fd14904ae4383b8397a3a77",
        "IPY_MODEL_4e6fe29e30e64f6698f5d3cdc62f50e7",
        "IPY_MODEL_e4c51ed5b6ee4b7eaea5bfb6447d0f04"
       ],
       "layout": "IPY_MODEL_1c0bd3bd547b452491d8d2cda79f10f3",
       "tabbable": null,
       "tooltip": null
      }
     },
     "cf351a6a37784edb98936dc0006ad841": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cfca46283a1e4ce69207845f5dfc957c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d2d14f651c004c0b89ba4a5e396acc17": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d44c3a9539884476bb4b9c2a00381d58": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "db37d79ad1294100a949c9f3511e3da8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e4c51ed5b6ee4b7eaea5bfb6447d0f04": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_791e1e78db8945b3983918cd1dbdae71",
       "placeholder": "",
       "style": "IPY_MODEL_c91239d618ef44f0bbf6f830d77cd48e",
       "tabbable": null,
       "tooltip": null,
       "value": "1/1[00:00&lt;00:00,1.02it/s]"
      }
     },
     "e4f883912fd14904ae4383b8397a3a77": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_82a1ee2041c54726ad5f62eaff45e3c9",
       "placeholder": "",
       "style": "IPY_MODEL_db37d79ad1294100a949c9f3511e3da8",
       "tabbable": null,
       "tooltip": null,
       "value": "InferMVP:100%"
      }
     },
     "e5903aa2a5984f41bf233a936a371c87": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9ccf5af265fa4a798c89f3332d3ef021",
       "placeholder": "",
       "style": "IPY_MODEL_167038eae78d4c98a6743957949df803",
       "tabbable": null,
       "tooltip": null,
       "value": "1/1[00:01&lt;00:00,1.06s/it]"
      }
     },
     "ec5f17d6b6bf4686be89f27caf8a2b5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8bccc89a1bbb4c18bde3c2cd72660647",
        "IPY_MODEL_6d22351ca80a49d8b0d27bc3fff4225c",
        "IPY_MODEL_78a3967a3e45426ab533af4204c22f91"
       ],
       "layout": "IPY_MODEL_299b0a5d8ff14197a486b5ee099dbb1b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ed9c462122f741d6a71bfca621f17d44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a8fee237345e4346a2a54a20432be600",
       "placeholder": "",
       "style": "IPY_MODEL_36f91a5f76d74f669df5acf39efa2d2b",
       "tabbable": null,
       "tooltip": null,
       "value": "1/1[00:02&lt;00:00,2.36s/it]"
      }
     },
     "ef8112d77ca2410b8fc355f53e4b602a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9f221447de654bc3bd28250fb0a44c04",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4f2b8e794ad64139bec24ff096072ef7",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "f091d549c1124df3a30736718d4da46a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_19901b1e2eb246d8b7a8213d4d575c36",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f43791b8cf4148cca8e067fdb0c9c1ba",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "f3d33dd1f3cd4235ad0f41b3068987b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f43791b8cf4148cca8e067fdb0c9c1ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f8acf6e4c34b4ae7b83abd9a9df84537": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f9674560773f408fa8621e014ea36577": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_85aa9244db2e44a8b497931839e9bea5",
        "IPY_MODEL_826231263d0b4539a44a5b66b7cb19a4",
        "IPY_MODEL_34022cbad29942f296071581c8ce07de"
       ],
       "layout": "IPY_MODEL_3f828cc843f34e95aa167242f09e25d6",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
