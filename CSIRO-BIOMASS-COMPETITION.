{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":112509,"databundleVersionId":14254895,"sourceType":"competition"},{"sourceId":13900620,"sourceType":"datasetVersion","datasetId":8856212,"isSourceIdPinned":false},{"sourceId":14018229,"sourceType":"datasetVersion","datasetId":8929818,"isSourceIdPinned":false},{"sourceId":288467413,"sourceType":"kernelVersion"},{"sourceId":4537,"sourceType":"modelInstanceVersion","modelInstanceId":3329,"modelId":986},{"sourceId":268942,"sourceType":"modelInstanceVersion","modelInstanceId":230141,"modelId":251887},{"sourceId":663314,"sourceType":"modelInstanceVersion","modelInstanceId":471723,"modelId":487624}],"dockerImageVersionId":31234,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"51e1b95a-cf50-4259-906b-fbf334258d3d","_cell_guid":"5061a83f-9d83-4302-9d3a-659adc5273a7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-27T22:59:44.611282Z","iopub.execute_input":"2025-12-27T22:59:44.611955Z","iopub.status.idle":"2025-12-27T22:59:44.886070Z","shell.execute_reply.started":"2025-12-27T22:59:44.611928Z","shell.execute_reply":"2025-12-27T22:59:44.885339Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/csiro/pytorch/default/12/fold_0/metrics.csv\n/kaggle/input/csiro/pytorch/default/12/fold_0/swanlab_info.json\n/kaggle/input/csiro/pytorch/default/12/fold_0/checkpoints/best_loss.pt\n/kaggle/input/csiro/pytorch/default/12/fold_0/checkpoints/best_wr2.pt\n/kaggle/input/csiro/pytorch/default/12/fold_0/checkpoints/last.pt\n/kaggle/input/csiro/pytorch/default/12/fold_4/metrics.csv\n/kaggle/input/csiro/pytorch/default/12/fold_4/swanlab_info.json\n/kaggle/input/csiro/pytorch/default/12/fold_4/checkpoints/best_loss.pt\n/kaggle/input/csiro/pytorch/default/12/fold_4/checkpoints/best_wr2.pt\n/kaggle/input/csiro/pytorch/default/12/fold_4/checkpoints/last.pt\n/kaggle/input/csiro/pytorch/default/12/fold_1/metrics.csv\n/kaggle/input/csiro/pytorch/default/12/fold_1/swanlab_info.json\n/kaggle/input/csiro/pytorch/default/12/fold_1/checkpoints/best_loss.pt\n/kaggle/input/csiro/pytorch/default/12/fold_1/checkpoints/best_wr2.pt\n/kaggle/input/csiro/pytorch/default/12/fold_1/checkpoints/last.pt\n/kaggle/input/csiro/pytorch/default/12/fold_3/metrics.csv\n/kaggle/input/csiro/pytorch/default/12/fold_3/swanlab_info.json\n/kaggle/input/csiro/pytorch/default/12/fold_3/checkpoints/best_loss.pt\n/kaggle/input/csiro/pytorch/default/12/fold_3/checkpoints/best_wr2.pt\n/kaggle/input/csiro/pytorch/default/12/fold_3/checkpoints/last.pt\n/kaggle/input/csiro/pytorch/default/12/fold_2/metrics.csv\n/kaggle/input/csiro/pytorch/default/12/fold_2/swanlab_info.json\n/kaggle/input/csiro/pytorch/default/12/fold_2/checkpoints/best_loss.pt\n/kaggle/input/csiro/pytorch/default/12/fold_2/checkpoints/best_wr2.pt\n/kaggle/input/csiro/pytorch/default/12/fold_2/checkpoints/last.pt\n/kaggle/input/csiro-biomass/sample_submission.csv\n/kaggle/input/csiro-biomass/train.csv\n/kaggle/input/csiro-biomass/test.csv\n/kaggle/input/csiro-biomass/test/ID1001187975.jpg\n/kaggle/input/csiro-biomass/train/ID2099464826.jpg\n/kaggle/input/csiro-biomass/train/ID2037861084.jpg\n/kaggle/input/csiro-biomass/train/ID1211362607.jpg\n/kaggle/input/csiro-biomass/train/ID1853508321.jpg\n/kaggle/input/csiro-biomass/train/ID193102215.jpg\n/kaggle/input/csiro-biomass/train/ID698608346.jpg\n/kaggle/input/csiro-biomass/train/ID1859251563.jpg\n/kaggle/input/csiro-biomass/train/ID1880764911.jpg\n/kaggle/input/csiro-biomass/train/ID853954911.jpg\n/kaggle/input/csiro-biomass/train/ID1403107574.jpg\n/kaggle/input/csiro-biomass/train/ID1781353117.jpg\n/kaggle/input/csiro-biomass/train/ID384648061.jpg\n/kaggle/input/csiro-biomass/train/ID1563418511.jpg\n/kaggle/input/csiro-biomass/train/ID2125100696.jpg\n/kaggle/input/csiro-biomass/train/ID482555369.jpg\n/kaggle/input/csiro-biomass/train/ID638711343.jpg\n/kaggle/input/csiro-biomass/train/ID779628955.jpg\n/kaggle/input/csiro-biomass/train/ID1876271942.jpg\n/kaggle/input/csiro-biomass/train/ID1692894460.jpg\n/kaggle/input/csiro-biomass/train/ID746335827.jpg\n/kaggle/input/csiro-biomass/train/ID1136169672.jpg\n/kaggle/input/csiro-biomass/train/ID1471216911.jpg\n/kaggle/input/csiro-biomass/train/ID846154859.jpg\n/kaggle/input/csiro-biomass/train/ID1294770420.jpg\n/kaggle/input/csiro-biomass/train/ID1183807388.jpg\n/kaggle/input/csiro-biomass/train/ID423506847.jpg\n/kaggle/input/csiro-biomass/train/ID1889150649.jpg\n/kaggle/input/csiro-biomass/train/ID1140993511.jpg\n/kaggle/input/csiro-biomass/train/ID1413758094.jpg\n/kaggle/input/csiro-biomass/train/ID1545077474.jpg\n/kaggle/input/csiro-biomass/train/ID95050718.jpg\n/kaggle/input/csiro-biomass/train/ID528010569.jpg\n/kaggle/input/csiro-biomass/train/ID1645161155.jpg\n/kaggle/input/csiro-biomass/train/ID786365141.jpg\n/kaggle/input/csiro-biomass/train/ID896386823.jpg\n/kaggle/input/csiro-biomass/train/ID1025234388.jpg\n/kaggle/input/csiro-biomass/train/ID663006174.jpg\n/kaggle/input/csiro-biomass/train/ID1509266870.jpg\n/kaggle/input/csiro-biomass/train/ID1496750796.jpg\n/kaggle/input/csiro-biomass/train/ID471758347.jpg\n/kaggle/input/csiro-biomass/train/ID740402124.jpg\n/kaggle/input/csiro-biomass/train/ID1624268863.jpg\n/kaggle/input/csiro-biomass/train/ID1098771283.jpg\n/kaggle/input/csiro-biomass/train/ID710341728.jpg\n/kaggle/input/csiro-biomass/train/ID2086966681.jpg\n/kaggle/input/csiro-biomass/train/ID1573329652.jpg\n/kaggle/input/csiro-biomass/train/ID54128926.jpg\n/kaggle/input/csiro-biomass/train/ID50027657.jpg\n/kaggle/input/csiro-biomass/train/ID1559189397.jpg\n/kaggle/input/csiro-biomass/train/ID290369222.jpg\n/kaggle/input/csiro-biomass/train/ID1590632667.jpg\n/kaggle/input/csiro-biomass/train/ID552040066.jpg\n/kaggle/input/csiro-biomass/train/ID488873801.jpg\n/kaggle/input/csiro-biomass/train/ID363069566.jpg\n/kaggle/input/csiro-biomass/train/ID1839139621.jpg\n/kaggle/input/csiro-biomass/train/ID1131079710.jpg\n/kaggle/input/csiro-biomass/train/ID2010625680.jpg\n/kaggle/input/csiro-biomass/train/ID152157478.jpg\n/kaggle/input/csiro-biomass/train/ID1357758282.jpg\n/kaggle/input/csiro-biomass/train/ID1498398599.jpg\n/kaggle/input/csiro-biomass/train/ID679913293.jpg\n/kaggle/input/csiro-biomass/train/ID697718693.jpg\n/kaggle/input/csiro-biomass/train/ID4464212.jpg\n/kaggle/input/csiro-biomass/train/ID1275072698.jpg\n/kaggle/input/csiro-biomass/train/ID1579942839.jpg\n/kaggle/input/csiro-biomass/train/ID799079114.jpg\n/kaggle/input/csiro-biomass/train/ID1415329644.jpg\n/kaggle/input/csiro-biomass/train/ID1510574031.jpg\n/kaggle/input/csiro-biomass/train/ID1078930021.jpg\n/kaggle/input/csiro-biomass/train/ID1456861072.jpg\n/kaggle/input/csiro-biomass/train/ID930534670.jpg\n/kaggle/input/csiro-biomass/train/ID13162390.jpg\n/kaggle/input/csiro-biomass/train/ID567744300.jpg\n/kaggle/input/csiro-biomass/train/ID344618040.jpg\n/kaggle/input/csiro-biomass/train/ID566966892.jpg\n/kaggle/input/csiro-biomass/train/ID1437386574.jpg\n/kaggle/input/csiro-biomass/train/ID667059550.jpg\n/kaggle/input/csiro-biomass/train/ID72895391.jpg\n/kaggle/input/csiro-biomass/train/ID1193692654.jpg\n/kaggle/input/csiro-biomass/train/ID1386202352.jpg\n/kaggle/input/csiro-biomass/train/ID871463897.jpg\n/kaggle/input/csiro-biomass/train/ID2096636211.jpg\n/kaggle/input/csiro-biomass/train/ID2003438517.jpg\n/kaggle/input/csiro-biomass/train/ID21377800.jpg\n/kaggle/input/csiro-biomass/train/ID230058600.jpg\n/kaggle/input/csiro-biomass/train/ID1753847361.jpg\n/kaggle/input/csiro-biomass/train/ID1512751450.jpg\n/kaggle/input/csiro-biomass/train/ID12390962.jpg\n/kaggle/input/csiro-biomass/train/ID1746343319.jpg\n/kaggle/input/csiro-biomass/train/ID978026131.jpg\n/kaggle/input/csiro-biomass/train/ID383231615.jpg\n/kaggle/input/csiro-biomass/train/ID146920896.jpg\n/kaggle/input/csiro-biomass/train/ID1036339023.jpg\n/kaggle/input/csiro-biomass/train/ID1168534540.jpg\n/kaggle/input/csiro-biomass/train/ID1859792585.jpg\n/kaggle/input/csiro-biomass/train/ID1251029854.jpg\n/kaggle/input/csiro-biomass/train/ID1113329413.jpg\n/kaggle/input/csiro-biomass/train/ID1874904894.jpg\n/kaggle/input/csiro-biomass/train/ID1671844336.jpg\n/kaggle/input/csiro-biomass/train/ID1831254380.jpg\n/kaggle/input/csiro-biomass/train/ID1103883611.jpg\n/kaggle/input/csiro-biomass/train/ID797502182.jpg\n/kaggle/input/csiro-biomass/train/ID1784585001.jpg\n/kaggle/input/csiro-biomass/train/ID1058383417.jpg\n/kaggle/input/csiro-biomass/train/ID1488408526.jpg\n/kaggle/input/csiro-biomass/train/ID429799190.jpg\n/kaggle/input/csiro-biomass/train/ID1291116815.jpg\n/kaggle/input/csiro-biomass/train/ID1516374298.jpg\n/kaggle/input/csiro-biomass/train/ID1618597318.jpg\n/kaggle/input/csiro-biomass/train/ID1345375788.jpg\n/kaggle/input/csiro-biomass/train/ID686797154.jpg\n/kaggle/input/csiro-biomass/train/ID1139866256.jpg\n/kaggle/input/csiro-biomass/train/ID1149598723.jpg\n/kaggle/input/csiro-biomass/train/ID212206250.jpg\n/kaggle/input/csiro-biomass/train/ID112966473.jpg\n/kaggle/input/csiro-biomass/train/ID1540480250.jpg\n/kaggle/input/csiro-biomass/train/ID544444725.jpg\n/kaggle/input/csiro-biomass/train/ID1513184765.jpg\n/kaggle/input/csiro-biomass/train/ID668330410.jpg\n/kaggle/input/csiro-biomass/train/ID1444674500.jpg\n/kaggle/input/csiro-biomass/train/ID1962379474.jpg\n/kaggle/input/csiro-biomass/train/ID605134229.jpg\n/kaggle/input/csiro-biomass/train/ID914754166.jpg\n/kaggle/input/csiro-biomass/train/ID354528442.jpg\n/kaggle/input/csiro-biomass/train/ID950496197.jpg\n/kaggle/input/csiro-biomass/train/ID1395011773.jpg\n/kaggle/input/csiro-biomass/train/ID1357768767.jpg\n/kaggle/input/csiro-biomass/train/ID210865340.jpg\n/kaggle/input/csiro-biomass/train/ID936984905.jpg\n/kaggle/input/csiro-biomass/train/ID1976436386.jpg\n/kaggle/input/csiro-biomass/train/ID1215977190.jpg\n/kaggle/input/csiro-biomass/train/ID803479541.jpg\n/kaggle/input/csiro-biomass/train/ID1244346858.jpg\n/kaggle/input/csiro-biomass/train/ID158170916.jpg\n/kaggle/input/csiro-biomass/train/ID1208644039.jpg\n/kaggle/input/csiro-biomass/train/ID1314135397.jpg\n/kaggle/input/csiro-biomass/train/ID1012260530.jpg\n/kaggle/input/csiro-biomass/train/ID1053972079.jpg\n/kaggle/input/csiro-biomass/train/ID656251220.jpg\n/kaggle/input/csiro-biomass/train/ID1084819986.jpg\n/kaggle/input/csiro-biomass/train/ID1337107565.jpg\n/kaggle/input/csiro-biomass/train/ID1268934251.jpg\n/kaggle/input/csiro-biomass/train/ID617132135.jpg\n/kaggle/input/csiro-biomass/train/ID1472525822.jpg\n/kaggle/input/csiro-biomass/train/ID668475812.jpg\n/kaggle/input/csiro-biomass/train/ID681680726.jpg\n/kaggle/input/csiro-biomass/train/ID1476045099.jpg\n/kaggle/input/csiro-biomass/train/ID1570190541.jpg\n/kaggle/input/csiro-biomass/train/ID1403078396.jpg\n/kaggle/input/csiro-biomass/train/ID2030696575.jpg\n/kaggle/input/csiro-biomass/train/ID1782608354.jpg\n/kaggle/input/csiro-biomass/train/ID194823383.jpg\n/kaggle/input/csiro-biomass/train/ID196516535.jpg\n/kaggle/input/csiro-biomass/train/ID212206832.jpg\n/kaggle/input/csiro-biomass/train/ID1638922597.jpg\n/kaggle/input/csiro-biomass/train/ID1457700382.jpg\n/kaggle/input/csiro-biomass/train/ID1989506559.jpg\n/kaggle/input/csiro-biomass/train/ID789169173.jpg\n/kaggle/input/csiro-biomass/train/ID1634731537.jpg\n/kaggle/input/csiro-biomass/train/ID1428837636.jpg\n/kaggle/input/csiro-biomass/train/ID2006686196.jpg\n/kaggle/input/csiro-biomass/train/ID885388135.jpg\n/kaggle/input/csiro-biomass/train/ID1789853061.jpg\n/kaggle/input/csiro-biomass/train/ID1655778545.jpg\n/kaggle/input/csiro-biomass/train/ID697059386.jpg\n/kaggle/input/csiro-biomass/train/ID121331988.jpg\n/kaggle/input/csiro-biomass/train/ID2099742797.jpg\n/kaggle/input/csiro-biomass/train/ID342818398.jpg\n/kaggle/input/csiro-biomass/train/ID317990700.jpg\n/kaggle/input/csiro-biomass/train/ID706288721.jpg\n/kaggle/input/csiro-biomass/train/ID1159071020.jpg\n/kaggle/input/csiro-biomass/train/ID755710743.jpg\n/kaggle/input/csiro-biomass/train/ID1254829053.jpg\n/kaggle/input/csiro-biomass/train/ID475010202.jpg\n/kaggle/input/csiro-biomass/train/ID1693880739.jpg\n/kaggle/input/csiro-biomass/train/ID1894998379.jpg\n/kaggle/input/csiro-biomass/train/ID48303557.jpg\n/kaggle/input/csiro-biomass/train/ID1385921939.jpg\n/kaggle/input/csiro-biomass/train/ID147528735.jpg\n/kaggle/input/csiro-biomass/train/ID407646960.jpg\n/kaggle/input/csiro-biomass/train/ID1035947949.jpg\n/kaggle/input/csiro-biomass/train/ID1119761112.jpg\n/kaggle/input/csiro-biomass/train/ID1988033238.jpg\n/kaggle/input/csiro-biomass/train/ID1857489997.jpg\n/kaggle/input/csiro-biomass/train/ID742198710.jpg\n/kaggle/input/csiro-biomass/train/ID588120964.jpg\n/kaggle/input/csiro-biomass/train/ID431471530.jpg\n/kaggle/input/csiro-biomass/train/ID353424190.jpg\n/kaggle/input/csiro-biomass/train/ID380752847.jpg\n/kaggle/input/csiro-biomass/train/ID2069766023.jpg\n/kaggle/input/csiro-biomass/train/ID600602588.jpg\n/kaggle/input/csiro-biomass/train/ID560946727.jpg\n/kaggle/input/csiro-biomass/train/ID1011485656.jpg\n/kaggle/input/csiro-biomass/train/ID808079729.jpg\n/kaggle/input/csiro-biomass/train/ID1217108125.jpg\n/kaggle/input/csiro-biomass/train/ID1623964968.jpg\n/kaggle/input/csiro-biomass/train/ID980878870.jpg\n/kaggle/input/csiro-biomass/train/ID793526563.jpg\n/kaggle/input/csiro-biomass/train/ID397994621.jpg\n/kaggle/input/csiro-biomass/train/ID975115267.jpg\n/kaggle/input/csiro-biomass/train/ID1237349078.jpg\n/kaggle/input/csiro-biomass/train/ID684383343.jpg\n/kaggle/input/csiro-biomass/train/ID866684633.jpg\n/kaggle/input/csiro-biomass/train/ID1665142816.jpg\n/kaggle/input/csiro-biomass/train/ID2048645043.jpg\n/kaggle/input/csiro-biomass/train/ID1953171547.jpg\n/kaggle/input/csiro-biomass/train/ID1451025862.jpg\n/kaggle/input/csiro-biomass/train/ID71885430.jpg\n/kaggle/input/csiro-biomass/train/ID307060225.jpg\n/kaggle/input/csiro-biomass/train/ID969218269.jpg\n/kaggle/input/csiro-biomass/train/ID980538882.jpg\n/kaggle/input/csiro-biomass/train/ID1028611175.jpg\n/kaggle/input/csiro-biomass/train/ID670276799.jpg\n/kaggle/input/csiro-biomass/train/ID2002797732.jpg\n/kaggle/input/csiro-biomass/train/ID1374789439.jpg\n/kaggle/input/csiro-biomass/train/ID473494649.jpg\n/kaggle/input/csiro-biomass/train/ID1993907137.jpg\n/kaggle/input/csiro-biomass/train/ID1962197151.jpg\n/kaggle/input/csiro-biomass/train/ID828217731.jpg\n/kaggle/input/csiro-biomass/train/ID972274220.jpg\n/kaggle/input/csiro-biomass/train/ID1954669045.jpg\n/kaggle/input/csiro-biomass/train/ID1354190372.jpg\n/kaggle/input/csiro-biomass/train/ID1458758610.jpg\n/kaggle/input/csiro-biomass/train/ID40849327.jpg\n/kaggle/input/csiro-biomass/train/ID1952813879.jpg\n/kaggle/input/csiro-biomass/train/ID572336285.jpg\n/kaggle/input/csiro-biomass/train/ID1473228876.jpg\n/kaggle/input/csiro-biomass/train/ID1963715583.jpg\n/kaggle/input/csiro-biomass/train/ID1463690813.jpg\n/kaggle/input/csiro-biomass/train/ID1899025384.jpg\n/kaggle/input/csiro-biomass/train/ID386216505.jpg\n/kaggle/input/csiro-biomass/train/ID1789265307.jpg\n/kaggle/input/csiro-biomass/train/ID315357834.jpg\n/kaggle/input/csiro-biomass/train/ID2089023774.jpg\n/kaggle/input/csiro-biomass/train/ID520514019.jpg\n/kaggle/input/csiro-biomass/train/ID1970522802.jpg\n/kaggle/input/csiro-biomass/train/ID1139918758.jpg\n/kaggle/input/csiro-biomass/train/ID1051144034.jpg\n/kaggle/input/csiro-biomass/train/ID1370004842.jpg\n/kaggle/input/csiro-biomass/train/ID761508093.jpg\n/kaggle/input/csiro-biomass/train/ID2052993274.jpg\n/kaggle/input/csiro-biomass/train/ID1277756619.jpg\n/kaggle/input/csiro-biomass/train/ID6269659.jpg\n/kaggle/input/csiro-biomass/train/ID1574125908.jpg\n/kaggle/input/csiro-biomass/train/ID135365668.jpg\n/kaggle/input/csiro-biomass/train/ID1182523622.jpg\n/kaggle/input/csiro-biomass/train/ID554314721.jpg\n/kaggle/input/csiro-biomass/train/ID1049634115.jpg\n/kaggle/input/csiro-biomass/train/ID1127246618.jpg\n/kaggle/input/csiro-biomass/train/ID900012207.jpg\n/kaggle/input/csiro-biomass/train/ID574213894.jpg\n/kaggle/input/csiro-biomass/train/ID415656958.jpg\n/kaggle/input/csiro-biomass/train/ID61833032.jpg\n/kaggle/input/csiro-biomass/train/ID2053315094.jpg\n/kaggle/input/csiro-biomass/train/ID550623196.jpg\n/kaggle/input/csiro-biomass/train/ID657448172.jpg\n/kaggle/input/csiro-biomass/train/ID1675365449.jpg\n/kaggle/input/csiro-biomass/train/ID2014192906.jpg\n/kaggle/input/csiro-biomass/train/ID162394992.jpg\n/kaggle/input/csiro-biomass/train/ID968643034.jpg\n/kaggle/input/csiro-biomass/train/ID684062938.jpg\n/kaggle/input/csiro-biomass/train/ID802547515.jpg\n/kaggle/input/csiro-biomass/train/ID294150104.jpg\n/kaggle/input/csiro-biomass/train/ID1618145129.jpg\n/kaggle/input/csiro-biomass/train/ID956512130.jpg\n/kaggle/input/csiro-biomass/train/ID142751858.jpg\n/kaggle/input/csiro-biomass/train/ID325799913.jpg\n/kaggle/input/csiro-biomass/train/ID443091455.jpg\n/kaggle/input/csiro-biomass/train/ID661372352.jpg\n/kaggle/input/csiro-biomass/train/ID1062837331.jpg\n/kaggle/input/csiro-biomass/train/ID498304885.jpg\n/kaggle/input/csiro-biomass/train/ID187238869.jpg\n/kaggle/input/csiro-biomass/train/ID1450399782.jpg\n/kaggle/input/csiro-biomass/train/ID2056023629.jpg\n/kaggle/input/csiro-biomass/train/ID576621307.jpg\n/kaggle/input/csiro-biomass/train/ID1199150612.jpg\n/kaggle/input/csiro-biomass/train/ID1411613934.jpg\n/kaggle/input/csiro-biomass/train/ID105271783.jpg\n/kaggle/input/csiro-biomass/train/ID1703304524.jpg\n/kaggle/input/csiro-biomass/train/ID875119737.jpg\n/kaggle/input/csiro-biomass/train/ID1176292407.jpg\n/kaggle/input/csiro-biomass/train/ID1729002155.jpg\n/kaggle/input/csiro-biomass/train/ID2091439402.jpg\n/kaggle/input/csiro-biomass/train/ID576137678.jpg\n/kaggle/input/csiro-biomass/train/ID1946311744.jpg\n/kaggle/input/csiro-biomass/train/ID1982662138.jpg\n/kaggle/input/csiro-biomass/train/ID983582017.jpg\n/kaggle/input/csiro-biomass/train/ID661817669.jpg\n/kaggle/input/csiro-biomass/train/ID753699705.jpg\n/kaggle/input/csiro-biomass/train/ID1789834546.jpg\n/kaggle/input/csiro-biomass/train/ID529933668.jpg\n/kaggle/input/csiro-biomass/train/ID490139972.jpg\n/kaggle/input/csiro-biomass/train/ID743847993.jpg\n/kaggle/input/csiro-biomass/train/ID7850481.jpg\n/kaggle/input/csiro-biomass/train/ID1088965591.jpg\n/kaggle/input/csiro-biomass/train/ID629980789.jpg\n/kaggle/input/csiro-biomass/train/ID1119739385.jpg\n/kaggle/input/csiro-biomass/train/ID1477176296.jpg\n/kaggle/input/csiro-biomass/train/ID1113121340.jpg\n/kaggle/input/csiro-biomass/train/ID2131261930.jpg\n/kaggle/input/csiro-biomass/train/ID2145635095.jpg\n/kaggle/input/csiro-biomass/train/ID1414371018.jpg\n/kaggle/input/csiro-biomass/train/ID1148666289.jpg\n/kaggle/input/csiro-biomass/train/ID839432753.jpg\n/kaggle/input/csiro-biomass/train/ID157479394.jpg\n/kaggle/input/csiro-biomass/train/ID1761544403.jpg\n/kaggle/input/csiro-biomass/train/ID846984946.jpg\n/kaggle/input/csiro-biomass/train/ID751517087.jpg\n/kaggle/input/csiro-biomass/train/ID577112774.jpg\n/kaggle/input/csiro-biomass/train/ID353997899.jpg\n/kaggle/input/csiro-biomass/train/ID748979397.jpg\n/kaggle/input/csiro-biomass/train/ID1070112260.jpg\n/kaggle/input/csiro-biomass/train/ID1108283583.jpg\n/kaggle/input/csiro-biomass/train/ID1868719645.jpg\n/kaggle/input/csiro-biomass/train/ID1980675327.jpg\n/kaggle/input/csiro-biomass/train/ID1163061745.jpg\n/kaggle/input/csiro-biomass/train/ID1148528732.jpg\n/kaggle/input/csiro-biomass/train/ID534966093.jpg\n/kaggle/input/csiro-biomass/train/ID1717006117.jpg\n/kaggle/input/csiro-biomass/train/ID1953218650.jpg\n/kaggle/input/csiro-biomass/train/ID633775166.jpg\n/kaggle/input/csiro-biomass/train/ID808093827.jpg\n/kaggle/input/csiro-biomass/train/ID1997244125.jpg\n/kaggle/input/csiro-biomass/train/ID1920959057.jpg\n/kaggle/input/csiro-biomass/train/ID1948354837.jpg\n/kaggle/input/csiro-biomass/train/ID364856705.jpg\n/kaggle/input/csiro-biomass/train/ID249042826.jpg\n/kaggle/input/csiro-biomass/train/ID332742639.jpg\n/kaggle/input/csiro-biomass/train/ID1680597197.jpg\n/kaggle/input/csiro-biomass/train/ID1421714468.jpg\n/kaggle/input/csiro-biomass/train/ID905397692.jpg\n/kaggle/input/csiro-biomass/train/ID1782509721.jpg\n/kaggle/input/csiro-biomass/train/ID141370843.jpg\n/kaggle/input/csiro-biomass/train/ID2056982009.jpg\n/kaggle/input/csiro-biomass/train/ID94564238.jpg\n/kaggle/input/csiro-biomass/train/ID8209776.jpg\n/kaggle/input/csiro-biomass/train/ID908524512.jpg\n/kaggle/input/csiro-biomass/train/ID610397481.jpg\n/kaggle/input/csiro-biomass/train/ID750820644.jpg\n/kaggle/input/csiro-biomass/train/ID1515990019.jpg\n/kaggle/input/csiro-biomass/train/ID1547945326.jpg\n/kaggle/input/csiro-biomass/train/ID587125778.jpg\n/kaggle/input/csiro-biomass/train/ID1620371305.jpg\n/kaggle/input/csiro-biomass/train/ID1474775613.jpg\n/kaggle/input/csiro-biomass/train/ID545360459.jpg\n/kaggle/input/csiro-biomass/train/ID1783499590.jpg\n/kaggle/input/csiro-biomass/train/ID1249094008.jpg\n/kaggle/input/csiro-biomass/train/ID1525817840.jpg\n/kaggle/input/csiro-biomass/train/ID227847873.jpg\n/kaggle/input/csiro-biomass/train/ID1052620238.jpg\n/kaggle/input/csiro-biomass/train/ID1888700589.jpg\n/kaggle/input/csiro-biomass/train/ID2052442675.jpg\n/kaggle/input/csiro-biomass/train/ID963903358.jpg\n/kaggle/input/csiro-biomass/train/ID1121692672.jpg\n/kaggle/input/csiro-biomass/train/ID1343327476.jpg\n/kaggle/input/csiro-biomass/train/ID1667778338.jpg\n/kaggle/input/csiro-biomass/train/ID257822026.jpg\n/kaggle/input/csiro-datasplit/__results__.html\n/kaggle/input/csiro-datasplit/csiro_data_split.csv\n/kaggle/input/csiro-datasplit/__notebook__.ipynb\n/kaggle/input/csiro-datasplit/__output__.json\n/kaggle/input/csiro-datasplit/custom.css\n/kaggle/input/csiro-biomass-competition-comprehensive-eda/__results__.html\n/kaggle/input/csiro-biomass-competition-comprehensive-eda/__notebook__.ipynb\n/kaggle/input/csiro-biomass-competition-comprehensive-eda/__output__.json\n/kaggle/input/csiro-biomass-competition-comprehensive-eda/custom.css\n/kaggle/input/csiro-biomass-competition-comprehensive-eda/__results___files/__results___15_0.png\n/kaggle/input/csiro-biomass-competition-comprehensive-eda/__results___files/__results___25_0.png\n/kaggle/input/csiro-biomass-competition-comprehensive-eda/__results___files/__results___19_0.png\n/kaggle/input/csiro-biomass-competition-comprehensive-eda/__results___files/__results___31_0.png\n/kaggle/input/csiro-biomass-competition-comprehensive-eda/__results___files/__results___22_0.png\n/kaggle/input/csiro-biomass-competition-comprehensive-eda/__results___files/__results___28_0.png\n/kaggle/input/csiro-image-embeddings/train_siglip_embeddings.csv\n/kaggle/input/csiro-image-embeddings/train_dino_embeddings.csv\n/kaggle/input/csiro-mvp-models/model1.pth\n/kaggle/input/csiro-mvp-models/model2.pth\n/kaggle/input/csiro-mvp-models/model10.pth\n/kaggle/input/csiro-mvp-models/model7.pth\n/kaggle/input/csiro-mvp-models/model6.pth\n/kaggle/input/csiro-mvp-models/model4.pth\n/kaggle/input/csiro-mvp-models/model5.pth\n/kaggle/input/csiro-mvp-models/model9.pth\n/kaggle/input/csiro-mvp-models/model3.pth\n/kaggle/input/csiro-mvp-models/model8.pth\n/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1/config.json\n/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1/preprocessor_config.json\n/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1/spiece.model\n/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1/README.md\n/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1/tokenizer.json\n/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1/tokenizer_config.json\n/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1/gitattributes\n/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1/model.safetensors\n/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1/special_tokens_map.json\n/kaggle/input/dinov2/pytorch/giant/1/config.json\n/kaggle/input/dinov2/pytorch/giant/1/preprocessor_config.json\n/kaggle/input/dinov2/pytorch/giant/1/README.md\n/kaggle/input/dinov2/pytorch/giant/1/pytorch_model.bin\n/kaggle/input/dinov2/pytorch/giant/1/.gitattributes\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ================================================================\n# CSIRO BIOMASS COMPETITION - PROFESSIONAL EDA\n# ================================================================\n# Professional visualizations with consistent color scheme\n# Complete statistical analysis with bell curves and annotations\n# ================================================================\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nfrom PIL import Image\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom scipy import stats\nfrom scipy.stats import skew, kurtosis, normaltest, pearsonr, spearmanr, norm\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# ================================================================\n# PROFESSIONAL STYLING CONFIGURATION\n# ================================================================\n\n# Professional color palette (consistent across all plots)\nCOLORS = {\n    'primary': '#2E4057',      # Dark blue-gray (main)\n    'secondary': '#048A81',     # Teal (accent)\n    'tertiary': '#54C6EB',      # Light blue\n    'highlight': '#D95D39',     # Coral red (emphasis)\n    'neutral': '#8B8B8B',       # Gray\n    'background': '#F5F5F5',    # Light gray background\n    'grid': '#E0E0E0',          # Grid color\n    'text': '#2C3E50'           # Dark text\n}\n\n# Set professional matplotlib style\nplt.style.use('seaborn-v0_8-whitegrid')\nplt.rcParams.update({\n    'figure.figsize': (12, 7),\n    'font.size': 11,\n    'axes.labelsize': 12,\n    'axes.titlesize': 14,\n    'xtick.labelsize': 10,\n    'ytick.labelsize': 10,\n    'legend.fontsize': 10,\n    'figure.titlesize': 16,\n    'axes.facecolor': COLORS['background'],\n    'figure.facecolor': 'white',\n    'axes.edgecolor': COLORS['neutral'],\n    'grid.color': COLORS['grid'],\n    'grid.alpha': 0.3,\n    'text.color': COLORS['text'],\n    'axes.labelcolor': COLORS['text'],\n    'xtick.color': COLORS['text'],\n    'ytick.color': COLORS['text']\n})\n\n# ================================================================\n# CONFIGURATION\n# ================================================================\n\nclass Config:\n    BASE_PATH = Path(\"/kaggle/input/csiro-biomass/\")\n    TRAIN_PATH = BASE_PATH / \"train\"\n    TEST_PATH = BASE_PATH / \"test\"\n    OUTPUT_PATH = Path(\"/kaggle/working/\")\n    \n    TARGET_COLS = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n    TARGET_NAMES = {\n        'Dry_Green_g': 'Green Biomass',\n        'Dry_Dead_g': 'Dead Biomass',\n        'Dry_Clover_g': 'Clover Biomass',\n        'GDM_g': 'Green Dry Matter',\n        'Dry_Total_g': 'Total Biomass'\n    }\n    \n    TARGET_WEIGHTS = {\n        'Dry_Green_g': 0.1,\n        'Dry_Dead_g': 0.1,\n        'Dry_Clover_g': 0.1,\n        'GDM_g': 0.2,\n        'Dry_Total_g': 0.5,\n    }\n\ncfg = Config()\n\nprint(\"=\"*80)\nprint(\"CSIRO BIOMASS COMPETITION - PROFESSIONAL EDA\")\nprint(\"=\"*80)\n\n# ================================================================\n# LOAD DATA\n# ================================================================\n\nprint(\"\\nLoading data...\")\ntrain_df = pd.read_csv(cfg.BASE_PATH / \"train.csv\")\ntest_df = pd.read_csv(cfg.BASE_PATH / \"test.csv\")\n\nprint(f\"Train shape: {train_df.shape}\")\nprint(f\"Test shape: {test_df.shape}\")\n\n# Pivot to get one row per image\ntrain_pivot = train_df.pivot_table(\n    values='target',\n    index='image_path',\n    columns='target_name',\n    aggfunc='mean'\n).reset_index()\n\nprint(f\"Pivoted train shape: {train_pivot.shape}\")\n\n# ================================================================\n# 1. COMPREHENSIVE TARGET DISTRIBUTION WITH BELL CURVES\n# ================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"Creating Visualization 1: Target Distributions with Normal Curves\")\nprint(\"=\"*80)\n\nfig = plt.figure(figsize=(20, 12))\ngs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.25)\n\nfor idx, col in enumerate(cfg.TARGET_COLS):\n    row = idx // 2\n    col_idx = idx % 2\n    ax = fig.add_subplot(gs[row, col_idx])\n    \n    values = train_pivot[col].dropna().values\n    \n    # Histogram\n    n, bins, patches = ax.hist(values, bins=40, alpha=0.6, color=COLORS['primary'], \n                                edgecolor='white', linewidth=1.5, density=True,\n                                label='Observed Distribution')\n    \n    # Fit normal distribution\n    mu, sigma = values.mean(), values.std()\n    x = np.linspace(values.min(), values.max(), 100)\n    normal_curve = norm.pdf(x, mu, sigma)\n    \n    # Plot normal curve\n    ax.plot(x, normal_curve, color=COLORS['highlight'], linewidth=3, \n            label=f'Normal Fit (μ={mu:.1f}, σ={sigma:.1f})', linestyle='--')\n    \n    # Statistics lines\n    ax.axvline(mu, color=COLORS['secondary'], linestyle='-', linewidth=2.5, \n               label=f'Mean: {mu:.2f}g', alpha=0.8)\n    ax.axvline(np.median(values), color=COLORS['tertiary'], linestyle='-', linewidth=2.5,\n               label=f'Median: {np.median(values):.2f}g', alpha=0.8)\n    \n    # Annotations\n    ax.text(0.98, 0.97, f'n = {len(values):,}', transform=ax.transAxes,\n            verticalalignment='top', horizontalalignment='right',\n            bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor=COLORS['neutral']),\n            fontsize=10, fontweight='bold')\n    \n    # Statistical properties\n    skewness = skew(values)\n    kurt = kurtosis(values)\n    stats_text = f'Skewness: {skewness:.2f}\\nKurtosis: {kurt:.2f}\\nMin: {values.min():.2f}g\\nMax: {values.max():.2f}g'\n    ax.text(0.02, 0.97, stats_text, transform=ax.transAxes,\n            verticalalignment='top', horizontalalignment='left',\n            bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor=COLORS['neutral']),\n            fontsize=9)\n    \n    # Labels and title\n    ax.set_xlabel(f'{cfg.TARGET_NAMES[col]} (grams)', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Probability Density', fontsize=12, fontweight='bold')\n    ax.set_title(f'{cfg.TARGET_NAMES[col]} Distribution', \n                 fontsize=14, fontweight='bold', pad=15, color=COLORS['text'])\n    ax.legend(loc='upper right', framealpha=0.95, edgecolor=COLORS['neutral'])\n    ax.grid(True, alpha=0.3, linestyle='--')\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n\n# Add overall title\nfig.suptitle('Target Variable Distributions with Statistical Analysis', \n             fontsize=18, fontweight='bold', y=0.995, color=COLORS['text'])\n\nplt.savefig(cfg.OUTPUT_PATH / 'professional_1_distributions.png', dpi=300, bbox_inches='tight', \n            facecolor='white', edgecolor='none')\nprint(\"✓ Saved: professional_1_distributions.png\")\nplt.close()\n\n# ================================================================\n# 2. COMPREHENSIVE CORRELATION MATRIX  \n# ================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"Creating Visualization 2: Complete Correlation Matrix\")\nprint(\"=\"*80)\n\n# Calculate correlations\ncorrelation_matrix = train_pivot[cfg.TARGET_COLS].corr()\n\n# Create simple figure\nfig, ax = plt.subplots(figsize=(12, 10))\n\n# Professional RED-WHITE-GREEN diverging colormap\n# Red (negative) → White/Yellow (zero) → Green (positive)\nfrom matplotlib.colors import LinearSegmentedColormap\ncolors_cmap = [\n    '#D73027',  # Dark red (strong negative)\n    '#FC8D59',  # Medium red\n    '#FEE090',  # Light red/orange\n    '#FFFFBF',  # White/Yellow (zero)\n    '#E0F3DB',  # Very light green\n    '#A8DDB5',  # Light green\n    '#66C2A4',  # Medium light green\n    '#2CA25F',  # Medium green\n    '#006D2C'   # Dark green (strong positive)\n]\nn_bins = 100\ncmap_diverging = LinearSegmentedColormap.from_list('red_white_green', colors_cmap, N=n_bins)\n\n# Create heatmap with full range -1 to 1\nim = ax.imshow(correlation_matrix, cmap=cmap_diverging, aspect='auto', vmin=-1, vmax=1)\n\n# Set ticks\nax.set_xticks(np.arange(len(cfg.TARGET_COLS)))\nax.set_yticks(np.arange(len(cfg.TARGET_COLS)))\nax.set_xticklabels([cfg.TARGET_NAMES[col] for col in cfg.TARGET_COLS], \n                    rotation=45, ha='right', fontsize=11, fontweight='bold')\nax.set_yticklabels([cfg.TARGET_NAMES[col] for col in cfg.TARGET_COLS], \n                    fontsize=11, fontweight='bold')\n\n# Add correlation values and significance\nfor i in range(len(cfg.TARGET_COLS)):\n    for j in range(len(cfg.TARGET_COLS)):\n        corr_val = correlation_matrix.iloc[i, j]\n        \n        # Calculate p-value\n        if i != j:\n            _, p_val = pearsonr(train_pivot[cfg.TARGET_COLS[i]], \n                               train_pivot[cfg.TARGET_COLS[j]])\n            sig = '***' if p_val < 0.001 else '**' if p_val < 0.01 else '*' if p_val < 0.05 else ''\n        else:\n            sig = ''\n        \n        # Choose text color based on correlation value\n        # Dark text for light colors (near zero), white text for dark colors (strong correlations)\n        if abs(corr_val) > 0.6:\n            text_color = 'white'\n        else:\n            text_color = 'black'\n        \n        # Main correlation value\n        ax.text(j, i, f'{corr_val:.3f}', ha='center', va='center',\n                color=text_color, fontsize=12, fontweight='bold')\n        \n        # Significance stars\n        if sig:\n            ax.text(j, i + 0.35, sig, ha='center', va='center',\n                    color=text_color, fontsize=10, fontweight='bold')\n\n# Colorbar with professional labels\ncbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\ncbar.set_label('Pearson Correlation Coefficient (r)', rotation=270, labelpad=25, \n               fontsize=12, fontweight='bold')\ncbar.ax.tick_params(labelsize=10)\n\n# Add interpretive labels on colorbar\ncbar.ax.text(3.5, -0.9, 'Strong Negative', transform=cbar.ax.transData,\n            fontsize=9, fontweight='bold', color='#D73027', rotation=0)\ncbar.ax.text(3.5, 0.0, 'No Correlation', transform=cbar.ax.transData,\n            fontsize=9, fontweight='bold', color='#666666', rotation=0)\ncbar.ax.text(3.5, 0.9, 'Strong Positive', transform=cbar.ax.transData,\n            fontsize=9, fontweight='bold', color='#006D2C', rotation=0)\n\n# Title with significance legend\ntitle_text = 'Complete Correlation Matrix: All Target Variables\\n'\ntitle_text += 'Red = Negative | Yellow = Zero | Green = Positive  |  '\ntitle_text += '*** p<0.001, ** p<0.01, * p<0.05'\nax.set_title(title_text, fontsize=13, fontweight='bold', pad=20, color=COLORS['text'])\n\n# Grid\nax.set_xticks(np.arange(len(cfg.TARGET_COLS)) - 0.5, minor=True)\nax.set_yticks(np.arange(len(cfg.TARGET_COLS)) - 0.5, minor=True)\nax.grid(which='minor', color='white', linestyle='-', linewidth=2)\n\nplt.tight_layout()\nplt.savefig(cfg.OUTPUT_PATH / 'professional_2_correlation_matrix.png', dpi=300, bbox_inches='tight',\n            facecolor='white', edgecolor='none')\nprint(\"✓ Saved: professional_2_correlation_matrix.png\")\nplt.close()\n\n# ================================================================\n# 3. DETAILED BOX PLOTS WITH STATISTICS\n# ================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"Creating Visualization 3: Detailed Box Plots\")\nprint(\"=\"*80)\n\nfig, ax = plt.subplots(figsize=(16, 8))\n\n# Prepare data\ndata_for_box = [train_pivot[col].dropna().values for col in cfg.TARGET_COLS]\nlabels = [cfg.TARGET_NAMES[col] for col in cfg.TARGET_COLS]\n\n# Create box plot\nbp = ax.boxplot(data_for_box, labels=labels, patch_artist=True,\n                widths=0.6, showmeans=True,\n                meanprops=dict(marker='D', markerfacecolor=COLORS['highlight'], \n                              markeredgecolor='white', markersize=10),\n                medianprops=dict(color=COLORS['secondary'], linewidth=2.5),\n                boxprops=dict(facecolor=COLORS['primary'], alpha=0.7, \n                             edgecolor=COLORS['text'], linewidth=1.5),\n                whiskerprops=dict(color=COLORS['text'], linewidth=1.5),\n                capprops=dict(color=COLORS['text'], linewidth=1.5),\n                flierprops=dict(marker='o', markerfacecolor=COLORS['highlight'], \n                               markersize=5, alpha=0.5, markeredgecolor='none'))\n\n# Add detailed statistics\nfor idx, (col, data) in enumerate(zip(cfg.TARGET_COLS, data_for_box)):\n    # Calculate statistics\n    q1 = np.percentile(data, 25)\n    median = np.median(data)\n    q3 = np.percentile(data, 75)\n    mean = np.mean(data)\n    iqr = q3 - q1\n    lower_whisker = q1 - 1.5 * iqr\n    upper_whisker = q3 + 1.5 * iqr\n    outliers = len(data[(data < lower_whisker) | (data > upper_whisker)])\n    \n    # Add text annotation\n    stats_text = f'Mean: {mean:.1f}g\\nMedian: {median:.1f}g\\nIQR: {iqr:.1f}g\\nOutliers: {outliers}'\n    ax.text(idx + 1, ax.get_ylim()[1] * 0.95, stats_text,\n            ha='center', va='top', fontsize=9,\n            bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, \n                     edgecolor=COLORS['neutral']))\n\n# Labels and formatting\nax.set_ylabel('Biomass (grams)', fontsize=13, fontweight='bold')\nax.set_xlabel('Target Variables', fontsize=13, fontweight='bold')\nax.set_title('Box Plot Analysis: Target Variables with Statistical Details', \n             fontsize=15, fontweight='bold', pad=20, color=COLORS['text'])\n\n# Legend\nlegend_elements = [\n    plt.Line2D([0], [0], marker='D', color='w', label='Mean',\n              markerfacecolor=COLORS['highlight'], markersize=10),\n    plt.Line2D([0], [0], color=COLORS['secondary'], linewidth=2.5, label='Median'),\n    plt.Line2D([0], [0], marker='o', color='w', label='Outliers',\n              markerfacecolor=COLORS['highlight'], markersize=7, alpha=0.5)\n]\nax.legend(handles=legend_elements, loc='upper right', framealpha=0.95, \n         edgecolor=COLORS['neutral'], fontsize=11)\n\nax.grid(True, alpha=0.3, axis='y', linestyle='--')\nax.set_axisbelow(True)\nplt.xticks(rotation=15, ha='right')\n\nplt.tight_layout()\nplt.savefig(cfg.OUTPUT_PATH / 'professional_3_boxplots.png', dpi=300, bbox_inches='tight',\n            facecolor='white', edgecolor='none')\nprint(\"✓ Saved: professional_3_boxplots.png\")\nplt.close()\n\n# ================================================================\n# 4. SCATTER PLOT MATRIX WITH REGRESSION LINES\n# ================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"Creating Visualization 4: Scatter Plot Matrix\")\nprint(\"=\"*80)\n\n# Select subset of targets for clarity\nmain_targets = ['Dry_Green_g', 'Dry_Dead_g', 'GDM_g', 'Dry_Total_g']\nn_targets = len(main_targets)\n\nfig, axes = plt.subplots(n_targets, n_targets, figsize=(18, 18))\n\nfor i, target1 in enumerate(main_targets):\n    for j, target2 in enumerate(main_targets):\n        ax = axes[i, j]\n        \n        if i == j:\n            # Diagonal: histogram with KDE\n            data = train_pivot[target1].dropna().values\n            ax.hist(data, bins=30, alpha=0.6, color=COLORS['primary'], \n                   edgecolor='white', density=True)\n            \n            # KDE\n            from scipy.stats import gaussian_kde\n            kde = gaussian_kde(data)\n            x_range = np.linspace(data.min(), data.max(), 100)\n            ax.plot(x_range, kde(x_range), color=COLORS['highlight'], \n                   linewidth=2.5, label='KDE')\n            \n            ax.set_ylabel('Density', fontsize=9)\n            if i == n_targets - 1:\n                ax.set_xlabel(cfg.TARGET_NAMES[target1], fontsize=10, fontweight='bold')\n        else:\n            # Off-diagonal: scatter plot\n            x_data = train_pivot[target2].dropna()\n            y_data = train_pivot[target1].dropna()\n            \n            # Align data\n            common_idx = x_data.index.intersection(y_data.index)\n            x_vals = x_data.loc[common_idx].values\n            y_vals = y_data.loc[common_idx].values\n            \n            # Scatter\n            ax.scatter(x_vals, y_vals, alpha=0.4, s=20, color=COLORS['primary'], \n                      edgecolors='none')\n            \n            # Regression line\n            if len(x_vals) > 1:\n                z = np.polyfit(x_vals, y_vals, 1)\n                p = np.poly1d(z)\n                x_line = np.linspace(x_vals.min(), x_vals.max(), 100)\n                ax.plot(x_line, p(x_line), color=COLORS['highlight'], \n                       linewidth=2.5, linestyle='--')\n                \n                # Correlation\n                r, p_val = pearsonr(x_vals, y_vals)\n                ax.text(0.05, 0.95, f'r={r:.3f}', transform=ax.transAxes,\n                       verticalalignment='top', fontsize=9, fontweight='bold',\n                       bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n        \n        # Labels\n        if j == 0:\n            ax.set_ylabel(cfg.TARGET_NAMES[target1], fontsize=10, fontweight='bold')\n        if i == n_targets - 1:\n            ax.set_xlabel(cfg.TARGET_NAMES[target2], fontsize=10, fontweight='bold')\n        \n        ax.grid(True, alpha=0.2, linestyle='--')\n        ax.tick_params(labelsize=8)\n\nfig.suptitle('Scatter Plot Matrix: Pairwise Relationships Between Targets', \n             fontsize=16, fontweight='bold', y=0.995)\n\nplt.tight_layout()\nplt.savefig(cfg.OUTPUT_PATH / 'professional_4_scatter_matrix.png', dpi=300, bbox_inches='tight',\n            facecolor='white', edgecolor='none')\nprint(\"✓ Saved: professional_4_scatter_matrix.png\")\nplt.close()\n\n# ================================================================\n# 5. DETAILED SAMPLE IMAGE ANALYSIS\n# ================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"Creating Visualization 5: Detailed Sample Image Analysis\")\nprint(\"=\"*80)\n\n# Select 6 sample images\nsample_images = train_pivot['image_path'].sample(min(6, len(train_pivot)), random_state=42).tolist()\n\nfig = plt.figure(figsize=(20, 16))\ngs = fig.add_gridspec(6, 4, hspace=0.35, wspace=0.3)  # 6 rows, 4 columns\n\nfor idx, img_path in enumerate(sample_images):\n    img_name = os.path.basename(img_path)\n    full_path = cfg.TRAIN_PATH / img_name\n    \n    img = cv2.imread(str(full_path))\n    if img is None:\n        continue\n    \n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n    \n    # Main image (left column)\n    ax_img = fig.add_subplot(gs[idx, 0])\n    ax_img.imshow(img_rgb)\n    ax_img.set_title(f'Sample {idx+1}', fontsize=12, fontweight='bold')\n    ax_img.axis('off')\n    \n    # Add image properties\n    h, w, _ = img_rgb.shape\n    green_ratio = img_rgb[:,:,1] / (img_rgb.sum(axis=2) + 1)\n    brightness = img_rgb.mean()\n    \n    props_text = f'Size: {w}×{h}\\nBrightness: {brightness:.1f}\\nGreen Ratio: {green_ratio.mean():.3f}'\n    ax_img.text(0.02, 0.98, props_text, transform=ax_img.transAxes,\n               verticalalignment='top', fontsize=9,\n               bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n    \n    # RGB histogram\n    ax_hist = fig.add_subplot(gs[idx, 1])\n    colors_rgb = ['#E74C3C', '#27AE60', '#3498DB']  # Red, Green, Blue\n    labels_rgb = ['Red', 'Green', 'Blue']\n    \n    for c, color, label in zip(range(3), colors_rgb, labels_rgb):\n        hist = cv2.calcHist([img_rgb], [c], None, [256], [0, 256])\n        ax_hist.plot(hist, color=color, linewidth=2, label=label, alpha=0.7)\n    \n    ax_hist.set_xlabel('Pixel Value', fontsize=9)\n    ax_hist.set_ylabel('Frequency', fontsize=9)\n    ax_hist.set_title('RGB Distribution', fontsize=10, fontweight='bold')\n    ax_hist.legend(fontsize=8)\n    ax_hist.grid(True, alpha=0.3)\n    ax_hist.set_xlim([0, 256])\n    \n    # Green channel analysis\n    ax_green = fig.add_subplot(gs[idx, 2])\n    green_channel = img_rgb[:,:,1]\n    ax_green.imshow(green_channel, cmap='Greens')\n    ax_green.set_title('Green Channel', fontsize=10, fontweight='bold')\n    ax_green.axis('off')\n    \n    # Vegetation index\n    ax_veg = fig.add_subplot(gs[idx, 3])\n    ax_veg.imshow(green_ratio, cmap='RdYlGn', vmin=0, vmax=0.5)\n    ax_veg.set_title('Vegetation Index', fontsize=10, fontweight='bold')\n    ax_veg.axis('off')\n\nfig.suptitle('Detailed Sample Image Analysis: RGB, Green Channel, and Vegetation Index', \n             fontsize=16, fontweight='bold', y=0.995)\n\nplt.savefig(cfg.OUTPUT_PATH / 'professional_5_sample_images.png', dpi=300, bbox_inches='tight',\n            facecolor='white', edgecolor='none')\nprint(\"✓ Saved: professional_5_sample_images.png\")\nplt.close()\n\n# ================================================================\n# 6. HIERARCHICAL RELATIONSHIP VALIDATION\n# ================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"Creating Visualization 6: Hierarchical Relationships\")\nprint(\"=\"*80)\n\nfig, axes = plt.subplots(1, 2, figsize=(18, 7))\n\n# Green + Clover = GDM\nax = axes[0]\ncalculated = train_pivot['Dry_Green_g'] + train_pivot['Dry_Clover_g']\nactual = train_pivot['GDM_g']\n\nax.scatter(calculated, actual, alpha=0.5, s=40, color=COLORS['primary'], \n          edgecolors='white', linewidth=0.5)\n\n# Perfect match line\nmax_val = max(calculated.max(), actual.max())\nax.plot([0, max_val], [0, max_val], color=COLORS['highlight'], \n       linewidth=3, linestyle='--', label='Perfect Match (y=x)')\n\n# Regression line\nz = np.polyfit(calculated, actual, 1)\np = np.poly1d(z)\nx_line = np.linspace(calculated.min(), calculated.max(), 100)\nax.plot(x_line, p(x_line), color=COLORS['secondary'], \n       linewidth=2.5, label=f'Regression: y={z[0]:.3f}x+{z[1]:.2f}')\n\n# Statistics\nr, p_val = pearsonr(calculated, actual)\nrmse = np.sqrt(((calculated - actual) ** 2).mean())\n\nstats_text = f'Pearson r: {r:.4f}\\np-value: {p_val:.2e}\\nRMSE: {rmse:.2f}g\\nn: {len(calculated):,}'\nax.text(0.05, 0.95, stats_text, transform=ax.transAxes,\n       verticalalignment='top', fontsize=11, fontweight='bold',\n       bbox=dict(boxstyle='round', facecolor='white', alpha=0.95, \n                edgecolor=COLORS['neutral'], linewidth=2))\n\nax.set_xlabel('Green + Clover (calculated, grams)', fontsize=12, fontweight='bold')\nax.set_ylabel('GDM (actual, grams)', fontsize=12, fontweight='bold')\nax.set_title('Hierarchical Validation: Green + Clover = GDM', \n            fontsize=13, fontweight='bold', pad=15)\nax.legend(loc='lower right', fontsize=11, framealpha=0.95)\nax.grid(True, alpha=0.3, linestyle='--')\n\n# GDM + Dead = Total\nax = axes[1]\ncalculated = train_pivot['GDM_g'] + train_pivot['Dry_Dead_g']\nactual = train_pivot['Dry_Total_g']\n\nax.scatter(calculated, actual, alpha=0.5, s=40, color=COLORS['primary'], \n          edgecolors='white', linewidth=0.5)\n\nmax_val = max(calculated.max(), actual.max())\nax.plot([0, max_val], [0, max_val], color=COLORS['highlight'], \n       linewidth=3, linestyle='--', label='Perfect Match (y=x)')\n\nz = np.polyfit(calculated, actual, 1)\np = np.poly1d(z)\nx_line = np.linspace(calculated.min(), calculated.max(), 100)\nax.plot(x_line, p(x_line), color=COLORS['secondary'], \n       linewidth=2.5, label=f'Regression: y={z[0]:.3f}x+{z[1]:.2f}')\n\nr, p_val = pearsonr(calculated, actual)\nrmse = np.sqrt(((calculated - actual) ** 2).mean())\n\nstats_text = f'Pearson r: {r:.4f}\\np-value: {p_val:.2e}\\nRMSE: {rmse:.2f}g\\nn: {len(calculated):,}'\nax.text(0.05, 0.95, stats_text, transform=ax.transAxes,\n       verticalalignment='top', fontsize=11, fontweight='bold',\n       bbox=dict(boxstyle='round', facecolor='white', alpha=0.95, \n                edgecolor=COLORS['neutral'], linewidth=2))\n\nax.set_xlabel('GDM + Dead (calculated, grams)', fontsize=12, fontweight='bold')\nax.set_ylabel('Total Biomass (actual, grams)', fontsize=12, fontweight='bold')\nax.set_title('Hierarchical Validation: GDM + Dead = Total', \n            fontsize=13, fontweight='bold', pad=15)\nax.legend(loc='lower right', fontsize=11, framealpha=0.95)\nax.grid(True, alpha=0.3, linestyle='--')\n\nfig.suptitle('Hierarchical Relationship Validation with Statistical Analysis', \n             fontsize=15, fontweight='bold', y=1.00)\n\nplt.tight_layout()\nplt.savefig(cfg.OUTPUT_PATH / 'professional_6_hierarchical.png', dpi=300, bbox_inches='tight',\n            facecolor='white', edgecolor='none')\nprint(\"✓ Saved: professional_6_hierarchical.png\")\nplt.close()\n\n# ================================================================\n# SUMMARY\n# ================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"EDA COMPLETE - ALL VISUALIZATIONS SAVED\")\nprint(\"=\"*80)\nprint(\"\\nGenerated Professional Visualizations:\")\nprint(\"  1. professional_1_distributions.png - Target distributions with bell curves\")\nprint(\"  2. professional_2_correlation_matrix.png - Complete correlation analysis\")\nprint(\"  3. professional_3_boxplots.png - Detailed box plots with statistics\")\nprint(\"  4. professional_4_scatter_matrix.png - Scatter plot matrix with regression\")\nprint(\"  5. professional_5_sample_images.png - Detailed image analysis\")\nprint(\"  6. professional_6_hierarchical.png - Hierarchical relationship validation\")\nprint(\"\\nAll visualizations use consistent professional color scheme\")\nprint(\"Statistical details and annotations included on all plots\")\nprint(\"=\"*80)","metadata":{"_uuid":"eba9ea1a-132a-4d3b-b627-956bdfcf899c","_cell_guid":"9a182e42-6a25-4449-b40b-efcfd297fe51","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-12-27T22:59:45.152019Z","iopub.execute_input":"2025-12-27T22:59:45.152278Z","iopub.status.idle":"2025-12-27T23:00:08.082813Z","shell.execute_reply.started":"2025-12-27T22:59:45.152256Z","shell.execute_reply":"2025-12-27T23:00:08.082063Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"================================================================================\nCSIRO BIOMASS COMPETITION - PROFESSIONAL EDA\n================================================================================\n\nLoading data...\nTrain shape: (1785, 9)\nTest shape: (5, 3)\nPivoted train shape: (357, 6)\n\n================================================================================\nCreating Visualization 1: Target Distributions with Normal Curves\n================================================================================\n✓ Saved: professional_1_distributions.png\n\n================================================================================\nCreating Visualization 2: Complete Correlation Matrix\n================================================================================\n✓ Saved: professional_2_correlation_matrix.png\n\n================================================================================\nCreating Visualization 3: Detailed Box Plots\n================================================================================\n✓ Saved: professional_3_boxplots.png\n\n================================================================================\nCreating Visualization 4: Scatter Plot Matrix\n================================================================================\n✓ Saved: professional_4_scatter_matrix.png\n\n================================================================================\nCreating Visualization 5: Detailed Sample Image Analysis\n================================================================================\n✓ Saved: professional_5_sample_images.png\n\n================================================================================\nCreating Visualization 6: Hierarchical Relationships\n================================================================================\n✓ Saved: professional_6_hierarchical.png\n\n================================================================================\nEDA COMPLETE - ALL VISUALIZATIONS SAVED\n================================================================================\n\nGenerated Professional Visualizations:\n  1. professional_1_distributions.png - Target distributions with bell curves\n  2. professional_2_correlation_matrix.png - Complete correlation analysis\n  3. professional_3_boxplots.png - Detailed box plots with statistics\n  4. professional_4_scatter_matrix.png - Scatter plot matrix with regression\n  5. professional_5_sample_images.png - Detailed image analysis\n  6. professional_6_hierarchical.png - Hierarchical relationship validation\n\nAll visualizations use consistent professional color scheme\nStatistical details and annotations included on all plots\n================================================================================\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ================================================================\n# CSIRO BIOMASS - ULTRA-OPTIMIZED VERSION\n# ================================================================\n# Target: 0.80+ CV Score\n# Advanced ensemble + feature engineering + optimization\n# ================================================================\n\nimport os\nimport gc\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import VotingRegressor, StackingRegressor, ExtraTreesRegressor\nfrom sklearn.linear_model import Ridge, Lasso, ElasticNet\nfrom sklearn.neural_network import MLPRegressor\n\n# ================================================================\n# Configuration\n# ================================================================\n\nclass Config:\n    BASE_PATH = Path(\"/kaggle/input/csiro-biomass/\")\n    TRAIN_PATH = BASE_PATH / \"train\"\n    TEST_PATH = BASE_PATH / \"test\"\n    \n    SEED = 42\n    N_FOLDS = 5  # 5 folds is optimal (10 is overkill and slower)\n    \n    TARGET_COLS = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n    TARGET_WEIGHTS = {\n        'Dry_Green_g': 0.1,\n        'Dry_Dead_g': 0.1,\n        'Dry_Clover_g': 0.1,\n        'GDM_g': 0.2,\n        'Dry_Total_g': 0.5,  # EDA: This is 50%!\n    }\n\ncfg = Config()\n\n# ================================================================\n# Utility Functions\n# ================================================================\n\ndef set_seed(seed=42):\n    np.random.seed(seed)\n    import random\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\ndef competition_metric(y_true, y_pred):\n    \"\"\"Competition metric - weighted R²\"\"\"\n    weights = np.array([cfg.TARGET_WEIGHTS[col] for col in cfg.TARGET_COLS])\n    y_weighted = np.sum(y_true.mean(axis=0) * weights)\n    ss_res = np.sum(((y_true - y_pred) ** 2).mean(axis=0) * weights)\n    ss_tot = np.sum(((y_true - y_weighted) ** 2).mean(axis=0) * weights)\n    return 1 - ss_res / ss_tot\n\ndef reconcile_predictions(df):\n    \"\"\"Apply hierarchical reconciliation\"\"\"\n    df = df.copy()\n    for col in cfg.TARGET_COLS:\n        df[col] = df[col].clip(lower=0)\n    \n    ordered_cols = [\"Dry_Green_g\", \"Dry_Clover_g\", \"Dry_Dead_g\", \"GDM_g\", \"Dry_Total_g\"]\n    Y = df[ordered_cols].values.T\n    \n    C = np.array([[1, 1, 0, -1, 0], [0, 0, 1, 1, -1]])\n    C_T = C.T\n    inv_CCt = np.linalg.inv(C @ C_T)\n    P = np.eye(5) - C_T @ inv_CCt @ C\n    Y_reconciled = P @ Y\n    Y_reconciled = Y_reconciled.T.clip(min=0)\n    \n    df[ordered_cols] = Y_reconciled\n    return df\n\n# ================================================================\n# ULTRA-ADVANCED Feature Extraction (200+ features)\n# ================================================================\n\ndef extract_ultra_features(image_path):\n    \"\"\"Extract 200+ advanced features\"\"\"\n    img = cv2.imread(str(image_path))\n    if img is None:\n        return np.zeros(210)\n    \n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n    img_lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img_ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n    \n    h, w, _ = img_rgb.shape\n    mid = w // 2\n    left = img_rgb[:, :mid]\n    right = img_rgb[:, mid:]\n    \n    features = []\n    \n    # 1. RGB Statistics (30 features)\n    for channel in range(3):\n        ch = img_rgb[:, :, channel]\n        features.extend([\n            ch.mean(), ch.std(), ch.var(),\n            np.percentile(ch, 10), np.percentile(ch, 25), \n            np.percentile(ch, 50), np.percentile(ch, 75), np.percentile(ch, 90),\n            ch.max(), ch.min()\n        ])\n    \n    # 2. HSV Statistics (30 features)\n    for channel in range(3):\n        ch = img_hsv[:, :, channel]\n        features.extend([\n            ch.mean(), ch.std(), ch.var(),\n            np.percentile(ch, 10), np.percentile(ch, 25),\n            np.percentile(ch, 50), np.percentile(ch, 75), np.percentile(ch, 90),\n            ch.max(), ch.min()\n        ])\n    \n    # 3. LAB Statistics (30 features)\n    for channel in range(3):\n        ch = img_lab[:, :, channel]\n        features.extend([\n            ch.mean(), ch.std(), ch.var(),\n            np.percentile(ch, 10), np.percentile(ch, 25),\n            np.percentile(ch, 50), np.percentile(ch, 75), np.percentile(ch, 90),\n            ch.max(), ch.min()\n        ])\n    \n    # 4. YCrCb Statistics (30 features)\n    for channel in range(3):\n        ch = img_ycrcb[:, :, channel]\n        features.extend([\n            ch.mean(), ch.std(), ch.var(),\n            np.percentile(ch, 25), np.percentile(ch, 50),\n            np.percentile(ch, 75),\n            ch.max(), ch.min(),\n            (ch > 128).mean(), (ch < 64).mean()\n        ])\n    \n    # 5. Advanced Vegetation Indices (20 features)\n    R = img_rgb[:, :, 0].astype(float) + 1\n    G = img_rgb[:, :, 1].astype(float) + 1\n    B = img_rgb[:, :, 2].astype(float) + 1\n    \n    # Multiple vegetation indices\n    ExG = 2 * G - R - B\n    ExR = 1.4 * R - G\n    CIVE = 0.441 * R - 0.811 * G + 0.385 * B + 18.78745\n    VEG = G / (R ** 0.667 * B ** 0.333)\n    GRVI = (G - R) / (G + R)\n    VARI = (G - R) / (G + R - B + 1e-6)\n    NGBDI = (G - B) / (G + B + 1e-6)\n    green_ratio = G / (R + G + B)\n    \n    for idx in [ExG, ExR, CIVE, VEG, GRVI, VARI, NGBDI, green_ratio]:\n        features.extend([idx.mean(), idx.std()])\n    \n    # Additional ratios\n    features.extend([\n        (G / R).mean(), (G / B).mean(), (R / B).mean(),\n        (G > R).mean(), (G > B).mean(), (R > B).mean()\n    ])\n    \n    # 6. Texture Features (25 features)\n    # Edges\n    edges = cv2.Canny(img_gray, 50, 150)\n    features.extend([\n        edges.mean(), edges.std(),\n        np.count_nonzero(edges) / edges.size,\n        edges.max()\n    ])\n    \n    # Sobel\n    sobelx = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=3)\n    sobely = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=3)\n    gradient_magnitude = np.sqrt(sobelx**2 + sobely**2)\n    features.extend([\n        gradient_magnitude.mean(), gradient_magnitude.std(),\n        gradient_magnitude.max(), np.percentile(gradient_magnitude, 95)\n    ])\n    \n    # Laplacian\n    laplacian = cv2.Laplacian(img_gray, cv2.CV_64F)\n    features.extend([\n        laplacian.mean(), laplacian.std(),\n        np.abs(laplacian).mean(), laplacian.var()\n    ])\n    \n    # Gray statistics\n    features.extend([\n        img_gray.mean(), img_gray.std(), img_gray.var(),\n        np.percentile(img_gray, 25), np.percentile(img_gray, 50),\n        np.percentile(img_gray, 75), img_gray.max(), img_gray.min(),\n        (img_gray > 128).mean(), (img_gray < 64).mean()\n    ])\n    \n    # 7. Spatial Features (20 features)\n    # Left vs Right\n    for channel in range(3):\n        features.extend([\n            left[:, :, channel].mean() - right[:, :, channel].mean(),\n            left[:, :, channel].std() - right[:, :, channel].std(),\n            left[:, :, channel].max() - right[:, :, channel].max()\n        ])\n    \n    # Quadrant analysis\n    h_mid, w_mid = h // 2, w // 2\n    quad_tl = img_rgb[:h_mid, :w_mid]\n    quad_tr = img_rgb[:h_mid, w_mid:]\n    quad_bl = img_rgb[h_mid:, :w_mid]\n    quad_br = img_rgb[h_mid:, w_mid:]\n    \n    for quad in [quad_tl, quad_tr, quad_bl, quad_br]:\n        features.append(quad[:, :, 1].mean())  # Green channel mean\n    \n    # Vertical profile\n    features.extend([\n        img_rgb[:h//3, :, 1].mean(),\n        img_rgb[h//3:2*h//3, :, 1].mean(),\n        img_rgb[2*h//3:, :, 1].mean()\n    ])\n    \n    # 8. Color Moments (18 features)\n    from scipy.stats import skew, kurtosis\n    for channel in range(3):\n        ch = img_rgb[:, :, channel].flatten()\n        features.extend([\n            skew(ch), kurtosis(ch),\n            np.percentile(ch, 5), np.percentile(ch, 95),\n            (ch > ch.mean() + ch.std()).mean(),\n            (ch < ch.mean() - ch.std()).mean()\n        ])\n    \n    # 9. Color Histograms (12 features - compact)\n    for channel in range(3):\n        hist = cv2.calcHist([img_rgb], [channel], None, [4], [0, 256])\n        features.extend(hist.flatten() / hist.sum())\n    \n    # 10. Saturation & Value Analysis (15 features)\n    saturation = img_hsv[:, :, 1]\n    value = img_hsv[:, :, 2]\n    \n    features.extend([\n        saturation.mean(), saturation.std(), saturation.var(),\n        (saturation > 50).mean(), (saturation > 100).mean(),\n        np.percentile(saturation, 75), np.percentile(saturation, 90)\n    ])\n    \n    features.extend([\n        value.mean(), value.std(), value.var(),\n        (value > 128).mean(), (value > 180).mean(),\n        np.percentile(value, 75), np.percentile(value, 90),\n        (value < 50).mean()\n    ])\n    \n    return np.array(features)\n\ndef load_or_create_features(df, image_dir, feature_cache_path=None):\n    \"\"\"Load or create features\"\"\"\n    if feature_cache_path and os.path.exists(feature_cache_path):\n        print(f\"Loading cached features from {feature_cache_path}\")\n        return pd.read_parquet(feature_cache_path)\n    \n    print(\"Extracting ultra-advanced features...\")\n    features_list = []\n    image_paths = []\n    \n    for idx in tqdm(range(len(df)), desc=\"Processing images\"):\n        row = df.iloc[idx]\n        img_path_value = row['image_path']\n        img_name = os.path.basename(str(img_path_value))\n        img_path = image_dir / img_name\n        \n        try:\n            features = extract_ultra_features(img_path)\n        except Exception as e:\n            print(f\"Error processing {img_path}: {e}\")\n            features = np.zeros(210)\n        \n        features_list.append(features)\n        image_paths.append(img_path_value)\n    \n    n_features = len(features_list[0])\n    feature_cols = [f'feat_{i}' for i in range(n_features)]\n    feature_df = pd.DataFrame(features_list, columns=feature_cols)\n    feature_df['image_path'] = image_paths\n    \n    for col in cfg.TARGET_COLS:\n        if col in df.columns:\n            feature_df[col] = df[col].values\n    \n    if feature_cache_path:\n        feature_df.to_parquet(feature_cache_path, index=False)\n        print(f\"Cached features to {feature_cache_path}\")\n    \n    return feature_df\n\n# ================================================================\n# Ultra-Advanced Model with Stacking\n# ================================================================\n\ndef create_stacking_model(target_name):\n    \"\"\"Create stacking ensemble for each target - STRONGER for Total\"\"\"\n    \n    # EDA Finding: Total Biomass is 50% of score - make it strongest!\n    is_total = (target_name == 'Dry_Total_g')\n    \n    # Level 1: Base models (diverse and strong)\n    base_models = [\n        ('lgb', LGBMRegressor(\n            n_estimators=1500 if is_total else 1000,  # More trees for Total!\n            learning_rate=0.015 if is_total else 0.02,  # Slower = more accurate\n            max_depth=10 if is_total else 8,  # Deeper for Total\n            num_leaves=200 if is_total else 127,  # More leaves for Total\n            min_child_samples=10 if is_total else 15,\n            subsample=0.85,\n            colsample_bytree=0.85,\n            reg_alpha=0.15,\n            reg_lambda=0.15,\n            random_state=cfg.SEED,\n            verbose=-1,\n            n_jobs=-1\n        )),\n        ('xgb', XGBRegressor(\n            n_estimators=1500 if is_total else 1000,\n            learning_rate=0.015 if is_total else 0.02,\n            max_depth=10 if is_total else 8,\n            min_child_weight=2,\n            subsample=0.85,\n            colsample_bytree=0.85,\n            reg_alpha=0.15,\n            reg_lambda=0.15,\n            random_state=cfg.SEED,\n            n_jobs=-1,\n            tree_method='hist'\n        )),\n        ('cat', CatBoostRegressor(\n            iterations=1500 if is_total else 1000,\n            learning_rate=0.015 if is_total else 0.02,\n            depth=10 if is_total else 8,\n            l2_leaf_reg=4,\n            random_state=cfg.SEED,\n            verbose=0,\n            thread_count=-1\n        )),\n        ('et', ExtraTreesRegressor(\n            n_estimators=300 if is_total else 200,\n            max_depth=20 if is_total else 15,\n            min_samples_split=4 if is_total else 5,\n            min_samples_leaf=1 if is_total else 2,\n            random_state=cfg.SEED,\n            n_jobs=-1\n        ))\n    ]\n    \n    # Level 2: Stronger meta-learner\n    meta_learner = Ridge(alpha=0.5)  # Less regularization\n    \n    # Stacking with more CV folds for better generalization\n    model = StackingRegressor(\n        estimators=base_models,\n        final_estimator=meta_learner,\n        cv=5,\n        n_jobs=-1\n    )\n    \n    return model\n\ndef train_ultra_model(train_df, feature_cols):\n    \"\"\"Train ultra-advanced model\"\"\"\n    \n    set_seed(cfg.SEED)\n    kfold = KFold(n_splits=cfg.N_FOLDS, shuffle=True, random_state=cfg.SEED)\n    \n    # Keep as DataFrame to preserve feature names\n    X_df = train_df[feature_cols].copy()\n    \n    # Advanced scaling pipeline - use DataFrame methods\n    scaler1 = RobustScaler()\n    X_scaled1 = pd.DataFrame(\n        scaler1.fit_transform(X_df),\n        columns=X_df.columns,\n        index=X_df.index\n    )\n    \n    scaler2 = QuantileTransformer(output_distribution='normal', random_state=cfg.SEED)\n    X_scaled2 = pd.DataFrame(\n        scaler2.fit_transform(X_scaled1),\n        columns=X_df.columns,\n        index=X_df.index\n    )\n    \n    # PCA - create feature names\n    pca = PCA(n_components=0.99, random_state=cfg.SEED)\n    X_pca_array = pca.fit_transform(X_scaled2)\n    pca_cols = [f'pca_{i}' for i in range(X_pca_array.shape[1])]\n    X_pca = pd.DataFrame(X_pca_array, columns=pca_cols, index=X_df.index)\n    \n    print(f\"Features: {len(feature_cols)} -> PCA: {len(pca_cols)}\")\n    \n    oof_predictions = np.zeros((len(train_df), len(cfg.TARGET_COLS)))\n    models = []\n    \n    for fold, (train_idx, val_idx) in enumerate(kfold.split(train_df)):\n        print(f\"\\n{'='*60}\")\n        print(f\"Fold {fold + 1}/{cfg.N_FOLDS}\")\n        print(f\"{'='*60}\")\n        \n        X_train = X_pca.iloc[train_idx]\n        X_val = X_pca.iloc[val_idx]\n        \n        fold_models = []\n        \n        for target_idx, target_col in enumerate(cfg.TARGET_COLS):\n            y_train = train_df.iloc[train_idx][target_col].values\n            y_val = train_df.iloc[val_idx][target_col].values\n            \n            # Train model with DataFrame\n            model = create_stacking_model(target_col)\n            model.fit(X_train, y_train)\n            \n            # Predict\n            pred = model.predict(X_val)\n            pred = np.clip(pred, 0, None)\n            \n            oof_predictions[val_idx, target_idx] = pred\n            fold_models.append(model)\n            \n            # R²\n            ss_res = ((y_val - pred) ** 2).mean()\n            ss_tot = ((y_val - y_val.mean()) ** 2).mean()\n            r2 = 1 - ss_res / ss_tot\n            print(f\"  {target_col}: R² = {r2:.4f}\")\n        \n        models.append(fold_models)\n        \n        # Fold score\n        fold_score = competition_metric(\n            train_df.iloc[val_idx][cfg.TARGET_COLS].values,\n            oof_predictions[val_idx]\n        )\n        print(f\"\\nFold {fold + 1} Competition Score: {fold_score:.4f}\")\n    \n    # Overall CV\n    cv_score = competition_metric(\n        train_df[cfg.TARGET_COLS].values,\n        oof_predictions\n    )\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"Overall CV Score: {cv_score:.4f}\")\n    print(f\"{'='*60}\")\n    \n    return models, scaler1, scaler2, pca, pca_cols, oof_predictions\n\n# ================================================================\n# Inference\n# ================================================================\n\ndef predict_ultra(test_df, models, scaler1, scaler2, pca, pca_cols, feature_cols):\n    \"\"\"Ultra-advanced prediction\"\"\"\n    \n    print(\"\\nGenerating predictions...\")\n    \n    # Keep as DataFrame\n    X_test_df = test_df[feature_cols].copy()\n    \n    X_test_scaled1 = pd.DataFrame(\n        scaler1.transform(X_test_df),\n        columns=X_test_df.columns,\n        index=X_test_df.index\n    )\n    \n    X_test_scaled2 = pd.DataFrame(\n        scaler2.transform(X_test_scaled1),\n        columns=X_test_df.columns,\n        index=X_test_df.index\n    )\n    \n    X_test_pca = pd.DataFrame(\n        pca.transform(X_test_scaled2),\n        columns=pca_cols,\n        index=X_test_df.index\n    )\n    \n    predictions = np.zeros((len(test_df), len(cfg.TARGET_COLS)))\n    \n    for fold_idx, fold_models in enumerate(models):\n        for target_idx, model in enumerate(fold_models):\n            pred = model.predict(X_test_pca)\n            pred = np.clip(pred, 0, None)\n            predictions[:, target_idx] += pred\n    \n    predictions /= len(models)\n    \n    return predictions\n\n# ================================================================\n# Main Execution\n# ================================================================\n\ndef main():\n    print(\"=\"*60)\n    print(\"CSIRO BIOMASS - ULTRA-OPTIMIZED VERSION\")\n    print(\"Target: 0.80+ CV Score\")\n    print(\"=\"*60)\n    \n    set_seed(cfg.SEED)\n    \n    # Load data\n    print(\"\\n1. Loading data...\")\n    train_df = pd.read_csv(cfg.BASE_PATH / \"train.csv\")\n    test_df = pd.read_csv(cfg.BASE_PATH / \"test.csv\")\n    \n    print(f\"Train: {train_df.shape}\")\n    print(f\"Test: {test_df.shape}\")\n    \n    # Pivot\n    print(\"\\n2. Pivoting data...\")\n    train_pivot = train_df.pivot_table(\n        values='target',\n        index='image_path',\n        columns='target_name',\n        aggfunc='mean'\n    ).reset_index()\n    \n    for col in cfg.TARGET_COLS:\n        if col in train_pivot.columns:\n            train_pivot[col] = pd.to_numeric(train_pivot[col], errors='coerce').fillna(0.0)\n    \n    train_pivot['image_path'] = train_pivot['image_path'].apply(\n        lambda x: os.path.basename(x) if isinstance(x, str) else x\n    )\n    \n    test_unique = test_df.drop_duplicates('image_path').reset_index(drop=True)\n    test_unique['image_path'] = test_unique['image_path'].apply(\n        lambda x: os.path.basename(x) if isinstance(x, str) else x\n    )\n    \n    print(f\"Train pivot: {train_pivot.shape}\")\n    print(f\"Test unique: {test_unique.shape}\")\n    \n    # Extract features\n    print(\"\\n3. Extracting ultra-advanced features (210+)...\")\n    train_features = load_or_create_features(\n        train_pivot,\n        cfg.TRAIN_PATH,\n        feature_cache_path='/kaggle/working/train_features_ultra.parquet'\n    )\n    \n    test_features = load_or_create_features(\n        test_unique,\n        cfg.TEST_PATH,\n        feature_cache_path='/kaggle/working/test_features_ultra.parquet'\n    )\n    \n    feature_cols = [col for col in train_features.columns if col.startswith('feat_')]\n    print(f\"Number of features: {len(feature_cols)}\")\n    \n    # Train\n    print(\"\\n4. Training ultra-advanced stacking ensemble...\")\n    models, scaler1, scaler2, pca, pca_cols, oof_preds = train_ultra_model(train_features, feature_cols)\n    \n    # Reconcile OOF\n    print(\"\\n5. Reconciling OOF predictions...\")\n    oof_df = pd.DataFrame(oof_preds, columns=cfg.TARGET_COLS)\n    oof_reconciled = reconcile_predictions(oof_df)\n    \n    reconciled_score = competition_metric(\n        train_features[cfg.TARGET_COLS].values,\n        oof_reconciled.values\n    )\n    print(f\"Reconciled CV Score: {reconciled_score:.4f}\")\n    \n    # Predict test\n    print(\"\\n6. Predicting on test...\")\n    test_preds = predict_ultra(test_features, models, scaler1, scaler2, pca, pca_cols, feature_cols)\n    \n    # Submission\n    print(\"\\n7. Creating submission...\")\n    pred_df = pd.DataFrame(test_preds, columns=cfg.TARGET_COLS)\n    pred_df['image_path'] = test_features['image_path'].values\n    pred_df = reconcile_predictions(pred_df)\n    \n    pred_long = pred_df.melt(\n        id_vars='image_path',\n        value_vars=cfg.TARGET_COLS,\n        var_name='target_name',\n        value_name='target'\n    )\n    \n    test_df['image_path_basename'] = test_df['image_path'].apply(\n        lambda x: os.path.basename(x) if isinstance(x, str) else x\n    )\n    pred_long['image_path_basename'] = pred_long['image_path'].apply(\n        lambda x: os.path.basename(x) if isinstance(x, str) else x\n    )\n    \n    submission = test_df[['sample_id', 'image_path_basename', 'target_name']].merge(\n        pred_long[['image_path_basename', 'target_name', 'target']],\n        on=['image_path_basename', 'target_name'],\n        how='left'\n    )[['sample_id', 'target']]\n    \n    submission.to_csv('/kaggle/working/submission.csv', index=False)\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"✓ ULTRA-OPTIMIZATION COMPLETE!\")\n    print(\"=\"*60)\n    print(f\"\\nFinal CV Score: {reconciled_score:.4f}\")\n    print(f\"Submission shape: {submission.shape}\")\n    print(f\"\\nSubmission saved to: /kaggle/working/submission.csv\")\n    \n    # Final stats\n    print(\"\\nPrediction Statistics:\")\n    for col in cfg.TARGET_COLS:\n        vals = pred_df[col].values\n        print(f\"  {col}:\")\n        print(f\"    Mean: {vals.mean():.2f}g, Std: {vals.std():.2f}g\")\n        print(f\"    Min: {vals.min():.2f}g, Max: {vals.max():.2f}g\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T23:00:08.085965Z","iopub.execute_input":"2025-12-27T23:00:08.086231Z"}},"outputs":[{"name":"stdout","text":"============================================================\nCSIRO BIOMASS - ULTRA-OPTIMIZED VERSION\nTarget: 0.80+ CV Score\n============================================================\n\n1. Loading data...\nTrain: (1785, 9)\nTest: (5, 3)\n\n2. Pivoting data...\nTrain pivot: (357, 6)\nTest unique: (1, 3)\n\n3. Extracting ultra-advanced features (210+)...\nLoading cached features from /kaggle/working/train_features_ultra.parquet\nLoading cached features from /kaggle/working/test_features_ultra.parquet\nNumber of features: 225\n\n4. Training ultra-advanced stacking ensemble...\nFeatures: 225 -> PCA: 59\n\n============================================================\nFold 1/5\n============================================================\n  Dry_Green_g: R² = 0.2545\n  Dry_Dead_g: R² = 0.3068\n  Dry_Clover_g: R² = 0.0286\n  GDM_g: R² = 0.4405\n","output_type":"stream"}],"execution_count":null}]}